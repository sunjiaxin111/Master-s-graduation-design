C1 的取值有 541 个
C2 的取值有 497 个
C3 的取值有 43869 个
C4 的取值有 25183 个
C5 的取值有 145 个
C6 的取值有 11 个
C7 的取值有 7623 个
C8 的取值有 257 个
C9 的取值有 3 个
C10 的取值有 10997 个
C11 的取值有 3799 个
C12 的取值有 41311 个
C13 的取值有 2796 个
C14 的取值有 26 个
C15 的取值有 5238 个
C16 的取值有 34616 个
C17 的取值有 10 个
C18 的取值有 2548 个
C19 的取值有 1302 个
C20 的取值有 3 个
C21 的取值有 38617 个
C22 的取值有 10 个
C23 的取值有 14 个
C24 的取值有 12334 个
C25 的取值有 50 个
C26 的取值有 9526 个
one-hot处理后的特征数为: 241339
##############################################################################

1、对比labelEncoder和meanEncoder编码后数据集在lgb上的效果
2、使用lgb编码后，在FFM中对比①不使用交叉熵特征和正例率特征②使用交叉熵特征③使用正例率特征④使用交叉熵特征和正例率特征这4种情况的效果
3、使用交叉熵特征和正例率特征，使用AFFM

##############################################################################
1、对比labelEncoder和meanEncoder编码后数据集在lgb上的效果
1.1、使用gen_criteo_labelEncoder.py生成criteo_labelEncoder.csv(在本地生成后传到超算，这里本地运行和超算运行有点差异)
1.2、使用lgb_tuning中的labelEncoder_lgb_tuning.py调参（这里调参和avazu类似就不多余了）
1.3、使用lgb_test中的labelEncoder_lgb_test.py得到labelEncoder在lgb上的效果
1.4、使用gen_criteo_meanEncoder.py生成criteo_meanEncoder.csv(在本地生成后传到超算，这里本地运行和超算运行有点差异)
1.5、使用lgb_tuning中的meanEncoder_lgb_tuning.py调参（这里调参和avazu类似就不多余了）
1.6、使用lgb_test中的meanEncoder_lgb_test.py得到meanEncoder在lgb上的效果

##############################################################################
2、使用lgb编码后，在FFM中对比①不使用交叉熵特征和正例率特征②使用交叉熵特征③使用正例率特征④使用交叉熵特征和正例率特征这4种情况的效果
2.1、使用gen_criteo_lgbEncoder.py生成criteo_lgbEncoder.csv
2.2、在ffm_tuning中分别对上述四种情况进行调参
①不使用交叉熵特征和正例率特征（输出保存在ffm_lgbEncoder_tuning1.out）
python ffm_lgbEncoder_tuning.py --use_cross_entropy False --use_pos_ratio False
--embedding_size_list [4,8] --dropout_fm_0_list [0.3,0.5] --dropout_fm_1_list [0.3,0.5]
最优参数
'embedding_size': 4, 'dropout_fm': [0.3, 0.3]
最优效果
WARNING:root:训练集logloss: 0.42642580
WARNING:root:训练集auc: 0.79994734
WARNING:root:验证集logloss: 0.45868904
WARNING:root:验证集auc: 0.75402729
WARNING:root:测试集logloss: 0.46967970
WARNING:root:测试集auc: 0.75279627
Time used: 186.555917263031

②使用交叉熵特征（输出保存在ffm_lgbEncoder_tuning2.out）
python ffm_lgbEncoder_tuning.py --use_cross_entropy True --use_pos_ratio False
--embedding_size_list [4,8] --dropout_fm_0_list [0.3,0.5] --dropout_fm_1_list [0.3,0.5]
最优参数
'embedding_size': 4, 'dropout_fm': [0.3, 0.3]
最优效果
WARNING:root:训练集logloss: 0.42371925
WARNING:root:训练集auc: 0.80090621
WARNING:root:验证集logloss: 0.45782202
WARNING:root:验证集auc: 0.75527196
WARNING:root:测试集logloss: 0.46911609
WARNING:root:测试集auc: 0.75448256
Time used: 663.8779594898224

③使用正例率特征（输出保存在ffm_lgbEncoder_tuning3.out）
python ffm_lgbEncoder_tuning.py --use_cross_entropy False --use_pos_ratio True
--embedding_size_list [4,8] --dropout_fm_0_list [0.5,0.7] --dropout_fm_1_list [0.3,0.5]
最优参数
'embedding_size': 4, 'dropout_fm': [0.5, 0.3]
最优效果
WARNING:root:训练集logloss: 0.42544337
WARNING:root:训练集auc: 0.79889036
WARNING:root:验证集logloss: 0.45729884
WARNING:root:验证集auc: 0.75546344
WARNING:root:测试集logloss: 0.46864845
WARNING:root:测试集auc: 0.75459841
Time used: 689.9907119274139

④使用交叉熵特征和正例率特征（输出保存在ffm_lgbEncoder_tuning4.out）
python ffm_lgbEncoder_tuning.py --use_cross_entropy True --use_pos_ratio True
--embedding_size_list [2,4] --dropout_fm_0_list [0.3] --dropout_fm_1_list [0.1]
最优参数
'embedding_size': 2, 'dropout_fm': [0.3, 0.1]
最优效果
WARNING:root:训练集logloss: 0.43078846
WARNING:root:训练集auc: 0.79293631
WARNING:root:验证集logloss: 0.45731161
WARNING:root:验证集auc: 0.75472665
WARNING:root:测试集logloss: 0.46764388
WARNING:root:测试集auc: 0.75508891
Time used: 579.2318682670593

2.3、在ffm_test中分别得到上述四种情况的效果
通过传入参数来区分四种情况
①不使用交叉熵特征和正例率特征
命令
python ffm_lgbEncoder_test.py --use_cross_entropy False --use_pos_ratio False
--embedding_size 4 --dropout_fm [0.3,0.3]
输出
WARNING:root:#params: 35546
WARNING:root:[1] train-auc=0.7578, valid-auc=0.7279 [3.3 s]
WARNING:root:[2] train-auc=0.7905, valid-auc=0.7523 [2.7 s]
WARNING:root:[3] train-auc=0.7999, valid-auc=0.7540 [2.8 s]
WARNING:root:[4] train-auc=0.8059, valid-auc=0.7534 [2.7 s]
WARNING:root:[5] train-auc=0.8102, valid-auc=0.7523 [2.8 s]
WARNING:root:[6] train-auc=0.8136, valid-auc=0.7511 [2.7 s]
WARNING:root:[7] train-auc=0.8167, valid-auc=0.7500 [2.8 s]
WARNING:root:训练集logloss: 0.42642580
WARNING:root:训练集auc: 0.79994734
WARNING:root:验证集logloss: 0.45868904
WARNING:root:验证集auc: 0.75402729
WARNING:root:测试集logloss: 0.46967970
WARNING:root:测试集auc: 0.75279627
Time used: 26.185401439666748

②使用交叉熵特征
命令
python ffm_lgbEncoder_test.py --use_cross_entropy True --use_pos_ratio False
--embedding_size 4 --dropout_fm [0.3,0.3]
输出
WARNING:root:#params: 78570
WARNING:root:[1] train-auc=0.7860, valid-auc=0.7542 [10.2 s]
WARNING:root:[2] train-auc=0.8009, valid-auc=0.7553 [8.3 s]
WARNING:root:[3] train-auc=0.8082, valid-auc=0.7525 [8.2 s]
WARNING:root:[4] train-auc=0.8131, valid-auc=0.7495 [8.2 s]
WARNING:root:[5] train-auc=0.8172, valid-auc=0.7463 [8.2 s]
WARNING:root:[6] train-auc=0.8206, valid-auc=0.7445 [8.3 s]
WARNING:root:训练集logloss: 0.42371925
WARNING:root:训练集auc: 0.80090621
WARNING:root:验证集logloss: 0.45782202
WARNING:root:验证集auc: 0.75527196
WARNING:root:测试集logloss: 0.46911609
WARNING:root:测试集auc: 0.75448256
Time used: 59.441006660461426

③使用正例率特征
命令
python ffm_lgbEncoder_test.py --use_cross_entropy False --use_pos_ratio True
--embedding_size 4 --dropout_fm [0.5,0.3]
输出
WARNING:root:#params: 78570
WARNING:root:[1] train-auc=0.7816, valid-auc=0.7512 [10.2 s]
WARNING:root:[2] train-auc=0.7989, valid-auc=0.7555 [8.5 s]
WARNING:root:[3] train-auc=0.8075, valid-auc=0.7537 [8.5 s]
WARNING:root:[4] train-auc=0.8133, valid-auc=0.7508 [8.5 s]
WARNING:root:[5] train-auc=0.8182, valid-auc=0.7474 [8.5 s]
WARNING:root:[6] train-auc=0.8221, valid-auc=0.7452 [8.5 s]
WARNING:root:训练集logloss: 0.42544337
WARNING:root:训练集auc: 0.79889036
WARNING:root:验证集logloss: 0.45729884
WARNING:root:验证集auc: 0.75546344
WARNING:root:测试集logloss: 0.46864845
WARNING:root:测试集auc: 0.75459841
Time used: 61.04885411262512

④使用交叉熵特征和正例率特征
命令
python ffm_lgbEncoder_test.py --use_cross_entropy True --use_pos_ratio True
--embedding_size 2 --dropout_fm [0.3,0.1]
输出
WARNING:root:#params: 65786
WARNING:root:[1] train-auc=0.7769, valid-auc=0.7482 [22.1 s]
WARNING:root:[2] train-auc=0.7929, valid-auc=0.7547 [15.9 s]
WARNING:root:[3] train-auc=0.7995, valid-auc=0.7543 [15.8 s]
WARNING:root:[4] train-auc=0.8034, valid-auc=0.7533 [16.1 s]
WARNING:root:[5] train-auc=0.8064, valid-auc=0.7522 [15.8 s]
WARNING:root:[6] train-auc=0.8084, valid-auc=0.7516 [15.8 s]
WARNING:root:训练集logloss: 0.43078846
WARNING:root:训练集auc: 0.79293631
WARNING:root:验证集logloss: 0.45731161
WARNING:root:验证集auc: 0.75472665
WARNING:root:测试集logloss: 0.46764388
WARNING:root:测试集auc: 0.75508891
Time used: 112.45628190040588

##############################################################################
3、使用交叉熵特征和正例率特征，使用AFFM
3.1、在affm_tuning中进行调参
python affm_lgbEncoder_tuning.py --use_cross_entropy True --use_pos_ratio True
--attention_size_list [4,8] --embedding_size_list [4,8] --dropout_fm_0_list [0.5] --dropout_fm_1_list [0.3]
最优参数
'attention_size': 4, 'embedding_size': 4, 'dropout_fm': [0.5, 0.3]
最优效果
WARNING:root:训练集logloss: 0.43211987
WARNING:root:训练集auc: 0.79546638
WARNING:root:验证集logloss: 0.45540019
WARNING:root:验证集auc: 0.75524436
WARNING:root:测试集logloss: 0.46586333
WARNING:root:测试集auc: 0.75614338
Time used: 5512.050860404968

3.2、在affm_test中得到效果
命令
python affm_lgbEncoder_test.py --use_cross_entropy True --use_pos_ratio True
--attention_size 4 --embedding_size 4 --dropout_fm [0.5,0.3]
输出
WARNING:root:#params: 130326
WARNING:root:[1] train-auc=0.4900, valid-auc=0.4965 [50.5 s]
WARNING:root:[2] train-auc=0.7188, valid-auc=0.6963 [45.7 s]
WARNING:root:[3] train-auc=0.7618, valid-auc=0.7345 [45.9 s]
WARNING:root:[4] train-auc=0.7724, valid-auc=0.7435 [46.2 s]
WARNING:root:[5] train-auc=0.7776, valid-auc=0.7473 [45.5 s]
WARNING:root:[6] train-auc=0.7810, valid-auc=0.7493 [45.5 s]
WARNING:root:[7] train-auc=0.7838, valid-auc=0.7508 [45.8 s]
WARNING:root:[8] train-auc=0.7859, valid-auc=0.7518 [46.1 s]
WARNING:root:[9] train-auc=0.7875, valid-auc=0.7523 [45.7 s]
WARNING:root:[10] train-auc=0.7887, valid-auc=0.7529 [46.2 s]
WARNING:root:[11] train-auc=0.7900, valid-auc=0.7534 [45.9 s]
WARNING:root:[12] train-auc=0.7910, valid-auc=0.7537 [45.7 s]
WARNING:root:[13] train-auc=0.7920, valid-auc=0.7540 [45.3 s]
WARNING:root:[14] train-auc=0.7927, valid-auc=0.7542 [45.6 s]
WARNING:root:[15] train-auc=0.7934, valid-auc=0.7546 [46.0 s]
WARNING:root:[16] train-auc=0.7941, valid-auc=0.7545 [45.4 s]
WARNING:root:[17] train-auc=0.7946, valid-auc=0.7548 [45.4 s]
WARNING:root:[18] train-auc=0.7950, valid-auc=0.7549 [46.1 s]
WARNING:root:[19] train-auc=0.7955, valid-auc=0.7552 [45.8 s]
WARNING:root:[20] train-auc=0.7965, valid-auc=0.7551 [45.6 s]
WARNING:root:[21] train-auc=0.7979, valid-auc=0.7550 [45.8 s]
WARNING:root:[22] train-auc=0.7996, valid-auc=0.7548 [46.6 s]
WARNING:root:[23] train-auc=0.8018, valid-auc=0.7545 [46.2 s]
WARNING:root:训练集logloss: 0.43211987
WARNING:root:训练集auc: 0.79546638
WARNING:root:验证集logloss: 0.45540019
WARNING:root:验证集auc: 0.75524436
WARNING:root:测试集logloss: 0.46586333
WARNING:root:测试集auc: 0.75614338
Time used: 1069.461582183838

##############################################################################
使用xlearn在原始数据集上做一些对比实验，用于证明上面2个创新点的有效性
①LR
训练集logloss: 0.34308300874692754
训练集auc: 0.8933579243760199
验证集logloss: 0.4742282469084088
验证集auc: 0.7348169762941203
测试集logloss: 0.48667507340830946
测试集auc: 0.7333774138715082
②FM
训练集logloss: 0.3929992879350968
训练集auc: 0.8633462516088517
验证集logloss: 0.4620834437744992
验证集auc: 0.743588647118034
测试集logloss: 0.47202136593734395
测试集auc: 0.7476627877043716
③FFM
训练集logloss: 0.39977826753164863
训练集auc: 0.8570882233304955
验证集logloss: 0.46030402524751424
验证集auc: 0.7480056613437973
测试集logloss: 0.47115900221867285
测试集auc: 0.7521464614268657