WARNING:root:设置参数
WARNING:root:交叉验证
WARNING:root:调参2：降低过拟合
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
WARNING:root:调参3：降低过拟合
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
WARNING:root:调参4：降低过拟合
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 100
[LightGBM] [Info] Number of data: 40000, number of used features: 21
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
labelEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
WARNING:root:{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'learning_rate': 0.5, 'max_depth': -1, 'num_leaves': 80, 'max_bin': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.4, 'lambda_l2': 0.4, 'min_split_gain': 0.1}
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.429696 + 0.000585331
[2]	cv_agg's binary_logloss: 0.422821 + 0.000628347
[3]	cv_agg's binary_logloss: 0.420055 + 0.000443751
[4]	cv_agg's binary_logloss: 0.418841 + 0.000698972
[5]	cv_agg's binary_logloss: 0.41869 + 0.000905076
[6]	cv_agg's binary_logloss: 0.418839 + 0.00105483
[7]	cv_agg's binary_logloss: 0.419082 + 0.000950296
[8]	cv_agg's binary_logloss: 0.41923 + 0.000953965
[1]	cv_agg's binary_logloss: 0.429595 + 0.000785647
[2]	cv_agg's binary_logloss: 0.422647 + 0.00103155
[3]	cv_agg's binary_logloss: 0.41982 + 0.000711277
[4]	cv_agg's binary_logloss: 0.418574 + 0.000539722
[5]	cv_agg's binary_logloss: 0.418442 + 0.000759234
[6]	cv_agg's binary_logloss: 0.41834 + 0.000953538
[7]	cv_agg's binary_logloss: 0.418266 + 0.000713264
[8]	cv_agg's binary_logloss: 0.418472 + 0.000660185
[9]	cv_agg's binary_logloss: 0.418601 + 0.000583198
[10]	cv_agg's binary_logloss: 0.419041 + 0.000879115
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429553 + 0.000883901
[2]	cv_agg's binary_logloss: 0.422195 + 0.00106322
[3]	cv_agg's binary_logloss: 0.419587 + 0.000645118
[4]	cv_agg's binary_logloss: 0.4187 + 0.000714342
[5]	cv_agg's binary_logloss: 0.418251 + 0.000537867
[6]	cv_agg's binary_logloss: 0.418163 + 0.000320675
[7]	cv_agg's binary_logloss: 0.41817 + 0.000522633
[8]	cv_agg's binary_logloss: 0.418125 + 0.000271298
[9]	cv_agg's binary_logloss: 0.418194 + 0.00077864
[10]	cv_agg's binary_logloss: 0.41845 + 0.00101372
[11]	cv_agg's binary_logloss: 0.418786 + 0.000952299
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421602 + 0.00113094
[7]	cv_agg's binary_logloss: 0.421931 + 0.000963866
[8]	cv_agg's binary_logloss: 0.421897 + 0.00137853
[9]	cv_agg's binary_logloss: 0.422284 + 0.00155584
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421511 + 0.00105919
[7]	cv_agg's binary_logloss: 0.42167 + 0.00135338
[8]	cv_agg's binary_logloss: 0.421324 + 0.00136296
[9]	cv_agg's binary_logloss: 0.421748 + 0.00158927
[10]	cv_agg's binary_logloss: 0.421992 + 0.00162328
[11]	cv_agg's binary_logloss: 0.42267 + 0.00147341
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421511 + 0.00105919
[7]	cv_agg's binary_logloss: 0.42167 + 0.00135338
[8]	cv_agg's binary_logloss: 0.421324 + 0.00136296
[9]	cv_agg's binary_logloss: 0.421748 + 0.00158927
[10]	cv_agg's binary_logloss: 0.421992 + 0.00162328
[11]	cv_agg's binary_logloss: 0.422262 + 0.00162546
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421511 + 0.00105919
[7]	cv_agg's binary_logloss: 0.42167 + 0.00135338
[8]	cv_agg's binary_logloss: 0.421324 + 0.00136296
[9]	cv_agg's binary_logloss: 0.421748 + 0.00158927
[10]	cv_agg's binary_logloss: 0.421992 + 0.00162328
[11]	cv_agg's binary_logloss: 0.422262 + 0.00162546
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421511 + 0.00105919
[7]	cv_agg's binary_logloss: 0.42167 + 0.00135338
[8]	cv_agg's binary_logloss: 0.421324 + 0.00136296
[9]	cv_agg's binary_logloss: 0.421748 + 0.00158927
[10]	cv_agg's binary_logloss: 0.421992 + 0.00162328
[11]	cv_agg's binary_logloss: 0.422262 + 0.00162546
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421511 + 0.00105919
[7]	cv_agg's binary_logloss: 0.42167 + 0.00135338
[8]	cv_agg's binary_logloss: 0.421324 + 0.00136296
[9]	cv_agg's binary_logloss: 0.421748 + 0.00158927
[10]	cv_agg's binary_logloss: 0.421992 + 0.00162328
[11]	cv_agg's binary_logloss: 0.422262 + 0.00162546
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421511 + 0.00105919
[7]	cv_agg's binary_logloss: 0.42167 + 0.00135338
[8]	cv_agg's binary_logloss: 0.421324 + 0.00136296
[9]	cv_agg's binary_logloss: 0.421748 + 0.00158927
[10]	cv_agg's binary_logloss: 0.421992 + 0.00162328
[11]	cv_agg's binary_logloss: 0.422262 + 0.00162546
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421511 + 0.00105919
[7]	cv_agg's binary_logloss: 0.42167 + 0.00135338
[8]	cv_agg's binary_logloss: 0.421324 + 0.00136296
[9]	cv_agg's binary_logloss: 0.421748 + 0.00158927
[10]	cv_agg's binary_logloss: 0.421992 + 0.00162328
[11]	cv_agg's binary_logloss: 0.422262 + 0.00162546
[1]	cv_agg's binary_logloss: 0.435008 + 0.000301452
[2]	cv_agg's binary_logloss: 0.427336 + 0.00074371
[3]	cv_agg's binary_logloss: 0.423127 + 0.000811374
[4]	cv_agg's binary_logloss: 0.422036 + 0.000957049
[5]	cv_agg's binary_logloss: 0.421697 + 0.00130012
[6]	cv_agg's binary_logloss: 0.421511 + 0.00105919
[7]	cv_agg's binary_logloss: 0.42167 + 0.00135338
[8]	cv_agg's binary_logloss: 0.421324 + 0.00136296
[9]	cv_agg's binary_logloss: 0.421748 + 0.00158927
[10]	cv_agg's binary_logloss: 0.421992 + 0.00162328
[11]	cv_agg's binary_logloss: 0.422262 + 0.00162546
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420713 + 0.000557777
[7]	cv_agg's binary_logloss: 0.420623 + 0.000678344
[8]	cv_agg's binary_logloss: 0.420672 + 0.000775591
[9]	cv_agg's binary_logloss: 0.420948 + 0.000843863
[10]	cv_agg's binary_logloss: 0.421213 + 0.000817034
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420842 + 0.000540258
[7]	cv_agg's binary_logloss: 0.420579 + 0.000360076
[8]	cv_agg's binary_logloss: 0.420373 + 0.000620218
[9]	cv_agg's binary_logloss: 0.420466 + 0.000811598
[10]	cv_agg's binary_logloss: 0.420588 + 0.000922407
[11]	cv_agg's binary_logloss: 0.420563 + 0.00124754
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420842 + 0.000540258
[7]	cv_agg's binary_logloss: 0.420579 + 0.000360076
[8]	cv_agg's binary_logloss: 0.420373 + 0.000620218
[9]	cv_agg's binary_logloss: 0.420466 + 0.000811598
[10]	cv_agg's binary_logloss: 0.420588 + 0.000922407
[11]	cv_agg's binary_logloss: 0.420699 + 0.0007484
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420842 + 0.000540258
[7]	cv_agg's binary_logloss: 0.420579 + 0.000360076
[8]	cv_agg's binary_logloss: 0.420373 + 0.000620218
[9]	cv_agg's binary_logloss: 0.420466 + 0.000811598
[10]	cv_agg's binary_logloss: 0.420588 + 0.000922407
[11]	cv_agg's binary_logloss: 0.420699 + 0.0007484
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420842 + 0.000540258
[7]	cv_agg's binary_logloss: 0.420579 + 0.000360076
[8]	cv_agg's binary_logloss: 0.420373 + 0.000620218
[9]	cv_agg's binary_logloss: 0.420466 + 0.000811598
[10]	cv_agg's binary_logloss: 0.420588 + 0.000922407
[11]	cv_agg's binary_logloss: 0.420699 + 0.0007484
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420842 + 0.000540258
[7]	cv_agg's binary_logloss: 0.420579 + 0.000360076
[8]	cv_agg's binary_logloss: 0.420373 + 0.000620218
[9]	cv_agg's binary_logloss: 0.420466 + 0.000811598
[10]	cv_agg's binary_logloss: 0.420588 + 0.000922407
[11]	cv_agg's binary_logloss: 0.420699 + 0.0007484
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420842 + 0.000540258
[7]	cv_agg's binary_logloss: 0.420579 + 0.000360076
[8]	cv_agg's binary_logloss: 0.420373 + 0.000620218
[9]	cv_agg's binary_logloss: 0.420466 + 0.000811598
[10]	cv_agg's binary_logloss: 0.420588 + 0.000922407
[11]	cv_agg's binary_logloss: 0.420699 + 0.0007484
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420842 + 0.000540258
[7]	cv_agg's binary_logloss: 0.420579 + 0.000360076
[8]	cv_agg's binary_logloss: 0.420373 + 0.000620218
[9]	cv_agg's binary_logloss: 0.420466 + 0.000811598
[10]	cv_agg's binary_logloss: 0.420588 + 0.000922407
[11]	cv_agg's binary_logloss: 0.420699 + 0.0007484
[1]	cv_agg's binary_logloss: 0.434727 + 0.000439945
[2]	cv_agg's binary_logloss: 0.426725 + 0.00046915
[3]	cv_agg's binary_logloss: 0.422817 + 0.00041883
[4]	cv_agg's binary_logloss: 0.421483 + 0.000596299
[5]	cv_agg's binary_logloss: 0.421017 + 0.000635985
[6]	cv_agg's binary_logloss: 0.420842 + 0.000540258
[7]	cv_agg's binary_logloss: 0.420579 + 0.000360076
[8]	cv_agg's binary_logloss: 0.420373 + 0.000620218
[9]	cv_agg's binary_logloss: 0.420466 + 0.000811598
[10]	cv_agg's binary_logloss: 0.420588 + 0.000922407
[11]	cv_agg's binary_logloss: 0.420699 + 0.0007484
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.419943 + 0.00054309
[7]	cv_agg's binary_logloss: 0.420102 + 0.000557474
[8]	cv_agg's binary_logloss: 0.420216 + 0.000822921
[9]	cv_agg's binary_logloss: 0.420434 + 0.000818015
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.420156 + 0.000561642
[7]	cv_agg's binary_logloss: 0.419965 + 0.000796366
[8]	cv_agg's binary_logloss: 0.419738 + 0.000766249
[9]	cv_agg's binary_logloss: 0.419846 + 0.000683314
[10]	cv_agg's binary_logloss: 0.4202 + 0.000612347
[11]	cv_agg's binary_logloss: 0.420044 + 0.000927005
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.420156 + 0.000561642
[7]	cv_agg's binary_logloss: 0.419965 + 0.000796366
[8]	cv_agg's binary_logloss: 0.419738 + 0.000766249
[9]	cv_agg's binary_logloss: 0.419846 + 0.000683314
[10]	cv_agg's binary_logloss: 0.4202 + 0.000612347
[11]	cv_agg's binary_logloss: 0.420423 + 0.000756622
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.420156 + 0.000561642
[7]	cv_agg's binary_logloss: 0.419965 + 0.000796366
[8]	cv_agg's binary_logloss: 0.419738 + 0.000766249
[9]	cv_agg's binary_logloss: 0.419846 + 0.000683314
[10]	cv_agg's binary_logloss: 0.4202 + 0.000612347
[11]	cv_agg's binary_logloss: 0.420423 + 0.000756622
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.420156 + 0.000561642
[7]	cv_agg's binary_logloss: 0.419965 + 0.000796366
[8]	cv_agg's binary_logloss: 0.419738 + 0.000766249
[9]	cv_agg's binary_logloss: 0.419846 + 0.000683314
[10]	cv_agg's binary_logloss: 0.4202 + 0.000612347
[11]	cv_agg's binary_logloss: 0.420423 + 0.000756622
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.420156 + 0.000561642
[7]	cv_agg's binary_logloss: 0.419965 + 0.000796366
[8]	cv_agg's binary_logloss: 0.419738 + 0.000766249
[9]	cv_agg's binary_logloss: 0.419846 + 0.000683314
[10]	cv_agg's binary_logloss: 0.4202 + 0.000612347
[11]	cv_agg's binary_logloss: 0.420423 + 0.000756622
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.420156 + 0.000561642
[7]	cv_agg's binary_logloss: 0.419965 + 0.000796366
[8]	cv_agg's binary_logloss: 0.419738 + 0.000766249
[9]	cv_agg's binary_logloss: 0.419846 + 0.000683314
[10]	cv_agg's binary_logloss: 0.4202 + 0.000612347
[11]	cv_agg's binary_logloss: 0.420423 + 0.000756622
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.420156 + 0.000561642
[7]	cv_agg's binary_logloss: 0.419965 + 0.000796366
[8]	cv_agg's binary_logloss: 0.419738 + 0.000766249
[9]	cv_agg's binary_logloss: 0.419846 + 0.000683314
[10]	cv_agg's binary_logloss: 0.4202 + 0.000612347
[11]	cv_agg's binary_logloss: 0.420423 + 0.000756622
[1]	cv_agg's binary_logloss: 0.434777 + 0.000962556
[2]	cv_agg's binary_logloss: 0.426549 + 0.000934575
[3]	cv_agg's binary_logloss: 0.422254 + 0.000775071
[4]	cv_agg's binary_logloss: 0.420917 + 0.000586982
[5]	cv_agg's binary_logloss: 0.420133 + 0.000632728
[6]	cv_agg's binary_logloss: 0.420156 + 0.000561642
[7]	cv_agg's binary_logloss: 0.419965 + 0.000796366
[8]	cv_agg's binary_logloss: 0.419738 + 0.000766249
[9]	cv_agg's binary_logloss: 0.419846 + 0.000683314
[10]	cv_agg's binary_logloss: 0.4202 + 0.000612347
[11]	cv_agg's binary_logloss: 0.420423 + 0.000756622
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420034 + 0.000736113
[7]	cv_agg's binary_logloss: 0.419731 + 0.00092932
[8]	cv_agg's binary_logloss: 0.419524 + 0.000911594
[9]	cv_agg's binary_logloss: 0.419413 + 0.00100956
[10]	cv_agg's binary_logloss: 0.41944 + 0.000713081
[11]	cv_agg's binary_logloss: 0.419629 + 0.000862321
[12]	cv_agg's binary_logloss: 0.420006 + 0.00107243
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420067 + 0.000623798
[7]	cv_agg's binary_logloss: 0.419963 + 0.00093575
[8]	cv_agg's binary_logloss: 0.419793 + 0.000833887
[9]	cv_agg's binary_logloss: 0.41995 + 0.00111402
[10]	cv_agg's binary_logloss: 0.420181 + 0.00126351
[11]	cv_agg's binary_logloss: 0.420212 + 0.00138192
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420067 + 0.000623798
[7]	cv_agg's binary_logloss: 0.419963 + 0.00093575
[8]	cv_agg's binary_logloss: 0.419793 + 0.000833887
[9]	cv_agg's binary_logloss: 0.41995 + 0.00111402
[10]	cv_agg's binary_logloss: 0.420181 + 0.00126351
[11]	cv_agg's binary_logloss: 0.420194 + 0.00124884
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420067 + 0.000623798
[7]	cv_agg's binary_logloss: 0.419963 + 0.00093575
[8]	cv_agg's binary_logloss: 0.419793 + 0.000833887
[9]	cv_agg's binary_logloss: 0.41995 + 0.00111402
[10]	cv_agg's binary_logloss: 0.420181 + 0.00126351
[11]	cv_agg's binary_logloss: 0.420194 + 0.00124884
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420067 + 0.000623798
[7]	cv_agg's binary_logloss: 0.419963 + 0.00093575
[8]	cv_agg's binary_logloss: 0.419793 + 0.000833887
[9]	cv_agg's binary_logloss: 0.41995 + 0.00111402
[10]	cv_agg's binary_logloss: 0.420181 + 0.00126351
[11]	cv_agg's binary_logloss: 0.420194 + 0.00124884
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420067 + 0.000623798
[7]	cv_agg's binary_logloss: 0.419963 + 0.00093575
[8]	cv_agg's binary_logloss: 0.419793 + 0.000833887
[9]	cv_agg's binary_logloss: 0.41995 + 0.00111402
[10]	cv_agg's binary_logloss: 0.420181 + 0.00126351
[11]	cv_agg's binary_logloss: 0.420194 + 0.00124884
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420067 + 0.000623798
[7]	cv_agg's binary_logloss: 0.419963 + 0.00093575
[8]	cv_agg's binary_logloss: 0.419793 + 0.000833887
[9]	cv_agg's binary_logloss: 0.41995 + 0.00111402
[10]	cv_agg's binary_logloss: 0.420181 + 0.00126351
[11]	cv_agg's binary_logloss: 0.420194 + 0.00124884
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420067 + 0.000623798
[7]	cv_agg's binary_logloss: 0.419963 + 0.00093575
[8]	cv_agg's binary_logloss: 0.419793 + 0.000833887
[9]	cv_agg's binary_logloss: 0.41995 + 0.00111402
[10]	cv_agg's binary_logloss: 0.420181 + 0.00126351
[11]	cv_agg's binary_logloss: 0.420194 + 0.00124884
[1]	cv_agg's binary_logloss: 0.434743 + 0.00100697
[2]	cv_agg's binary_logloss: 0.426602 + 0.00074482
[3]	cv_agg's binary_logloss: 0.42216 + 0.00055846
[4]	cv_agg's binary_logloss: 0.420892 + 0.000743491
[5]	cv_agg's binary_logloss: 0.420154 + 0.000750172
[6]	cv_agg's binary_logloss: 0.420067 + 0.000623798
[7]	cv_agg's binary_logloss: 0.419963 + 0.00093575
[8]	cv_agg's binary_logloss: 0.419793 + 0.000833887
[9]	cv_agg's binary_logloss: 0.41995 + 0.00111402
[10]	cv_agg's binary_logloss: 0.420181 + 0.00126351
[11]	cv_agg's binary_logloss: 0.420194 + 0.00124884
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.434341 + 0.000938907
[2]	cv_agg's binary_logloss: 0.426031 + 0.000559142
[3]	cv_agg's binary_logloss: 0.421939 + 0.000595162
[4]	cv_agg's binary_logloss: 0.420524 + 0.000788971
[5]	cv_agg's binary_logloss: 0.419701 + 0.000730197
[6]	cv_agg's binary_logloss: 0.419541 + 0.000885293
[7]	cv_agg's binary_logloss: 0.419271 + 0.000887476
[8]	cv_agg's binary_logloss: 0.419243 + 0.000826933
[9]	cv_agg's binary_logloss: 0.419362 + 0.00102625
[10]	cv_agg's binary_logloss: 0.419395 + 0.000936171
[11]	cv_agg's binary_logloss: 0.419551 + 0.000885026
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.419337 + 0.000748501
[7]	cv_agg's binary_logloss: 0.419896 + 0.000534394
[8]	cv_agg's binary_logloss: 0.420365 + 0.000323852
[9]	cv_agg's binary_logloss: 0.420784 + 0.0005891
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.420014 + 0.0009951
[7]	cv_agg's binary_logloss: 0.420323 + 0.000827398
[8]	cv_agg's binary_logloss: 0.420814 + 0.00073781
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.420014 + 0.0009951
[7]	cv_agg's binary_logloss: 0.420323 + 0.000827398
[8]	cv_agg's binary_logloss: 0.420814 + 0.00073781
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.420014 + 0.0009951
[7]	cv_agg's binary_logloss: 0.420323 + 0.000827398
[8]	cv_agg's binary_logloss: 0.420814 + 0.00073781
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.420014 + 0.0009951
[7]	cv_agg's binary_logloss: 0.420323 + 0.000827398
[8]	cv_agg's binary_logloss: 0.420814 + 0.00073781
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.420014 + 0.0009951
[7]	cv_agg's binary_logloss: 0.420323 + 0.000827398
[8]	cv_agg's binary_logloss: 0.420814 + 0.00073781
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.420014 + 0.0009951
[7]	cv_agg's binary_logloss: 0.420323 + 0.000827398
[8]	cv_agg's binary_logloss: 0.420814 + 0.00073781
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.420014 + 0.0009951
[7]	cv_agg's binary_logloss: 0.420323 + 0.000827398
[8]	cv_agg's binary_logloss: 0.420814 + 0.00073781
[1]	cv_agg's binary_logloss: 0.431667 + 0.000979712
[2]	cv_agg's binary_logloss: 0.424568 + 0.000910442
[3]	cv_agg's binary_logloss: 0.421467 + 0.000935657
[4]	cv_agg's binary_logloss: 0.420242 + 0.000764733
[5]	cv_agg's binary_logloss: 0.419962 + 0.00099904
[6]	cv_agg's binary_logloss: 0.420014 + 0.0009951
[7]	cv_agg's binary_logloss: 0.420323 + 0.000827398
[8]	cv_agg's binary_logloss: 0.420814 + 0.00073781
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419289 + 0.000212702
[7]	cv_agg's binary_logloss: 0.419301 + 0.000378396
[8]	cv_agg's binary_logloss: 0.419797 + 0.000322302
[9]	cv_agg's binary_logloss: 0.420025 + 0.000595046
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419758 + 0.000183374
[7]	cv_agg's binary_logloss: 0.42005 + 0.000461314
[8]	cv_agg's binary_logloss: 0.420538 + 0.000581974
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419758 + 0.000183374
[7]	cv_agg's binary_logloss: 0.42005 + 0.000461314
[8]	cv_agg's binary_logloss: 0.420538 + 0.000581974
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419758 + 0.000183374
[7]	cv_agg's binary_logloss: 0.42005 + 0.000461314
[8]	cv_agg's binary_logloss: 0.420538 + 0.000581974
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419758 + 0.000183374
[7]	cv_agg's binary_logloss: 0.42005 + 0.000461314
[8]	cv_agg's binary_logloss: 0.420538 + 0.000581974
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419758 + 0.000183374
[7]	cv_agg's binary_logloss: 0.42005 + 0.000461314
[8]	cv_agg's binary_logloss: 0.420538 + 0.000581974
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419758 + 0.000183374
[7]	cv_agg's binary_logloss: 0.42005 + 0.000461314
[8]	cv_agg's binary_logloss: 0.420538 + 0.000581974
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419758 + 0.000183374
[7]	cv_agg's binary_logloss: 0.42005 + 0.000461314
[8]	cv_agg's binary_logloss: 0.420538 + 0.000581974
[1]	cv_agg's binary_logloss: 0.431581 + 0.000410885
[2]	cv_agg's binary_logloss: 0.42442 + 0.000675408
[3]	cv_agg's binary_logloss: 0.421395 + 0.000193578
[4]	cv_agg's binary_logloss: 0.419961 + 0.000246414
[5]	cv_agg's binary_logloss: 0.41952 + 0.000258117
[6]	cv_agg's binary_logloss: 0.419758 + 0.000183374
[7]	cv_agg's binary_logloss: 0.42005 + 0.000461314
[8]	cv_agg's binary_logloss: 0.420538 + 0.000581974
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419578 + 0.00108954
[7]	cv_agg's binary_logloss: 0.419327 + 0.00106795
[8]	cv_agg's binary_logloss: 0.419488 + 0.000952359
[9]	cv_agg's binary_logloss: 0.419814 + 0.00115525
[10]	cv_agg's binary_logloss: 0.420073 + 0.00137894
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419725 + 0.00083934
[7]	cv_agg's binary_logloss: 0.419548 + 0.000848625
[8]	cv_agg's binary_logloss: 0.419815 + 0.000722423
[9]	cv_agg's binary_logloss: 0.419906 + 0.000764153
[10]	cv_agg's binary_logloss: 0.41998 + 0.00091216
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419725 + 0.00083934
[7]	cv_agg's binary_logloss: 0.419548 + 0.000848625
[8]	cv_agg's binary_logloss: 0.419815 + 0.000722423
[9]	cv_agg's binary_logloss: 0.419906 + 0.000764153
[10]	cv_agg's binary_logloss: 0.41998 + 0.00091216
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419725 + 0.00083934
[7]	cv_agg's binary_logloss: 0.419548 + 0.000848625
[8]	cv_agg's binary_logloss: 0.419815 + 0.000722423
[9]	cv_agg's binary_logloss: 0.419906 + 0.000764153
[10]	cv_agg's binary_logloss: 0.41998 + 0.00091216
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419725 + 0.00083934
[7]	cv_agg's binary_logloss: 0.419548 + 0.000848625
[8]	cv_agg's binary_logloss: 0.419815 + 0.000722423
[9]	cv_agg's binary_logloss: 0.419906 + 0.000764153
[10]	cv_agg's binary_logloss: 0.41998 + 0.00091216
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419725 + 0.00083934
[7]	cv_agg's binary_logloss: 0.419548 + 0.000848625
[8]	cv_agg's binary_logloss: 0.419815 + 0.000722423
[9]	cv_agg's binary_logloss: 0.419906 + 0.000764153
[10]	cv_agg's binary_logloss: 0.41998 + 0.00091216
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419725 + 0.00083934
[7]	cv_agg's binary_logloss: 0.419548 + 0.000848625
[8]	cv_agg's binary_logloss: 0.419815 + 0.000722423
[9]	cv_agg's binary_logloss: 0.419906 + 0.000764153
[10]	cv_agg's binary_logloss: 0.41998 + 0.00091216
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419725 + 0.00083934
[7]	cv_agg's binary_logloss: 0.419548 + 0.000848625
[8]	cv_agg's binary_logloss: 0.419815 + 0.000722423
[9]	cv_agg's binary_logloss: 0.419906 + 0.000764153
[10]	cv_agg's binary_logloss: 0.41998 + 0.00091216
[1]	cv_agg's binary_logloss: 0.431434 + 0.000849268
[2]	cv_agg's binary_logloss: 0.424229 + 0.000964958
[3]	cv_agg's binary_logloss: 0.421513 + 0.000968047
[4]	cv_agg's binary_logloss: 0.420202 + 0.00119412
[5]	cv_agg's binary_logloss: 0.419677 + 0.00110013
[6]	cv_agg's binary_logloss: 0.419725 + 0.00083934
[7]	cv_agg's binary_logloss: 0.419548 + 0.000848625
[8]	cv_agg's binary_logloss: 0.419815 + 0.000722423
[9]	cv_agg's binary_logloss: 0.419906 + 0.000764153
[10]	cv_agg's binary_logloss: 0.41998 + 0.00091216
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418462 + 0.000484485
[7]	cv_agg's binary_logloss: 0.418371 + 0.000737081
[8]	cv_agg's binary_logloss: 0.41868 + 0.000795719
[9]	cv_agg's binary_logloss: 0.418943 + 0.00102005
[10]	cv_agg's binary_logloss: 0.419192 + 0.000784949
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418578 + 0.000604691
[7]	cv_agg's binary_logloss: 0.418644 + 0.000580535
[8]	cv_agg's binary_logloss: 0.418742 + 0.000553805
[9]	cv_agg's binary_logloss: 0.418924 + 0.000452633
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418578 + 0.000604691
[7]	cv_agg's binary_logloss: 0.418644 + 0.000580535
[8]	cv_agg's binary_logloss: 0.418742 + 0.000553805
[9]	cv_agg's binary_logloss: 0.418924 + 0.000452633
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418578 + 0.000604691
[7]	cv_agg's binary_logloss: 0.418644 + 0.000580535
[8]	cv_agg's binary_logloss: 0.418742 + 0.000553805
[9]	cv_agg's binary_logloss: 0.418924 + 0.000452633
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418578 + 0.000604691
[7]	cv_agg's binary_logloss: 0.418644 + 0.000580535
[8]	cv_agg's binary_logloss: 0.418742 + 0.000553805
[9]	cv_agg's binary_logloss: 0.418924 + 0.000452633
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418578 + 0.000604691
[7]	cv_agg's binary_logloss: 0.418644 + 0.000580535
[8]	cv_agg's binary_logloss: 0.418742 + 0.000553805
[9]	cv_agg's binary_logloss: 0.418924 + 0.000452633
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418578 + 0.000604691
[7]	cv_agg's binary_logloss: 0.418644 + 0.000580535
[8]	cv_agg's binary_logloss: 0.418742 + 0.000553805
[9]	cv_agg's binary_logloss: 0.418924 + 0.000452633
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418578 + 0.000604691
[7]	cv_agg's binary_logloss: 0.418644 + 0.000580535
[8]	cv_agg's binary_logloss: 0.418742 + 0.000553805
[9]	cv_agg's binary_logloss: 0.418924 + 0.000452633
[1]	cv_agg's binary_logloss: 0.431028 + 0.00059101
[2]	cv_agg's binary_logloss: 0.424004 + 0.00047287
[3]	cv_agg's binary_logloss: 0.420916 + 0.000572293
[4]	cv_agg's binary_logloss: 0.419395 + 0.00091485
[5]	cv_agg's binary_logloss: 0.418696 + 0.000587762
[6]	cv_agg's binary_logloss: 0.418578 + 0.000604691
[7]	cv_agg's binary_logloss: 0.418644 + 0.000580535
[8]	cv_agg's binary_logloss: 0.418742 + 0.000553805
[9]	cv_agg's binary_logloss: 0.418924 + 0.000452633
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.431192 + 0.000430075
[2]	cv_agg's binary_logloss: 0.42354 + 0.000468352
[3]	cv_agg's binary_logloss: 0.420019 + 0.000695767
[4]	cv_agg's binary_logloss: 0.418336 + 0.000833137
[5]	cv_agg's binary_logloss: 0.417961 + 0.000733944
[6]	cv_agg's binary_logloss: 0.418271 + 0.000731989
[7]	cv_agg's binary_logloss: 0.418613 + 0.000826931
[8]	cv_agg's binary_logloss: 0.418676 + 0.000913022
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419215 + 0.00112301
[7]	cv_agg's binary_logloss: 0.419372 + 0.000997418
[8]	cv_agg's binary_logloss: 0.420052 + 0.000707263
[9]	cv_agg's binary_logloss: 0.420842 + 0.00104597
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419793 + 0.00111137
[7]	cv_agg's binary_logloss: 0.420224 + 0.00134009
[8]	cv_agg's binary_logloss: 0.420737 + 0.00124313
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419793 + 0.00111137
[7]	cv_agg's binary_logloss: 0.420224 + 0.00134009
[8]	cv_agg's binary_logloss: 0.420737 + 0.00124313
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419793 + 0.00111137
[7]	cv_agg's binary_logloss: 0.420224 + 0.00134009
[8]	cv_agg's binary_logloss: 0.420737 + 0.00124313
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419793 + 0.00111137
[7]	cv_agg's binary_logloss: 0.420224 + 0.00134009
[8]	cv_agg's binary_logloss: 0.420737 + 0.00124313
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419793 + 0.00111137
[7]	cv_agg's binary_logloss: 0.420224 + 0.00134009
[8]	cv_agg's binary_logloss: 0.420737 + 0.00124313
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419793 + 0.00111137
[7]	cv_agg's binary_logloss: 0.420224 + 0.00134009
[8]	cv_agg's binary_logloss: 0.420737 + 0.00124313
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419793 + 0.00111137
[7]	cv_agg's binary_logloss: 0.420224 + 0.00134009
[8]	cv_agg's binary_logloss: 0.420737 + 0.00124313
[1]	cv_agg's binary_logloss: 0.431056 + 0.000150928
[2]	cv_agg's binary_logloss: 0.423769 + 0.000372911
[3]	cv_agg's binary_logloss: 0.420729 + 0.000759993
[4]	cv_agg's binary_logloss: 0.419581 + 0.00110281
[5]	cv_agg's binary_logloss: 0.419553 + 0.00111489
[6]	cv_agg's binary_logloss: 0.419793 + 0.00111137
[7]	cv_agg's binary_logloss: 0.420224 + 0.00134009
[8]	cv_agg's binary_logloss: 0.420737 + 0.00124313
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.419018 + 0.000938971
[7]	cv_agg's binary_logloss: 0.419244 + 0.000387869
[8]	cv_agg's binary_logloss: 0.419569 + 0.000293022
[9]	cv_agg's binary_logloss: 0.419707 + 0.000581473
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.41922 + 0.000629491
[7]	cv_agg's binary_logloss: 0.419389 + 0.000451698
[8]	cv_agg's binary_logloss: 0.419957 + 0.000255192
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.41922 + 0.000629491
[7]	cv_agg's binary_logloss: 0.419389 + 0.000451698
[8]	cv_agg's binary_logloss: 0.419957 + 0.000255192
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.41922 + 0.000629491
[7]	cv_agg's binary_logloss: 0.419389 + 0.000451698
[8]	cv_agg's binary_logloss: 0.419957 + 0.000255192
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.41922 + 0.000629491
[7]	cv_agg's binary_logloss: 0.419389 + 0.000451698
[8]	cv_agg's binary_logloss: 0.419957 + 0.000255192
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.41922 + 0.000629491
[7]	cv_agg's binary_logloss: 0.419389 + 0.000451698
[8]	cv_agg's binary_logloss: 0.419957 + 0.000255192
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.41922 + 0.000629491
[7]	cv_agg's binary_logloss: 0.419389 + 0.000451698
[8]	cv_agg's binary_logloss: 0.419957 + 0.000255192
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.41922 + 0.000629491
[7]	cv_agg's binary_logloss: 0.419389 + 0.000451698
[8]	cv_agg's binary_logloss: 0.419957 + 0.000255192
[1]	cv_agg's binary_logloss: 0.430712 + 0.000434439
[2]	cv_agg's binary_logloss: 0.423267 + 0.000452303
[3]	cv_agg's binary_logloss: 0.420566 + 0.000628893
[4]	cv_agg's binary_logloss: 0.419321 + 0.000562017
[5]	cv_agg's binary_logloss: 0.419039 + 0.000772835
[6]	cv_agg's binary_logloss: 0.41922 + 0.000629491
[7]	cv_agg's binary_logloss: 0.419389 + 0.000451698
[8]	cv_agg's binary_logloss: 0.419957 + 0.000255192
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.41864 + 0.00136234
[7]	cv_agg's binary_logloss: 0.418936 + 0.00127518
[8]	cv_agg's binary_logloss: 0.419271 + 0.000913316
[9]	cv_agg's binary_logloss: 0.419334 + 0.000739362
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.419187 + 0.00100503
[7]	cv_agg's binary_logloss: 0.419419 + 0.000974529
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.419187 + 0.00100503
[7]	cv_agg's binary_logloss: 0.419419 + 0.000974529
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.419187 + 0.00100503
[7]	cv_agg's binary_logloss: 0.419419 + 0.000974529
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.419187 + 0.00100503
[7]	cv_agg's binary_logloss: 0.419419 + 0.000974529
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.419187 + 0.00100503
[7]	cv_agg's binary_logloss: 0.419419 + 0.000974529
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.419187 + 0.00100503
[7]	cv_agg's binary_logloss: 0.419419 + 0.000974529
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.419187 + 0.00100503
[7]	cv_agg's binary_logloss: 0.419419 + 0.000974529
[1]	cv_agg's binary_logloss: 0.430695 + 0.00107174
[2]	cv_agg's binary_logloss: 0.42325 + 0.000801396
[3]	cv_agg's binary_logloss: 0.420268 + 0.000879804
[4]	cv_agg's binary_logloss: 0.418819 + 0.00094221
[5]	cv_agg's binary_logloss: 0.418896 + 0.00102519
[6]	cv_agg's binary_logloss: 0.419187 + 0.00100503
[7]	cv_agg's binary_logloss: 0.419419 + 0.000974529
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418028 + 0.000828583
[7]	cv_agg's binary_logloss: 0.417828 + 0.000493333
[8]	cv_agg's binary_logloss: 0.418186 + 0.000664962
[9]	cv_agg's binary_logloss: 0.418132 + 0.000649006
[10]	cv_agg's binary_logloss: 0.418448 + 0.000762698
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418024 + 0.000689611
[7]	cv_agg's binary_logloss: 0.418115 + 0.000343665
[8]	cv_agg's binary_logloss: 0.418409 + 0.00042596
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418024 + 0.000689611
[7]	cv_agg's binary_logloss: 0.418115 + 0.000343665
[8]	cv_agg's binary_logloss: 0.418409 + 0.00042596
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418024 + 0.000689611
[7]	cv_agg's binary_logloss: 0.418115 + 0.000343665
[8]	cv_agg's binary_logloss: 0.418409 + 0.00042596
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418024 + 0.000689611
[7]	cv_agg's binary_logloss: 0.418115 + 0.000343665
[8]	cv_agg's binary_logloss: 0.418409 + 0.00042596
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418024 + 0.000689611
[7]	cv_agg's binary_logloss: 0.418115 + 0.000343665
[8]	cv_agg's binary_logloss: 0.418409 + 0.00042596
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418024 + 0.000689611
[7]	cv_agg's binary_logloss: 0.418115 + 0.000343665
[8]	cv_agg's binary_logloss: 0.418409 + 0.00042596
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418024 + 0.000689611
[7]	cv_agg's binary_logloss: 0.418115 + 0.000343665
[8]	cv_agg's binary_logloss: 0.418409 + 0.00042596
[1]	cv_agg's binary_logloss: 0.430411 + 0.0011118
[2]	cv_agg's binary_logloss: 0.423008 + 0.000636052
[3]	cv_agg's binary_logloss: 0.419953 + 0.000514702
[4]	cv_agg's binary_logloss: 0.418527 + 0.000587589
[5]	cv_agg's binary_logloss: 0.418015 + 0.0008304
[6]	cv_agg's binary_logloss: 0.418024 + 0.000689611
[7]	cv_agg's binary_logloss: 0.418115 + 0.000343665
[8]	cv_agg's binary_logloss: 0.418409 + 0.00042596
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.420291 + 0.000936968
[7]	cv_agg's binary_logloss: 0.420828 + 0.000790563
[8]	cv_agg's binary_logloss: 0.421316 + 0.000918835
[9]	cv_agg's binary_logloss: 0.421901 + 0.000861228
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.42067 + 0.00115532
[7]	cv_agg's binary_logloss: 0.421288 + 0.00121348
[8]	cv_agg's binary_logloss: 0.421787 + 0.00132761
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.42067 + 0.00115532
[7]	cv_agg's binary_logloss: 0.421288 + 0.00121348
[8]	cv_agg's binary_logloss: 0.421787 + 0.00132761
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.42067 + 0.00115532
[7]	cv_agg's binary_logloss: 0.421288 + 0.00121348
[8]	cv_agg's binary_logloss: 0.421787 + 0.00132761
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.42067 + 0.00115532
[7]	cv_agg's binary_logloss: 0.421288 + 0.00121348
[8]	cv_agg's binary_logloss: 0.421787 + 0.00132761
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.42067 + 0.00115532
[7]	cv_agg's binary_logloss: 0.421288 + 0.00121348
[8]	cv_agg's binary_logloss: 0.421787 + 0.00132761
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.42067 + 0.00115532
[7]	cv_agg's binary_logloss: 0.421288 + 0.00121348
[8]	cv_agg's binary_logloss: 0.421787 + 0.00132761
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.42067 + 0.00115532
[7]	cv_agg's binary_logloss: 0.421288 + 0.00121348
[8]	cv_agg's binary_logloss: 0.421787 + 0.00132761
[1]	cv_agg's binary_logloss: 0.430967 + 0.000231563
[2]	cv_agg's binary_logloss: 0.423799 + 0.000319512
[3]	cv_agg's binary_logloss: 0.421847 + 0.000340161
[4]	cv_agg's binary_logloss: 0.420514 + 0.0004909
[5]	cv_agg's binary_logloss: 0.420352 + 0.000754914
[6]	cv_agg's binary_logloss: 0.42067 + 0.00115532
[7]	cv_agg's binary_logloss: 0.421288 + 0.00121348
[8]	cv_agg's binary_logloss: 0.421787 + 0.00132761
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419505 + 0.000602961
[7]	cv_agg's binary_logloss: 0.42006 + 0.000688435
[8]	cv_agg's binary_logloss: 0.420786 + 0.00067392
[9]	cv_agg's binary_logloss: 0.421364 + 0.000746046
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419925 + 0.000655628
[7]	cv_agg's binary_logloss: 0.420207 + 0.000964607
[8]	cv_agg's binary_logloss: 0.420578 + 0.000679441
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419925 + 0.000655628
[7]	cv_agg's binary_logloss: 0.420207 + 0.000964607
[8]	cv_agg's binary_logloss: 0.420578 + 0.000679441
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419925 + 0.000655628
[7]	cv_agg's binary_logloss: 0.420207 + 0.000964607
[8]	cv_agg's binary_logloss: 0.420578 + 0.000679441
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419925 + 0.000655628
[7]	cv_agg's binary_logloss: 0.420207 + 0.000964607
[8]	cv_agg's binary_logloss: 0.420578 + 0.000679441
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419925 + 0.000655628
[7]	cv_agg's binary_logloss: 0.420207 + 0.000964607
[8]	cv_agg's binary_logloss: 0.420578 + 0.000679441
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419925 + 0.000655628
[7]	cv_agg's binary_logloss: 0.420207 + 0.000964607
[8]	cv_agg's binary_logloss: 0.420578 + 0.000679441
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419925 + 0.000655628
[7]	cv_agg's binary_logloss: 0.420207 + 0.000964607
[8]	cv_agg's binary_logloss: 0.420578 + 0.000679441
[1]	cv_agg's binary_logloss: 0.431019 + 0.000386676
[2]	cv_agg's binary_logloss: 0.423319 + 0.000259565
[3]	cv_agg's binary_logloss: 0.421018 + 9.04083e-05
[4]	cv_agg's binary_logloss: 0.41992 + 0.000342304
[5]	cv_agg's binary_logloss: 0.419761 + 0.000548087
[6]	cv_agg's binary_logloss: 0.419925 + 0.000655628
[7]	cv_agg's binary_logloss: 0.420207 + 0.000964607
[8]	cv_agg's binary_logloss: 0.420578 + 0.000679441
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419195 + 0.00136012
[7]	cv_agg's binary_logloss: 0.419693 + 0.00139659
[8]	cv_agg's binary_logloss: 0.419859 + 0.00114723
[9]	cv_agg's binary_logloss: 0.419939 + 0.00134333
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419562 + 0.00103824
[7]	cv_agg's binary_logloss: 0.419854 + 0.00105198
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419562 + 0.00103824
[7]	cv_agg's binary_logloss: 0.419854 + 0.00105198
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419562 + 0.00103824
[7]	cv_agg's binary_logloss: 0.419854 + 0.00105198
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419562 + 0.00103824
[7]	cv_agg's binary_logloss: 0.419854 + 0.00105198
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419562 + 0.00103824
[7]	cv_agg's binary_logloss: 0.419854 + 0.00105198
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419562 + 0.00103824
[7]	cv_agg's binary_logloss: 0.419854 + 0.00105198
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419562 + 0.00103824
[7]	cv_agg's binary_logloss: 0.419854 + 0.00105198
[1]	cv_agg's binary_logloss: 0.430696 + 0.00097962
[2]	cv_agg's binary_logloss: 0.423329 + 0.00104778
[3]	cv_agg's binary_logloss: 0.421028 + 0.00110267
[4]	cv_agg's binary_logloss: 0.419555 + 0.00107932
[5]	cv_agg's binary_logloss: 0.419722 + 0.00119753
[6]	cv_agg's binary_logloss: 0.419562 + 0.00103824
[7]	cv_agg's binary_logloss: 0.419854 + 0.00105198
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.418178 + 0.000731779
[7]	cv_agg's binary_logloss: 0.418222 + 0.000621812
[8]	cv_agg's binary_logloss: 0.418581 + 0.000806633
[9]	cv_agg's binary_logloss: 0.418761 + 0.000819307
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.419151 + 0.00058084
[7]	cv_agg's binary_logloss: 0.419127 + 0.000597731
[8]	cv_agg's binary_logloss: 0.41958 + 0.000873124
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.419151 + 0.00058084
[7]	cv_agg's binary_logloss: 0.419127 + 0.000597731
[8]	cv_agg's binary_logloss: 0.41958 + 0.000873124
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.419151 + 0.00058084
[7]	cv_agg's binary_logloss: 0.419127 + 0.000597731
[8]	cv_agg's binary_logloss: 0.41958 + 0.000873124
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.419151 + 0.00058084
[7]	cv_agg's binary_logloss: 0.419127 + 0.000597731
[8]	cv_agg's binary_logloss: 0.41958 + 0.000873124
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.419151 + 0.00058084
[7]	cv_agg's binary_logloss: 0.419127 + 0.000597731
[8]	cv_agg's binary_logloss: 0.41958 + 0.000873124
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.419151 + 0.00058084
[7]	cv_agg's binary_logloss: 0.419127 + 0.000597731
[8]	cv_agg's binary_logloss: 0.41958 + 0.000873124
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.419151 + 0.00058084
[7]	cv_agg's binary_logloss: 0.419127 + 0.000597731
[8]	cv_agg's binary_logloss: 0.41958 + 0.000873124
[1]	cv_agg's binary_logloss: 0.430244 + 0.00084541
[2]	cv_agg's binary_logloss: 0.42313 + 0.000446467
[3]	cv_agg's binary_logloss: 0.420184 + 0.000596406
[4]	cv_agg's binary_logloss: 0.418891 + 0.00068478
[5]	cv_agg's binary_logloss: 0.41888 + 0.000425045
[6]	cv_agg's binary_logloss: 0.419151 + 0.00058084
[7]	cv_agg's binary_logloss: 0.419127 + 0.000597731
[8]	cv_agg's binary_logloss: 0.41958 + 0.000873124
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.430204 + 0.00102868
[2]	cv_agg's binary_logloss: 0.422671 + 0.000618587
[3]	cv_agg's binary_logloss: 0.419882 + 0.000418257
[4]	cv_agg's binary_logloss: 0.418232 + 0.000582944
[5]	cv_agg's binary_logloss: 0.417894 + 0.000696461
[6]	cv_agg's binary_logloss: 0.41798 + 0.000591516
[7]	cv_agg's binary_logloss: 0.418089 + 0.000634263
[8]	cv_agg's binary_logloss: 0.418503 + 0.000726717
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.42071 + 0.000513554
[7]	cv_agg's binary_logloss: 0.421438 + 0.000110946
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.420857 + 0.000831134
[7]	cv_agg's binary_logloss: 0.421261 + 0.000866894
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.420857 + 0.000831134
[7]	cv_agg's binary_logloss: 0.421261 + 0.000866894
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.420857 + 0.000831134
[7]	cv_agg's binary_logloss: 0.421261 + 0.000866894
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.420857 + 0.000831134
[7]	cv_agg's binary_logloss: 0.421261 + 0.000866894
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.420857 + 0.000831134
[7]	cv_agg's binary_logloss: 0.421261 + 0.000866894
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.420857 + 0.000831134
[7]	cv_agg's binary_logloss: 0.421261 + 0.000866894
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.420857 + 0.000831134
[7]	cv_agg's binary_logloss: 0.421261 + 0.000866894
[1]	cv_agg's binary_logloss: 0.430323 + 0.000334744
[2]	cv_agg's binary_logloss: 0.423726 + 0.000427719
[3]	cv_agg's binary_logloss: 0.421122 + 0.000354654
[4]	cv_agg's binary_logloss: 0.420468 + 0.000639111
[5]	cv_agg's binary_logloss: 0.42081 + 0.000958313
[6]	cv_agg's binary_logloss: 0.420857 + 0.000831134
[7]	cv_agg's binary_logloss: 0.421261 + 0.000866894
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419456 + 0.000724232
[7]	cv_agg's binary_logloss: 0.419582 + 0.000559056
[8]	cv_agg's binary_logloss: 0.419806 + 0.000704593
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419425 + 0.000822598
[7]	cv_agg's binary_logloss: 0.420176 + 0.0012489
[8]	cv_agg's binary_logloss: 0.420667 + 0.00151447
[9]	cv_agg's binary_logloss: 0.42109 + 0.00156067
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419425 + 0.000822598
[7]	cv_agg's binary_logloss: 0.420176 + 0.0012489
[8]	cv_agg's binary_logloss: 0.420667 + 0.00151447
[9]	cv_agg's binary_logloss: 0.42109 + 0.00156067
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419425 + 0.000822598
[7]	cv_agg's binary_logloss: 0.420176 + 0.0012489
[8]	cv_agg's binary_logloss: 0.420667 + 0.00151447
[9]	cv_agg's binary_logloss: 0.42109 + 0.00156067
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419425 + 0.000822598
[7]	cv_agg's binary_logloss: 0.420176 + 0.0012489
[8]	cv_agg's binary_logloss: 0.420667 + 0.00151447
[9]	cv_agg's binary_logloss: 0.42109 + 0.00156067
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419425 + 0.000822598
[7]	cv_agg's binary_logloss: 0.420176 + 0.0012489
[8]	cv_agg's binary_logloss: 0.420667 + 0.00151447
[9]	cv_agg's binary_logloss: 0.42109 + 0.00156067
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419425 + 0.000822598
[7]	cv_agg's binary_logloss: 0.420176 + 0.0012489
[8]	cv_agg's binary_logloss: 0.420667 + 0.00151447
[9]	cv_agg's binary_logloss: 0.42109 + 0.00156067
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419425 + 0.000822598
[7]	cv_agg's binary_logloss: 0.420176 + 0.0012489
[8]	cv_agg's binary_logloss: 0.420667 + 0.00151447
[9]	cv_agg's binary_logloss: 0.42109 + 0.00156067
[1]	cv_agg's binary_logloss: 0.430181 + 0.000198112
[2]	cv_agg's binary_logloss: 0.422957 + 0.000441639
[3]	cv_agg's binary_logloss: 0.420413 + 0.000501556
[4]	cv_agg's binary_logloss: 0.419972 + 0.000393147
[5]	cv_agg's binary_logloss: 0.419446 + 0.000467906
[6]	cv_agg's binary_logloss: 0.419425 + 0.000822598
[7]	cv_agg's binary_logloss: 0.420176 + 0.0012489
[8]	cv_agg's binary_logloss: 0.420667 + 0.00151447
[9]	cv_agg's binary_logloss: 0.42109 + 0.00156067
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419539 + 0.0012578
[7]	cv_agg's binary_logloss: 0.41978 + 0.000865056
[8]	cv_agg's binary_logloss: 0.420053 + 0.000961952
[9]	cv_agg's binary_logloss: 0.420703 + 0.000987414
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419827 + 0.000839302
[7]	cv_agg's binary_logloss: 0.41979 + 0.000785255
[8]	cv_agg's binary_logloss: 0.420004 + 0.000564564
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419827 + 0.000839302
[7]	cv_agg's binary_logloss: 0.41979 + 0.000785255
[8]	cv_agg's binary_logloss: 0.420004 + 0.000564564
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419827 + 0.000839302
[7]	cv_agg's binary_logloss: 0.41979 + 0.000785255
[8]	cv_agg's binary_logloss: 0.420004 + 0.000564564
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419827 + 0.000839302
[7]	cv_agg's binary_logloss: 0.41979 + 0.000785255
[8]	cv_agg's binary_logloss: 0.420004 + 0.000564564
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419827 + 0.000839302
[7]	cv_agg's binary_logloss: 0.41979 + 0.000785255
[8]	cv_agg's binary_logloss: 0.420004 + 0.000564564
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419827 + 0.000839302
[7]	cv_agg's binary_logloss: 0.41979 + 0.000785255
[8]	cv_agg's binary_logloss: 0.420004 + 0.000564564
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419827 + 0.000839302
[7]	cv_agg's binary_logloss: 0.41979 + 0.000785255
[8]	cv_agg's binary_logloss: 0.420004 + 0.000564564
[1]	cv_agg's binary_logloss: 0.429952 + 0.00101724
[2]	cv_agg's binary_logloss: 0.422687 + 0.00119188
[3]	cv_agg's binary_logloss: 0.420411 + 0.00121588
[4]	cv_agg's binary_logloss: 0.419724 + 0.000995635
[5]	cv_agg's binary_logloss: 0.419541 + 0.0011394
[6]	cv_agg's binary_logloss: 0.419827 + 0.000839302
[7]	cv_agg's binary_logloss: 0.41979 + 0.000785255
[8]	cv_agg's binary_logloss: 0.420004 + 0.000564564
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.41894 + 0.000833627
[7]	cv_agg's binary_logloss: 0.418816 + 0.00101043
[8]	cv_agg's binary_logloss: 0.419343 + 0.0010147
[9]	cv_agg's binary_logloss: 0.419467 + 0.00113527
[10]	cv_agg's binary_logloss: 0.420002 + 0.000879124
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.418719 + 0.000999281
[7]	cv_agg's binary_logloss: 0.418923 + 0.000831739
[8]	cv_agg's binary_logloss: 0.419102 + 0.00114371
[9]	cv_agg's binary_logloss: 0.419334 + 0.000889308
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.418719 + 0.000999281
[7]	cv_agg's binary_logloss: 0.418923 + 0.000831739
[8]	cv_agg's binary_logloss: 0.419102 + 0.00114371
[9]	cv_agg's binary_logloss: 0.419334 + 0.000889308
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.418719 + 0.000999281
[7]	cv_agg's binary_logloss: 0.418923 + 0.000831739
[8]	cv_agg's binary_logloss: 0.419102 + 0.00114371
[9]	cv_agg's binary_logloss: 0.419334 + 0.000889308
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.418719 + 0.000999281
[7]	cv_agg's binary_logloss: 0.418923 + 0.000831739
[8]	cv_agg's binary_logloss: 0.419102 + 0.00114371
[9]	cv_agg's binary_logloss: 0.419334 + 0.000889308
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.418719 + 0.000999281
[7]	cv_agg's binary_logloss: 0.418923 + 0.000831739
[8]	cv_agg's binary_logloss: 0.419102 + 0.00114371
[9]	cv_agg's binary_logloss: 0.419334 + 0.000889308
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.418719 + 0.000999281
[7]	cv_agg's binary_logloss: 0.418923 + 0.000831739
[8]	cv_agg's binary_logloss: 0.419102 + 0.00114371
[9]	cv_agg's binary_logloss: 0.419334 + 0.000889308
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.418719 + 0.000999281
[7]	cv_agg's binary_logloss: 0.418923 + 0.000831739
[8]	cv_agg's binary_logloss: 0.419102 + 0.00114371
[9]	cv_agg's binary_logloss: 0.419334 + 0.000889308
[1]	cv_agg's binary_logloss: 0.429707 + 0.000611738
[2]	cv_agg's binary_logloss: 0.422547 + 0.000814612
[3]	cv_agg's binary_logloss: 0.420059 + 0.000659369
[4]	cv_agg's binary_logloss: 0.419254 + 0.000869847
[5]	cv_agg's binary_logloss: 0.418849 + 0.000807161
[6]	cv_agg's binary_logloss: 0.418719 + 0.000999281
[7]	cv_agg's binary_logloss: 0.418923 + 0.000831739
[8]	cv_agg's binary_logloss: 0.419102 + 0.00114371
[9]	cv_agg's binary_logloss: 0.419334 + 0.000889308
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.42936 + 0.000968588
[2]	cv_agg's binary_logloss: 0.422173 + 0.000928202
[3]	cv_agg's binary_logloss: 0.419498 + 0.000765663
[4]	cv_agg's binary_logloss: 0.418549 + 0.000845092
[5]	cv_agg's binary_logloss: 0.418137 + 0.000415263
[6]	cv_agg's binary_logloss: 0.418076 + 0.000153534
[7]	cv_agg's binary_logloss: 0.418163 + 0.000431574
[8]	cv_agg's binary_logloss: 0.418537 + 0.000484202
[9]	cv_agg's binary_logloss: 0.419018 + 0.0004615
[1]	cv_agg's binary_logloss: 0.429964 + 0.00104388
[2]	cv_agg's binary_logloss: 0.422645 + 0.000532534
[3]	cv_agg's binary_logloss: 0.419511 + 0.000488801
[4]	cv_agg's binary_logloss: 0.417749 + 0.000490928
[5]	cv_agg's binary_logloss: 0.417302 + 0.000129256
[6]	cv_agg's binary_logloss: 0.417587 + 0.000328772
[7]	cv_agg's binary_logloss: 0.417868 + 0.000426446
[8]	cv_agg's binary_logloss: 0.417883 + 0.000668527
[1]	cv_agg's binary_logloss: 0.430095 + 0.000926253
[2]	cv_agg's binary_logloss: 0.422829 + 0.000432478
[3]	cv_agg's binary_logloss: 0.419686 + 0.000539821
[4]	cv_agg's binary_logloss: 0.418061 + 0.000661927
[5]	cv_agg's binary_logloss: 0.417754 + 0.000706331
[6]	cv_agg's binary_logloss: 0.417735 + 0.000661161
[7]	cv_agg's binary_logloss: 0.417667 + 0.000749749
[8]	cv_agg's binary_logloss: 0.417744 + 0.000700147
[9]	cv_agg's binary_logloss: 0.417962 + 0.00088455
[10]	cv_agg's binary_logloss: 0.418169 + 0.000774278
[1]	cv_agg's binary_logloss: 0.430095 + 0.000926253
[2]	cv_agg's binary_logloss: 0.422843 + 0.000444286
[3]	cv_agg's binary_logloss: 0.419668 + 0.000535257
[4]	cv_agg's binary_logloss: 0.418239 + 0.00071874
[5]	cv_agg's binary_logloss: 0.417956 + 0.000859637
[6]	cv_agg's binary_logloss: 0.417939 + 0.000782684
[7]	cv_agg's binary_logloss: 0.41765 + 0.000697596
[8]	cv_agg's binary_logloss: 0.41764 + 0.000688626
[9]	cv_agg's binary_logloss: 0.417619 + 0.000643744
[10]	cv_agg's binary_logloss: 0.417607 + 0.000632596
[11]	cv_agg's binary_logloss: 0.41761 + 0.000607454
[12]	cv_agg's binary_logloss: 0.417609 + 0.00061019
[13]	cv_agg's binary_logloss: 0.417605 + 0.000604166
[14]	cv_agg's binary_logloss: 0.417597 + 0.000615328
[15]	cv_agg's binary_logloss: 0.417602 + 0.000620524
[16]	cv_agg's binary_logloss: 0.417602 + 0.000620524
[17]	cv_agg's binary_logloss: 0.417602 + 0.000620524
[1]	cv_agg's binary_logloss: 0.430103 + 0.000890645
[2]	cv_agg's binary_logloss: 0.422711 + 0.000584979
[3]	cv_agg's binary_logloss: 0.419771 + 0.000415856
[4]	cv_agg's binary_logloss: 0.418411 + 0.000445961
[5]	cv_agg's binary_logloss: 0.41794 + 0.000571366
[6]	cv_agg's binary_logloss: 0.417758 + 0.000606343
[7]	cv_agg's binary_logloss: 0.417688 + 0.00056603
[8]	cv_agg's binary_logloss: 0.417662 + 0.000659582
[9]	cv_agg's binary_logloss: 0.417662 + 0.000645837
[10]	cv_agg's binary_logloss: 0.417667 + 0.000651855
[11]	cv_agg's binary_logloss: 0.417665 + 0.000657309
[12]	cv_agg's binary_logloss: 0.417665 + 0.000657309
[1]	cv_agg's binary_logloss: 0.430108 + 0.000721443
[2]	cv_agg's binary_logloss: 0.422779 + 0.000645984
[3]	cv_agg's binary_logloss: 0.419662 + 0.000612566
[4]	cv_agg's binary_logloss: 0.418321 + 0.000256299
[5]	cv_agg's binary_logloss: 0.417964 + 0.000235413
[6]	cv_agg's binary_logloss: 0.417935 + 0.000230088
[7]	cv_agg's binary_logloss: 0.417857 + 0.000157837
[8]	cv_agg's binary_logloss: 0.417872 + 0.00018255
[9]	cv_agg's binary_logloss: 0.417887 + 0.000172835
[10]	cv_agg's binary_logloss: 0.417875 + 0.000180254
[1]	cv_agg's binary_logloss: 0.430048 + 0.000913206
[2]	cv_agg's binary_logloss: 0.422621 + 0.000394984
[3]	cv_agg's binary_logloss: 0.419699 + 0.000343391
[4]	cv_agg's binary_logloss: 0.418108 + 0.000417856
[5]	cv_agg's binary_logloss: 0.417784 + 0.000331145
[6]	cv_agg's binary_logloss: 0.41774 + 0.000302677
[7]	cv_agg's binary_logloss: 0.418064 + 0.000614961
[8]	cv_agg's binary_logloss: 0.418228 + 0.000594002
[9]	cv_agg's binary_logloss: 0.418414 + 0.000784836
[1]	cv_agg's binary_logloss: 0.430012 + 0.000933391
[2]	cv_agg's binary_logloss: 0.422696 + 0.000442007
[3]	cv_agg's binary_logloss: 0.41954 + 0.000486196
[4]	cv_agg's binary_logloss: 0.417883 + 0.000466661
[5]	cv_agg's binary_logloss: 0.417701 + 0.00042109
[6]	cv_agg's binary_logloss: 0.417321 + 0.000305133
[7]	cv_agg's binary_logloss: 0.41735 + 0.000211263
[8]	cv_agg's binary_logloss: 0.417337 + 0.000321777
[9]	cv_agg's binary_logloss: 0.417592 + 0.000244633
[1]	cv_agg's binary_logloss: 0.430061 + 0.00099498
[2]	cv_agg's binary_logloss: 0.42278 + 0.000601855
[3]	cv_agg's binary_logloss: 0.4195 + 0.000566446
[4]	cv_agg's binary_logloss: 0.417956 + 0.000320509
[5]	cv_agg's binary_logloss: 0.417673 + 0.00073005
[6]	cv_agg's binary_logloss: 0.417473 + 0.000629665
[7]	cv_agg's binary_logloss: 0.41751 + 0.000569515
[8]	cv_agg's binary_logloss: 0.41755 + 0.000642184
[9]	cv_agg's binary_logloss: 0.417576 + 0.000600457
[1]	cv_agg's binary_logloss: 0.429989 + 0.000940855
[2]	cv_agg's binary_logloss: 0.422703 + 0.000577595
[3]	cv_agg's binary_logloss: 0.419801 + 0.000506498
[4]	cv_agg's binary_logloss: 0.418279 + 0.000391813
[5]	cv_agg's binary_logloss: 0.417849 + 0.000431886
[6]	cv_agg's binary_logloss: 0.417717 + 0.0004894
[7]	cv_agg's binary_logloss: 0.417654 + 0.000464488
[8]	cv_agg's binary_logloss: 0.417666 + 0.000532103
[9]	cv_agg's binary_logloss: 0.417691 + 0.000530591
[10]	cv_agg's binary_logloss: 0.417708 + 0.000547924
[1]	cv_agg's binary_logloss: 0.430156 + 0.000577133
[2]	cv_agg's binary_logloss: 0.422642 + 0.000626588
[3]	cv_agg's binary_logloss: 0.419599 + 0.000563197
[4]	cv_agg's binary_logloss: 0.418365 + 0.00051684
[5]	cv_agg's binary_logloss: 0.417894 + 0.000424201
[6]	cv_agg's binary_logloss: 0.417795 + 0.000620568
[7]	cv_agg's binary_logloss: 0.417762 + 0.000617117
[8]	cv_agg's binary_logloss: 0.417753 + 0.000626151
[9]	cv_agg's binary_logloss: 0.417767 + 0.000593015
[10]	cv_agg's binary_logloss: 0.417774 + 0.000601182
[11]	cv_agg's binary_logloss: 0.417775 + 0.000601217
[1]	cv_agg's binary_logloss: 0.430221 + 0.000821505
[2]	cv_agg's binary_logloss: 0.422465 + 0.000437691
[3]	cv_agg's binary_logloss: 0.419428 + 0.000423631
[4]	cv_agg's binary_logloss: 0.417701 + 0.000478584
[5]	cv_agg's binary_logloss: 0.417481 + 0.000306618
[6]	cv_agg's binary_logloss: 0.41737 + 0.000417271
[7]	cv_agg's binary_logloss: 0.417449 + 0.000606902
[8]	cv_agg's binary_logloss: 0.417522 + 0.000982868
[9]	cv_agg's binary_logloss: 0.41795 + 0.000956909
[1]	cv_agg's binary_logloss: 0.430208 + 0.000834002
[2]	cv_agg's binary_logloss: 0.42271 + 0.000533162
[3]	cv_agg's binary_logloss: 0.419785 + 0.000344809
[4]	cv_agg's binary_logloss: 0.418335 + 0.000576383
[5]	cv_agg's binary_logloss: 0.417832 + 0.000660229
[6]	cv_agg's binary_logloss: 0.417811 + 0.000880835
[7]	cv_agg's binary_logloss: 0.417615 + 0.00124387
[8]	cv_agg's binary_logloss: 0.417688 + 0.00126857
[9]	cv_agg's binary_logloss: 0.417769 + 0.00148324
[10]	cv_agg's binary_logloss: 0.41795 + 0.00134424
[1]	cv_agg's binary_logloss: 0.430215 + 0.000832044
[2]	cv_agg's binary_logloss: 0.422547 + 0.000695721
[3]	cv_agg's binary_logloss: 0.419574 + 0.000592524
[4]	cv_agg's binary_logloss: 0.417808 + 0.00053936
[5]	cv_agg's binary_logloss: 0.417494 + 0.000706171
[6]	cv_agg's binary_logloss: 0.417575 + 0.000568715
[7]	cv_agg's binary_logloss: 0.417669 + 0.000529356
[8]	cv_agg's binary_logloss: 0.417676 + 0.000615541
[1]	cv_agg's binary_logloss: 0.430149 + 0.000765593
[2]	cv_agg's binary_logloss: 0.422547 + 0.00070381
[3]	cv_agg's binary_logloss: 0.419543 + 0.000480788
[4]	cv_agg's binary_logloss: 0.418107 + 0.000617749
[5]	cv_agg's binary_logloss: 0.417641 + 0.000634514
[6]	cv_agg's binary_logloss: 0.41758 + 0.000616634
[7]	cv_agg's binary_logloss: 0.417554 + 0.000707194
[8]	cv_agg's binary_logloss: 0.417581 + 0.000733807
[9]	cv_agg's binary_logloss: 0.417588 + 0.000702091
[10]	cv_agg's binary_logloss: 0.417583 + 0.000698027
[1]	cv_agg's binary_logloss: 0.430186 + 0.00056025
[2]	cv_agg's binary_logloss: 0.422458 + 0.000744434
[3]	cv_agg's binary_logloss: 0.419444 + 0.000551547
[4]	cv_agg's binary_logloss: 0.418175 + 0.000403844
[5]	cv_agg's binary_logloss: 0.4177 + 0.000386467
[6]	cv_agg's binary_logloss: 0.41752 + 0.000537158
[7]	cv_agg's binary_logloss: 0.417369 + 0.000547363
[8]	cv_agg's binary_logloss: 0.417348 + 0.000585661
[9]	cv_agg's binary_logloss: 0.417325 + 0.000556525
[10]	cv_agg's binary_logloss: 0.417322 + 0.000559845
[11]	cv_agg's binary_logloss: 0.417318 + 0.00055553
[12]	cv_agg's binary_logloss: 0.417323 + 0.000562246
[13]	cv_agg's binary_logloss: 0.417323 + 0.000562246
[14]	cv_agg's binary_logloss: 0.417323 + 0.000562246
[1]	cv_agg's binary_logloss: 0.430232 + 0.00079165
[2]	cv_agg's binary_logloss: 0.422593 + 0.000689888
[3]	cv_agg's binary_logloss: 0.419479 + 0.000554588
[4]	cv_agg's binary_logloss: 0.41793 + 0.000369684
[5]	cv_agg's binary_logloss: 0.417666 + 0.000355228
[6]	cv_agg's binary_logloss: 0.417478 + 0.000285131
[7]	cv_agg's binary_logloss: 0.417807 + 0.000461504
[8]	cv_agg's binary_logloss: 0.417924 + 0.000475458
[9]	cv_agg's binary_logloss: 0.418048 + 0.000477907
[1]	cv_agg's binary_logloss: 0.430239 + 0.000792142
[2]	cv_agg's binary_logloss: 0.422684 + 0.000670221
[3]	cv_agg's binary_logloss: 0.419646 + 0.000475243
[4]	cv_agg's binary_logloss: 0.418025 + 0.000603218
[5]	cv_agg's binary_logloss: 0.41769 + 0.000835409
[6]	cv_agg's binary_logloss: 0.417627 + 0.000921834
[7]	cv_agg's binary_logloss: 0.417548 + 0.00110776
[8]	cv_agg's binary_logloss: 0.417759 + 0.00114536
[9]	cv_agg's binary_logloss: 0.418 + 0.000965721
[10]	cv_agg's binary_logloss: 0.418074 + 0.00106181
[1]	cv_agg's binary_logloss: 0.430279 + 0.00084526
[2]	cv_agg's binary_logloss: 0.422699 + 0.000777247
[3]	cv_agg's binary_logloss: 0.419559 + 0.000726303
[4]	cv_agg's binary_logloss: 0.417812 + 0.000719651
[5]	cv_agg's binary_logloss: 0.417591 + 0.000739639
[6]	cv_agg's binary_logloss: 0.417593 + 0.000809933
[7]	cv_agg's binary_logloss: 0.417495 + 0.000778543
[8]	cv_agg's binary_logloss: 0.417574 + 0.000843817
[9]	cv_agg's binary_logloss: 0.417532 + 0.000800862
[10]	cv_agg's binary_logloss: 0.417494 + 0.000779357
[11]	cv_agg's binary_logloss: 0.417495 + 0.00077421
[12]	cv_agg's binary_logloss: 0.417495 + 0.00077421
[13]	cv_agg's binary_logloss: 0.417493 + 0.000781857
[14]	cv_agg's binary_logloss: 0.417493 + 0.000781857
[15]	cv_agg's binary_logloss: 0.417499 + 0.000774075
[16]	cv_agg's binary_logloss: 0.417499 + 0.000774075
[1]	cv_agg's binary_logloss: 0.430244 + 0.000824998
[2]	cv_agg's binary_logloss: 0.422559 + 0.000874637
[3]	cv_agg's binary_logloss: 0.419626 + 0.000628704
[4]	cv_agg's binary_logloss: 0.418072 + 0.000541599
[5]	cv_agg's binary_logloss: 0.417751 + 0.000794414
[6]	cv_agg's binary_logloss: 0.417524 + 0.000810102
[7]	cv_agg's binary_logloss: 0.417438 + 0.000750482
[8]	cv_agg's binary_logloss: 0.417398 + 0.000800883
[9]	cv_agg's binary_logloss: 0.417432 + 0.000766101
[10]	cv_agg's binary_logloss: 0.41745 + 0.00078228
[11]	cv_agg's binary_logloss: 0.417454 + 0.000771541
[1]	cv_agg's binary_logloss: 0.430236 + 0.000577474
[2]	cv_agg's binary_logloss: 0.422547 + 0.00066306
[3]	cv_agg's binary_logloss: 0.419362 + 0.000519156
[4]	cv_agg's binary_logloss: 0.418153 + 0.000357025
[5]	cv_agg's binary_logloss: 0.41762 + 0.000272417
[6]	cv_agg's binary_logloss: 0.417434 + 0.000409632
[7]	cv_agg's binary_logloss: 0.4173 + 0.000479946
[8]	cv_agg's binary_logloss: 0.417296 + 0.000506184
[9]	cv_agg's binary_logloss: 0.417293 + 0.000495048
[10]	cv_agg's binary_logloss: 0.417292 + 0.000511088
[11]	cv_agg's binary_logloss: 0.417297 + 0.000504612
[12]	cv_agg's binary_logloss: 0.417297 + 0.000504612
[13]	cv_agg's binary_logloss: 0.417297 + 0.000504612
[1]	cv_agg's binary_logloss: 0.430169 + 0.000814468
[2]	cv_agg's binary_logloss: 0.422556 + 0.00070996
[3]	cv_agg's binary_logloss: 0.419435 + 0.000510805
[4]	cv_agg's binary_logloss: 0.417852 + 0.000321328
[5]	cv_agg's binary_logloss: 0.417651 + 0.000420275
[6]	cv_agg's binary_logloss: 0.417531 + 0.000553745
[7]	cv_agg's binary_logloss: 0.417418 + 0.000559303
[8]	cv_agg's binary_logloss: 0.417337 + 0.000699295
[9]	cv_agg's binary_logloss: 0.417585 + 0.00078174
[10]	cv_agg's binary_logloss: 0.417714 + 0.000688402
[11]	cv_agg's binary_logloss: 0.417871 + 0.000951442
[1]	cv_agg's binary_logloss: 0.430191 + 0.000801461
[2]	cv_agg's binary_logloss: 0.422751 + 0.000625005
[3]	cv_agg's binary_logloss: 0.419542 + 0.000620154
[4]	cv_agg's binary_logloss: 0.417899 + 0.00065175
[5]	cv_agg's binary_logloss: 0.417559 + 0.000790993
[6]	cv_agg's binary_logloss: 0.417585 + 0.000969268
[7]	cv_agg's binary_logloss: 0.41749 + 0.000940902
[8]	cv_agg's binary_logloss: 0.417474 + 0.00087102
[9]	cv_agg's binary_logloss: 0.417567 + 0.00104866
[10]	cv_agg's binary_logloss: 0.417621 + 0.00096184
[11]	cv_agg's binary_logloss: 0.417646 + 0.000951743
[1]	cv_agg's binary_logloss: 0.430231 + 0.000856322
[2]	cv_agg's binary_logloss: 0.422681 + 0.000780003
[3]	cv_agg's binary_logloss: 0.419414 + 0.000708313
[4]	cv_agg's binary_logloss: 0.417886 + 0.000658092
[5]	cv_agg's binary_logloss: 0.417375 + 0.000574102
[6]	cv_agg's binary_logloss: 0.41734 + 0.000546512
[7]	cv_agg's binary_logloss: 0.417313 + 0.000425373
[8]	cv_agg's binary_logloss: 0.417358 + 0.000547362
[9]	cv_agg's binary_logloss: 0.41732 + 0.000468871
[10]	cv_agg's binary_logloss: 0.417359 + 0.000520968
[1]	cv_agg's binary_logloss: 0.430136 + 0.000741933
[2]	cv_agg's binary_logloss: 0.422427 + 0.000728553
[3]	cv_agg's binary_logloss: 0.419285 + 0.000513561
[4]	cv_agg's binary_logloss: 0.41786 + 0.000508954
[5]	cv_agg's binary_logloss: 0.417625 + 0.000488893
[6]	cv_agg's binary_logloss: 0.417527 + 0.000577775
[7]	cv_agg's binary_logloss: 0.417398 + 0.000691937
[8]	cv_agg's binary_logloss: 0.417388 + 0.000717229
[9]	cv_agg's binary_logloss: 0.41736 + 0.000646166
[10]	cv_agg's binary_logloss: 0.417383 + 0.000673535
[11]	cv_agg's binary_logloss: 0.417373 + 0.000660713
[12]	cv_agg's binary_logloss: 0.417372 + 0.000660448
[1]	cv_agg's binary_logloss: 0.430188 + 0.000604675
[2]	cv_agg's binary_logloss: 0.422594 + 0.000773232
[3]	cv_agg's binary_logloss: 0.419438 + 0.00076539
[4]	cv_agg's binary_logloss: 0.418209 + 0.000741513
[5]	cv_agg's binary_logloss: 0.417804 + 0.000598105
[6]	cv_agg's binary_logloss: 0.417865 + 0.000604256
[7]	cv_agg's binary_logloss: 0.417823 + 0.000619031
[8]	cv_agg's binary_logloss: 0.417798 + 0.000640808
[9]	cv_agg's binary_logloss: 0.417751 + 0.000555919
[10]	cv_agg's binary_logloss: 0.417743 + 0.000566789
[11]	cv_agg's binary_logloss: 0.417741 + 0.000561476
[12]	cv_agg's binary_logloss: 0.41774 + 0.000561487
[13]	cv_agg's binary_logloss: 0.417736 + 0.000561704
[14]	cv_agg's binary_logloss: 0.417736 + 0.000561704
[15]	cv_agg's binary_logloss: 0.417736 + 0.000561704
[16]	cv_agg's binary_logloss: 0.417736 + 0.000561704
[1]	cv_agg's binary_logloss: 0.430033 + 0.000918871
[2]	cv_agg's binary_logloss: 0.422733 + 0.000435512
[3]	cv_agg's binary_logloss: 0.419564 + 0.000582263
[4]	cv_agg's binary_logloss: 0.417623 + 0.000633576
[5]	cv_agg's binary_logloss: 0.417392 + 0.000593649
[6]	cv_agg's binary_logloss: 0.417313 + 0.000722116
[7]	cv_agg's binary_logloss: 0.417552 + 0.000815878
[8]	cv_agg's binary_logloss: 0.417686 + 0.00110246
[9]	cv_agg's binary_logloss: 0.417812 + 0.00116184
[1]	cv_agg's binary_logloss: 0.430043 + 0.000969114
[2]	cv_agg's binary_logloss: 0.42272 + 0.000480495
[3]	cv_agg's binary_logloss: 0.419397 + 0.000687105
[4]	cv_agg's binary_logloss: 0.417726 + 0.000593859
[5]	cv_agg's binary_logloss: 0.417598 + 0.00035736
[6]	cv_agg's binary_logloss: 0.417607 + 0.000435609
[7]	cv_agg's binary_logloss: 0.417538 + 0.000394933
[8]	cv_agg's binary_logloss: 0.417575 + 0.000565009
[9]	cv_agg's binary_logloss: 0.417928 + 0.000580026
[10]	cv_agg's binary_logloss: 0.417963 + 0.000498649
[1]	cv_agg's binary_logloss: 0.430067 + 0.000998376
[2]	cv_agg's binary_logloss: 0.422671 + 0.000747365
[3]	cv_agg's binary_logloss: 0.419708 + 0.000665296
[4]	cv_agg's binary_logloss: 0.418217 + 0.00033377
[5]	cv_agg's binary_logloss: 0.417754 + 0.000695584
[6]	cv_agg's binary_logloss: 0.417554 + 0.000802705
[7]	cv_agg's binary_logloss: 0.417475 + 0.000797994
[8]	cv_agg's binary_logloss: 0.417535 + 0.000801222
[9]	cv_agg's binary_logloss: 0.41748 + 0.000760286
[10]	cv_agg's binary_logloss: 0.41749 + 0.000765518
[1]	cv_agg's binary_logloss: 0.429912 + 0.000877202
[2]	cv_agg's binary_logloss: 0.422405 + 0.00068504
[3]	cv_agg's binary_logloss: 0.419405 + 0.000686715
[4]	cv_agg's binary_logloss: 0.41807 + 0.000441045
[5]	cv_agg's binary_logloss: 0.417614 + 0.000434108
[6]	cv_agg's binary_logloss: 0.41756 + 0.000433322
[7]	cv_agg's binary_logloss: 0.417451 + 0.000389866
[8]	cv_agg's binary_logloss: 0.417485 + 0.000420533
[9]	cv_agg's binary_logloss: 0.417484 + 0.000409192
[10]	cv_agg's binary_logloss: 0.417483 + 0.00040927
[1]	cv_agg's binary_logloss: 0.430164 + 0.000577633
[2]	cv_agg's binary_logloss: 0.42267 + 0.000523542
[3]	cv_agg's binary_logloss: 0.419699 + 0.000558162
[4]	cv_agg's binary_logloss: 0.418476 + 0.000411136
[5]	cv_agg's binary_logloss: 0.417897 + 0.000326458
[6]	cv_agg's binary_logloss: 0.417675 + 0.000493813
[7]	cv_agg's binary_logloss: 0.417541 + 0.000541881
[8]	cv_agg's binary_logloss: 0.41756 + 0.000579618
[9]	cv_agg's binary_logloss: 0.417594 + 0.000579153
[10]	cv_agg's binary_logloss: 0.417601 + 0.000585985
[1]	cv_agg's binary_logloss: 0.430255 + 0.000825529
[2]	cv_agg's binary_logloss: 0.422693 + 0.000455969
[3]	cv_agg's binary_logloss: 0.419593 + 0.000233012
[4]	cv_agg's binary_logloss: 0.417774 + 0.000393828
[5]	cv_agg's binary_logloss: 0.417485 + 0.000197535
[6]	cv_agg's binary_logloss: 0.417402 + 0.00034491
[7]	cv_agg's binary_logloss: 0.417336 + 0.000522387
[8]	cv_agg's binary_logloss: 0.417409 + 0.000696949
[9]	cv_agg's binary_logloss: 0.417428 + 0.000479884
[10]	cv_agg's binary_logloss: 0.417695 + 0.000654264
[1]	cv_agg's binary_logloss: 0.430264 + 0.000823934
[2]	cv_agg's binary_logloss: 0.422704 + 0.000476743
[3]	cv_agg's binary_logloss: 0.41969 + 0.000362745
[4]	cv_agg's binary_logloss: 0.417965 + 0.000460534
[5]	cv_agg's binary_logloss: 0.417631 + 0.000409675
[6]	cv_agg's binary_logloss: 0.417578 + 0.000537714
[7]	cv_agg's binary_logloss: 0.417413 + 0.000654769
[8]	cv_agg's binary_logloss: 0.417689 + 0.000489019
[9]	cv_agg's binary_logloss: 0.417651 + 0.000505284
[10]	cv_agg's binary_logloss: 0.417778 + 0.00074567
[1]	cv_agg's binary_logloss: 0.430253 + 0.000825936
[2]	cv_agg's binary_logloss: 0.4227 + 0.00065914
[3]	cv_agg's binary_logloss: 0.419782 + 0.000542651
[4]	cv_agg's binary_logloss: 0.418577 + 0.000503509
[5]	cv_agg's binary_logloss: 0.418293 + 0.00062465
[6]	cv_agg's binary_logloss: 0.418193 + 0.000666095
[7]	cv_agg's binary_logloss: 0.417967 + 0.00071533
[8]	cv_agg's binary_logloss: 0.418019 + 0.000675377
[9]	cv_agg's binary_logloss: 0.417967 + 0.000652601
[10]	cv_agg's binary_logloss: 0.417975 + 0.000677532
[1]	cv_agg's binary_logloss: 0.430107 + 0.000687906
[2]	cv_agg's binary_logloss: 0.422456 + 0.000675974
[3]	cv_agg's binary_logloss: 0.419452 + 0.000555834
[4]	cv_agg's binary_logloss: 0.41801 + 0.000674535
[5]	cv_agg's binary_logloss: 0.417795 + 0.000573486
[6]	cv_agg's binary_logloss: 0.417701 + 0.00055539
[7]	cv_agg's binary_logloss: 0.417687 + 0.000555847
[8]	cv_agg's binary_logloss: 0.417694 + 0.000562496
[9]	cv_agg's binary_logloss: 0.417634 + 0.000596265
[10]	cv_agg's binary_logloss: 0.417626 + 0.000589465
[11]	cv_agg's binary_logloss: 0.417627 + 0.000588149
[12]	cv_agg's binary_logloss: 0.417627 + 0.000588149
[13]	cv_agg's binary_logloss: 0.417627 + 0.000588149
[1]	cv_agg's binary_logloss: 0.430219 + 0.000615012
[2]	cv_agg's binary_logloss: 0.422636 + 0.000725979
[3]	cv_agg's binary_logloss: 0.419715 + 0.000699249
[4]	cv_agg's binary_logloss: 0.418512 + 0.000582764
[5]	cv_agg's binary_logloss: 0.417996 + 0.000430014
[6]	cv_agg's binary_logloss: 0.417867 + 0.000535668
[7]	cv_agg's binary_logloss: 0.417761 + 0.000555469
[8]	cv_agg's binary_logloss: 0.417752 + 0.000619291
[9]	cv_agg's binary_logloss: 0.417738 + 0.00061296
[10]	cv_agg's binary_logloss: 0.417738 + 0.000612975
[11]	cv_agg's binary_logloss: 0.41775 + 0.000603703
[12]	cv_agg's binary_logloss: 0.417749 + 0.000604392
[13]	cv_agg's binary_logloss: 0.417749 + 0.000604392
[1]	cv_agg's binary_logloss: 0.430233 + 0.000795494
[2]	cv_agg's binary_logloss: 0.422774 + 0.000591972
[3]	cv_agg's binary_logloss: 0.419676 + 0.000335871
[4]	cv_agg's binary_logloss: 0.417791 + 0.000324262
[5]	cv_agg's binary_logloss: 0.417615 + 0.000425917
[6]	cv_agg's binary_logloss: 0.417586 + 0.000436072
[7]	cv_agg's binary_logloss: 0.417593 + 0.000613435
[8]	cv_agg's binary_logloss: 0.417797 + 0.000700893
[9]	cv_agg's binary_logloss: 0.418216 + 0.000864798
[1]	cv_agg's binary_logloss: 0.430246 + 0.000855614
[2]	cv_agg's binary_logloss: 0.422843 + 0.000700745
[3]	cv_agg's binary_logloss: 0.419833 + 0.000611573
[4]	cv_agg's binary_logloss: 0.418019 + 0.000561795
[5]	cv_agg's binary_logloss: 0.417596 + 0.000479924
[6]	cv_agg's binary_logloss: 0.417451 + 0.000586586
[7]	cv_agg's binary_logloss: 0.417403 + 0.000620512
[8]	cv_agg's binary_logloss: 0.417711 + 0.000648072
[9]	cv_agg's binary_logloss: 0.417727 + 0.00070299
[10]	cv_agg's binary_logloss: 0.41801 + 0.000897599
[1]	cv_agg's binary_logloss: 0.430222 + 0.000863111
[2]	cv_agg's binary_logloss: 0.422708 + 0.00078219
[3]	cv_agg's binary_logloss: 0.419601 + 0.000724157
[4]	cv_agg's binary_logloss: 0.41815 + 0.000486006
[5]	cv_agg's binary_logloss: 0.417755 + 0.00055758
[6]	cv_agg's binary_logloss: 0.417582 + 0.000673956
[7]	cv_agg's binary_logloss: 0.417673 + 0.000801707
[8]	cv_agg's binary_logloss: 0.417694 + 0.000779666
[9]	cv_agg's binary_logloss: 0.417668 + 0.000760552
[1]	cv_agg's binary_logloss: 0.430078 + 0.000715612
[2]	cv_agg's binary_logloss: 0.422494 + 0.000671321
[3]	cv_agg's binary_logloss: 0.41932 + 0.000585856
[4]	cv_agg's binary_logloss: 0.41795 + 0.000576518
[5]	cv_agg's binary_logloss: 0.41754 + 0.00077079
[6]	cv_agg's binary_logloss: 0.41732 + 0.000737205
[7]	cv_agg's binary_logloss: 0.417199 + 0.000733829
[8]	cv_agg's binary_logloss: 0.417217 + 0.000754357
[9]	cv_agg's binary_logloss: 0.417227 + 0.000735164
[10]	cv_agg's binary_logloss: 0.417214 + 0.00075943
[1]	cv_agg's binary_logloss: 0.430218 + 0.000652748
[2]	cv_agg's binary_logloss: 0.422697 + 0.000710256
[3]	cv_agg's binary_logloss: 0.419702 + 0.000441764
[4]	cv_agg's binary_logloss: 0.41846 + 0.000604169
[5]	cv_agg's binary_logloss: 0.417905 + 0.000608453
[6]	cv_agg's binary_logloss: 0.417604 + 0.000635414
[7]	cv_agg's binary_logloss: 0.417493 + 0.000699382
[8]	cv_agg's binary_logloss: 0.417499 + 0.000709463
[9]	cv_agg's binary_logloss: 0.417487 + 0.000676462
[10]	cv_agg's binary_logloss: 0.417483 + 0.000678962
[11]	cv_agg's binary_logloss: 0.417483 + 0.000678962
[12]	cv_agg's binary_logloss: 0.417483 + 0.000678962
[13]	cv_agg's binary_logloss: 0.417483 + 0.000678962
[1]	cv_agg's binary_logloss: 0.430166 + 0.000818883
[2]	cv_agg's binary_logloss: 0.422695 + 0.00062348
[3]	cv_agg's binary_logloss: 0.419591 + 0.000362545
[4]	cv_agg's binary_logloss: 0.417844 + 0.00037185
[5]	cv_agg's binary_logloss: 0.417502 + 0.000635188
[6]	cv_agg's binary_logloss: 0.417382 + 0.000593996
[7]	cv_agg's binary_logloss: 0.417429 + 0.000641243
[8]	cv_agg's binary_logloss: 0.417531 + 0.000729123
[9]	cv_agg's binary_logloss: 0.417779 + 0.000901853
[1]	cv_agg's binary_logloss: 0.430221 + 0.000868141
[2]	cv_agg's binary_logloss: 0.422785 + 0.000722782
[3]	cv_agg's binary_logloss: 0.419587 + 0.000613908
[4]	cv_agg's binary_logloss: 0.417976 + 0.000387776
[5]	cv_agg's binary_logloss: 0.417689 + 0.000390191
[6]	cv_agg's binary_logloss: 0.417673 + 0.000553179
[7]	cv_agg's binary_logloss: 0.417693 + 0.000424658
[8]	cv_agg's binary_logloss: 0.41773 + 0.000563218
[9]	cv_agg's binary_logloss: 0.417938 + 0.000666993
[1]	cv_agg's binary_logloss: 0.430198 + 0.000895266
[2]	cv_agg's binary_logloss: 0.422637 + 0.000816214
[3]	cv_agg's binary_logloss: 0.419379 + 0.000770842
[4]	cv_agg's binary_logloss: 0.417864 + 0.000461316
[5]	cv_agg's binary_logloss: 0.417481 + 0.000532078
[6]	cv_agg's binary_logloss: 0.417438 + 0.000683806
[7]	cv_agg's binary_logloss: 0.417416 + 0.000712468
[8]	cv_agg's binary_logloss: 0.417577 + 0.000891997
[9]	cv_agg's binary_logloss: 0.4175 + 0.000903485
[10]	cv_agg's binary_logloss: 0.417489 + 0.000941276
[1]	cv_agg's binary_logloss: 0.430144 + 0.000647857
[2]	cv_agg's binary_logloss: 0.422457 + 0.00063674
[3]	cv_agg's binary_logloss: 0.419581 + 0.000604423
[4]	cv_agg's binary_logloss: 0.418181 + 0.00039384
[5]	cv_agg's binary_logloss: 0.417728 + 0.00039256
[6]	cv_agg's binary_logloss: 0.417714 + 0.000562811
[7]	cv_agg's binary_logloss: 0.41757 + 0.000629023
[8]	cv_agg's binary_logloss: 0.417495 + 0.000724403
[9]	cv_agg's binary_logloss: 0.417475 + 0.000681311
[10]	cv_agg's binary_logloss: 0.417492 + 0.000695571
[11]	cv_agg's binary_logloss: 0.417508 + 0.000682278
[12]	cv_agg's binary_logloss: 0.417508 + 0.000682412
[1]	cv_agg's binary_logloss: 0.430174 + 0.000613153
[2]	cv_agg's binary_logloss: 0.422473 + 0.000687738
[3]	cv_agg's binary_logloss: 0.419476 + 0.000703802
[4]	cv_agg's binary_logloss: 0.418165 + 0.000777662
[5]	cv_agg's binary_logloss: 0.417885 + 0.000780047
[6]	cv_agg's binary_logloss: 0.417884 + 0.000698801
[7]	cv_agg's binary_logloss: 0.417892 + 0.000733146
[8]	cv_agg's binary_logloss: 0.41788 + 0.000756392
[9]	cv_agg's binary_logloss: 0.417885 + 0.000744004
[10]	cv_agg's binary_logloss: 0.417885 + 0.00074891
[11]	cv_agg's binary_logloss: 0.417896 + 0.00074801
[1]	cv_agg's binary_logloss: 0.430184 + 0.000878888
[2]	cv_agg's binary_logloss: 0.422691 + 0.000674663
[3]	cv_agg's binary_logloss: 0.41963 + 0.000598047
[4]	cv_agg's binary_logloss: 0.418063 + 0.000601605
[5]	cv_agg's binary_logloss: 0.417521 + 0.000741816
[6]	cv_agg's binary_logloss: 0.417487 + 0.000755444
[7]	cv_agg's binary_logloss: 0.417382 + 0.000681025
[8]	cv_agg's binary_logloss: 0.417676 + 0.00066366
[9]	cv_agg's binary_logloss: 0.417761 + 0.000612631
[10]	cv_agg's binary_logloss: 0.417761 + 0.000519757
[1]	cv_agg's binary_logloss: 0.430189 + 0.000877141
[2]	cv_agg's binary_logloss: 0.422652 + 0.000716124
[3]	cv_agg's binary_logloss: 0.419391 + 0.000598529
[4]	cv_agg's binary_logloss: 0.417998 + 0.000612471
[5]	cv_agg's binary_logloss: 0.417658 + 0.00086001
[6]	cv_agg's binary_logloss: 0.417672 + 0.000825075
[7]	cv_agg's binary_logloss: 0.417583 + 0.000872072
[8]	cv_agg's binary_logloss: 0.417676 + 0.000810118
[9]	cv_agg's binary_logloss: 0.417689 + 0.000615456
[10]	cv_agg's binary_logloss: 0.417872 + 0.000705784
[1]	cv_agg's binary_logloss: 0.430213 + 0.000873042
[2]	cv_agg's binary_logloss: 0.422534 + 0.000812954
[3]	cv_agg's binary_logloss: 0.41937 + 0.000563038
[4]	cv_agg's binary_logloss: 0.418037 + 0.000456752
[5]	cv_agg's binary_logloss: 0.417621 + 0.000769004
[6]	cv_agg's binary_logloss: 0.417235 + 0.000827508
[7]	cv_agg's binary_logloss: 0.417216 + 0.000894386
[8]	cv_agg's binary_logloss: 0.417316 + 0.000828187
[9]	cv_agg's binary_logloss: 0.41725 + 0.000782286
[10]	cv_agg's binary_logloss: 0.417238 + 0.000771173
[1]	cv_agg's binary_logloss: 0.430169 + 0.000684037
[2]	cv_agg's binary_logloss: 0.422459 + 0.000655013
[3]	cv_agg's binary_logloss: 0.419467 + 0.000554326
[4]	cv_agg's binary_logloss: 0.418097 + 0.000520932
[5]	cv_agg's binary_logloss: 0.417711 + 0.000572772
[6]	cv_agg's binary_logloss: 0.417433 + 0.000688941
[7]	cv_agg's binary_logloss: 0.417268 + 0.000668654
[8]	cv_agg's binary_logloss: 0.417229 + 0.000617886
[9]	cv_agg's binary_logloss: 0.41716 + 0.000630139
[10]	cv_agg's binary_logloss: 0.417145 + 0.000613558
[11]	cv_agg's binary_logloss: 0.417144 + 0.000604227
[12]	cv_agg's binary_logloss: 0.417126 + 0.000608095
[13]	cv_agg's binary_logloss: 0.41713 + 0.000603046
[14]	cv_agg's binary_logloss: 0.41713 + 0.000603046
[15]	cv_agg's binary_logloss: 0.41713 + 0.000603046
[1]	cv_agg's binary_logloss: 0.430206 + 0.000653446
[2]	cv_agg's binary_logloss: 0.422411 + 0.000597024
[3]	cv_agg's binary_logloss: 0.419393 + 0.000537608
[4]	cv_agg's binary_logloss: 0.418154 + 0.000668676
[5]	cv_agg's binary_logloss: 0.417816 + 0.000637082
[6]	cv_agg's binary_logloss: 0.417636 + 0.000836957
[7]	cv_agg's binary_logloss: 0.417546 + 0.000765488
[8]	cv_agg's binary_logloss: 0.417521 + 0.000780403
[9]	cv_agg's binary_logloss: 0.417508 + 0.000701294
[10]	cv_agg's binary_logloss: 0.417518 + 0.000725244
[11]	cv_agg's binary_logloss: 0.417518 + 0.000722444
[12]	cv_agg's binary_logloss: 0.417527 + 0.000735538
[1]	cv_agg's binary_logloss: 0.430268 + 0.000826382
[2]	cv_agg's binary_logloss: 0.422734 + 0.000447583
[3]	cv_agg's binary_logloss: 0.419554 + 0.000328686
[4]	cv_agg's binary_logloss: 0.417805 + 0.000404207
[5]	cv_agg's binary_logloss: 0.417562 + 0.000636143
[6]	cv_agg's binary_logloss: 0.417254 + 0.000896369
[7]	cv_agg's binary_logloss: 0.417548 + 0.00081307
[8]	cv_agg's binary_logloss: 0.417732 + 0.00100329
[9]	cv_agg's binary_logloss: 0.41801 + 0.00084759
[1]	cv_agg's binary_logloss: 0.430256 + 0.000828335
[2]	cv_agg's binary_logloss: 0.422772 + 0.000630936
[3]	cv_agg's binary_logloss: 0.419518 + 0.00065317
[4]	cv_agg's binary_logloss: 0.418016 + 0.000659453
[5]	cv_agg's binary_logloss: 0.417568 + 0.000936852
[6]	cv_agg's binary_logloss: 0.417411 + 0.0011504
[7]	cv_agg's binary_logloss: 0.417412 + 0.00131958
[8]	cv_agg's binary_logloss: 0.417602 + 0.00124486
[9]	cv_agg's binary_logloss: 0.417759 + 0.000990445
[1]	cv_agg's binary_logloss: 0.430216 + 0.000818763
[2]	cv_agg's binary_logloss: 0.422615 + 0.000710228
[3]	cv_agg's binary_logloss: 0.419615 + 0.000744502
[4]	cv_agg's binary_logloss: 0.417916 + 0.000697666
[5]	cv_agg's binary_logloss: 0.417541 + 0.000943023
[6]	cv_agg's binary_logloss: 0.417385 + 0.00108054
[7]	cv_agg's binary_logloss: 0.417265 + 0.00113296
[8]	cv_agg's binary_logloss: 0.4173 + 0.0011774
[9]	cv_agg's binary_logloss: 0.417243 + 0.00122336
[10]	cv_agg's binary_logloss: 0.417233 + 0.00121445
[11]	cv_agg's binary_logloss: 0.41724 + 0.00120421
[12]	cv_agg's binary_logloss: 0.41724 + 0.00120421
[13]	cv_agg's binary_logloss: 0.417239 + 0.00120656
[1]	cv_agg's binary_logloss: 0.430142 + 0.000611602
[2]	cv_agg's binary_logloss: 0.422503 + 0.000611018
[3]	cv_agg's binary_logloss: 0.419615 + 0.000522409
[4]	cv_agg's binary_logloss: 0.418214 + 0.000453028
[5]	cv_agg's binary_logloss: 0.417577 + 0.000594297
[6]	cv_agg's binary_logloss: 0.417547 + 0.000577332
[7]	cv_agg's binary_logloss: 0.417492 + 0.0006185
[8]	cv_agg's binary_logloss: 0.417431 + 0.000652517
[9]	cv_agg's binary_logloss: 0.417429 + 0.000666769
[10]	cv_agg's binary_logloss: 0.417423 + 0.000675272
[11]	cv_agg's binary_logloss: 0.417431 + 0.000657115
[12]	cv_agg's binary_logloss: 0.417441 + 0.000668853
[13]	cv_agg's binary_logloss: 0.417439 + 0.000671467
[1]	cv_agg's binary_logloss: 0.43016 + 0.000657783
[2]	cv_agg's binary_logloss: 0.422552 + 0.000514108
[3]	cv_agg's binary_logloss: 0.419556 + 0.000417024
[4]	cv_agg's binary_logloss: 0.418329 + 0.000375371
[5]	cv_agg's binary_logloss: 0.417997 + 0.000353664
[6]	cv_agg's binary_logloss: 0.417959 + 0.000387777
[7]	cv_agg's binary_logloss: 0.417826 + 0.000498704
[8]	cv_agg's binary_logloss: 0.417802 + 0.000499734
[9]	cv_agg's binary_logloss: 0.417774 + 0.000463454
[10]	cv_agg's binary_logloss: 0.417772 + 0.000464027
[11]	cv_agg's binary_logloss: 0.417772 + 0.000464027
[12]	cv_agg's binary_logloss: 0.417772 + 0.000464027
[13]	cv_agg's binary_logloss: 0.417772 + 0.000464027
[14]	cv_agg's binary_logloss: 0.417772 + 0.000464027
[1]	cv_agg's binary_logloss: 0.430292 + 0.000847722
[2]	cv_agg's binary_logloss: 0.422868 + 0.000655349
[3]	cv_agg's binary_logloss: 0.419718 + 0.000562318
[4]	cv_agg's binary_logloss: 0.417723 + 0.000480149
[5]	cv_agg's binary_logloss: 0.417787 + 0.000548518
[6]	cv_agg's binary_logloss: 0.417513 + 0.000446887
[7]	cv_agg's binary_logloss: 0.41764 + 0.00083432
[8]	cv_agg's binary_logloss: 0.417781 + 0.000820344
[9]	cv_agg's binary_logloss: 0.417902 + 0.000796775
[1]	cv_agg's binary_logloss: 0.430247 + 0.000858373
[2]	cv_agg's binary_logloss: 0.422767 + 0.00072341
[3]	cv_agg's binary_logloss: 0.419756 + 0.000529121
[4]	cv_agg's binary_logloss: 0.418152 + 0.00035103
[5]	cv_agg's binary_logloss: 0.417687 + 0.000338227
[6]	cv_agg's binary_logloss: 0.41762 + 0.000472817
[7]	cv_agg's binary_logloss: 0.417524 + 0.000396156
[8]	cv_agg's binary_logloss: 0.41752 + 0.000425003
[9]	cv_agg's binary_logloss: 0.417414 + 0.000498822
[10]	cv_agg's binary_logloss: 0.417399 + 0.000585742
[11]	cv_agg's binary_logloss: 0.417397 + 0.000570389
[12]	cv_agg's binary_logloss: 0.417406 + 0.000567629
[13]	cv_agg's binary_logloss: 0.4174 + 0.000567581
[14]	cv_agg's binary_logloss: 0.417402 + 0.000566836
[1]	cv_agg's binary_logloss: 0.430202 + 0.000836191
[2]	cv_agg's binary_logloss: 0.422554 + 0.00083562
[3]	cv_agg's binary_logloss: 0.419592 + 0.000752002
[4]	cv_agg's binary_logloss: 0.418156 + 0.000552871
[5]	cv_agg's binary_logloss: 0.417948 + 0.000740959
[6]	cv_agg's binary_logloss: 0.417823 + 0.000665771
[7]	cv_agg's binary_logloss: 0.417616 + 0.000640081
[8]	cv_agg's binary_logloss: 0.417648 + 0.00066794
[9]	cv_agg's binary_logloss: 0.417675 + 0.000730067
[10]	cv_agg's binary_logloss: 0.417669 + 0.000736563
[1]	cv_agg's binary_logloss: 0.43014 + 0.000645446
[2]	cv_agg's binary_logloss: 0.422523 + 0.000617192
[3]	cv_agg's binary_logloss: 0.419528 + 0.000427522
[4]	cv_agg's binary_logloss: 0.418154 + 0.000451084
[5]	cv_agg's binary_logloss: 0.417711 + 0.000535294
[6]	cv_agg's binary_logloss: 0.417492 + 0.000643755
[7]	cv_agg's binary_logloss: 0.417366 + 0.000599606
[8]	cv_agg's binary_logloss: 0.417374 + 0.000618797
[9]	cv_agg's binary_logloss: 0.417385 + 0.000612917
[10]	cv_agg's binary_logloss: 0.417408 + 0.000633191
[1]	cv_agg's binary_logloss: 0.430172 + 0.000609036
[2]	cv_agg's binary_logloss: 0.422552 + 0.000615232
[3]	cv_agg's binary_logloss: 0.419541 + 0.000555034
[4]	cv_agg's binary_logloss: 0.418227 + 0.000668349
[5]	cv_agg's binary_logloss: 0.417657 + 0.000704929
[6]	cv_agg's binary_logloss: 0.417486 + 0.000756536
[7]	cv_agg's binary_logloss: 0.417419 + 0.00074112
[8]	cv_agg's binary_logloss: 0.417432 + 0.000764319
[9]	cv_agg's binary_logloss: 0.417372 + 0.000820883
[10]	cv_agg's binary_logloss: 0.417372 + 0.000817172
[11]	cv_agg's binary_logloss: 0.417375 + 0.000812904
[12]	cv_agg's binary_logloss: 0.417385 + 0.000823753
[13]	cv_agg's binary_logloss: 0.417384 + 0.000822847
[1]	cv_agg's binary_logloss: 0.430214 + 0.000873586
[2]	cv_agg's binary_logloss: 0.422749 + 0.000713854
[3]	cv_agg's binary_logloss: 0.419502 + 0.000622923
[4]	cv_agg's binary_logloss: 0.417766 + 0.000589616
[5]	cv_agg's binary_logloss: 0.417626 + 0.00092772
[6]	cv_agg's binary_logloss: 0.417452 + 0.00096803
[7]	cv_agg's binary_logloss: 0.417678 + 0.00100855
[8]	cv_agg's binary_logloss: 0.417874 + 0.000696
[9]	cv_agg's binary_logloss: 0.418055 + 0.000650273
[1]	cv_agg's binary_logloss: 0.430194 + 0.000899141
[2]	cv_agg's binary_logloss: 0.422631 + 0.000856287
[3]	cv_agg's binary_logloss: 0.419555 + 0.000707496
[4]	cv_agg's binary_logloss: 0.417738 + 0.000437747
[5]	cv_agg's binary_logloss: 0.417461 + 0.000518012
[6]	cv_agg's binary_logloss: 0.417189 + 0.000748906
[7]	cv_agg's binary_logloss: 0.417244 + 0.000887442
[8]	cv_agg's binary_logloss: 0.417178 + 0.00107827
[9]	cv_agg's binary_logloss: 0.417149 + 0.00130773
[10]	cv_agg's binary_logloss: 0.417313 + 0.00121244
[11]	cv_agg's binary_logloss: 0.417341 + 0.00115836
[12]	cv_agg's binary_logloss: 0.417351 + 0.00116438
[1]	cv_agg's binary_logloss: 0.430188 + 0.000845975
[2]	cv_agg's binary_logloss: 0.422633 + 0.000948789
[3]	cv_agg's binary_logloss: 0.419581 + 0.000785211
[4]	cv_agg's binary_logloss: 0.418087 + 0.00049426
[5]	cv_agg's binary_logloss: 0.417496 + 0.000626362
[6]	cv_agg's binary_logloss: 0.417425 + 0.000454106
[7]	cv_agg's binary_logloss: 0.417248 + 0.000616814
[8]	cv_agg's binary_logloss: 0.417217 + 0.000735491
[9]	cv_agg's binary_logloss: 0.417216 + 0.000642651
[10]	cv_agg's binary_logloss: 0.417199 + 0.000648686
[11]	cv_agg's binary_logloss: 0.417202 + 0.000644833
[12]	cv_agg's binary_logloss: 0.417201 + 0.000645746
[13]	cv_agg's binary_logloss: 0.417204 + 0.000642643
[1]	cv_agg's binary_logloss: 0.430174 + 0.000701071
[2]	cv_agg's binary_logloss: 0.4225 + 0.000609994
[3]	cv_agg's binary_logloss: 0.419656 + 0.000653711
[4]	cv_agg's binary_logloss: 0.418337 + 0.000681408
[5]	cv_agg's binary_logloss: 0.417904 + 0.000812508
[6]	cv_agg's binary_logloss: 0.417611 + 0.000750819
[7]	cv_agg's binary_logloss: 0.417551 + 0.000855948
[8]	cv_agg's binary_logloss: 0.417507 + 0.000907152
[9]	cv_agg's binary_logloss: 0.417435 + 0.000812657
[10]	cv_agg's binary_logloss: 0.417436 + 0.000813837
[11]	cv_agg's binary_logloss: 0.417437 + 0.000805833
[12]	cv_agg's binary_logloss: 0.417432 + 0.000811558
[13]	cv_agg's binary_logloss: 0.417435 + 0.000815093
[14]	cv_agg's binary_logloss: 0.417435 + 0.000815093
[15]	cv_agg's binary_logloss: 0.417435 + 0.000815093
[1]	cv_agg's binary_logloss: 0.430172 + 0.000616804
[2]	cv_agg's binary_logloss: 0.422468 + 0.000619001
[3]	cv_agg's binary_logloss: 0.419497 + 0.000603692
[4]	cv_agg's binary_logloss: 0.41826 + 0.000974173
[5]	cv_agg's binary_logloss: 0.417789 + 0.00125161
[6]	cv_agg's binary_logloss: 0.417712 + 0.00119913
[7]	cv_agg's binary_logloss: 0.417666 + 0.00118095
[8]	cv_agg's binary_logloss: 0.417664 + 0.00122089
[9]	cv_agg's binary_logloss: 0.417642 + 0.00122634
[10]	cv_agg's binary_logloss: 0.417641 + 0.00123694
[11]	cv_agg's binary_logloss: 0.417634 + 0.00123909
[12]	cv_agg's binary_logloss: 0.417634 + 0.00123909
[13]	cv_agg's binary_logloss: 0.417634 + 0.00123909
[14]	cv_agg's binary_logloss: 0.417634 + 0.00123909
[15]	cv_agg's binary_logloss: 0.417634 + 0.00123909
[1]	cv_agg's binary_logloss: 0.430235 + 0.000867173
[2]	cv_agg's binary_logloss: 0.422679 + 0.000770374
[3]	cv_agg's binary_logloss: 0.419492 + 0.000619017
[4]	cv_agg's binary_logloss: 0.417705 + 0.000348952
[5]	cv_agg's binary_logloss: 0.417477 + 0.000577756
[6]	cv_agg's binary_logloss: 0.417409 + 0.000481521
[7]	cv_agg's binary_logloss: 0.417417 + 0.000441557
[8]	cv_agg's binary_logloss: 0.417433 + 0.000514887
[9]	cv_agg's binary_logloss: 0.417463 + 0.000679449
[1]	cv_agg's binary_logloss: 0.430225 + 0.000887031
[2]	cv_agg's binary_logloss: 0.422699 + 0.000816895
[3]	cv_agg's binary_logloss: 0.419534 + 0.000705494
[4]	cv_agg's binary_logloss: 0.417926 + 0.000333779
[5]	cv_agg's binary_logloss: 0.417559 + 0.000347914
[6]	cv_agg's binary_logloss: 0.417486 + 0.000468837
[7]	cv_agg's binary_logloss: 0.417428 + 0.000488989
[8]	cv_agg's binary_logloss: 0.417511 + 0.000468632
[9]	cv_agg's binary_logloss: 0.417539 + 0.000521004
[10]	cv_agg's binary_logloss: 0.417677 + 0.000469878
[1]	cv_agg's binary_logloss: 0.430189 + 0.000856207
[2]	cv_agg's binary_logloss: 0.422587 + 0.000965042
[3]	cv_agg's binary_logloss: 0.41934 + 0.000793247
[4]	cv_agg's binary_logloss: 0.4178 + 0.000636567
[5]	cv_agg's binary_logloss: 0.417429 + 0.000707631
[6]	cv_agg's binary_logloss: 0.417253 + 0.000851043
[7]	cv_agg's binary_logloss: 0.417254 + 0.000973314
[8]	cv_agg's binary_logloss: 0.417251 + 0.00107544
[9]	cv_agg's binary_logloss: 0.41718 + 0.00113482
[10]	cv_agg's binary_logloss: 0.417169 + 0.00111673
[11]	cv_agg's binary_logloss: 0.417161 + 0.00113133
[12]	cv_agg's binary_logloss: 0.417166 + 0.00112572
[13]	cv_agg's binary_logloss: 0.417166 + 0.0011262
[14]	cv_agg's binary_logloss: 0.417166 + 0.0011262
[1]	cv_agg's binary_logloss: 0.430173 + 0.000689143
[2]	cv_agg's binary_logloss: 0.422481 + 0.000719182
[3]	cv_agg's binary_logloss: 0.419135 + 0.000662399
[4]	cv_agg's binary_logloss: 0.417748 + 0.000568792
[5]	cv_agg's binary_logloss: 0.417351 + 0.000490831
[6]	cv_agg's binary_logloss: 0.417254 + 0.00055736
[7]	cv_agg's binary_logloss: 0.417171 + 0.000398557
[8]	cv_agg's binary_logloss: 0.417148 + 0.000438154
[9]	cv_agg's binary_logloss: 0.417219 + 0.000384032
[10]	cv_agg's binary_logloss: 0.417211 + 0.000397762
[11]	cv_agg's binary_logloss: 0.417217 + 0.000396118
[1]	cv_agg's binary_logloss: 0.430183 + 0.000620651
[2]	cv_agg's binary_logloss: 0.42243 + 0.000698987
[3]	cv_agg's binary_logloss: 0.419444 + 0.000525611
[4]	cv_agg's binary_logloss: 0.418407 + 0.000934971
[5]	cv_agg's binary_logloss: 0.417859 + 0.00114216
[6]	cv_agg's binary_logloss: 0.417736 + 0.00111056
[7]	cv_agg's binary_logloss: 0.417757 + 0.00110759
[8]	cv_agg's binary_logloss: 0.417782 + 0.00110067
[9]	cv_agg's binary_logloss: 0.417783 + 0.00105078
[1]	cv_agg's binary_logloss: 0.430205 + 0.00086594
[2]	cv_agg's binary_logloss: 0.422626 + 0.000710744
[3]	cv_agg's binary_logloss: 0.419386 + 0.000581254
[4]	cv_agg's binary_logloss: 0.417722 + 0.000605815
[5]	cv_agg's binary_logloss: 0.417426 + 0.000531521
[6]	cv_agg's binary_logloss: 0.41752 + 0.000441707
[7]	cv_agg's binary_logloss: 0.417577 + 0.000518924
[8]	cv_agg's binary_logloss: 0.417659 + 0.000663903
[1]	cv_agg's binary_logloss: 0.430178 + 0.000874732
[2]	cv_agg's binary_logloss: 0.422586 + 0.000767935
[3]	cv_agg's binary_logloss: 0.419319 + 0.000626013
[4]	cv_agg's binary_logloss: 0.41788 + 0.000582381
[5]	cv_agg's binary_logloss: 0.417676 + 0.000771896
[6]	cv_agg's binary_logloss: 0.417563 + 0.00100113
[7]	cv_agg's binary_logloss: 0.417662 + 0.00101709
[8]	cv_agg's binary_logloss: 0.417844 + 0.00103925
[9]	cv_agg's binary_logloss: 0.417929 + 0.00102512
[1]	cv_agg's binary_logloss: 0.43014 + 0.000815084
[2]	cv_agg's binary_logloss: 0.422407 + 0.000773979
[3]	cv_agg's binary_logloss: 0.419295 + 0.000537007
[4]	cv_agg's binary_logloss: 0.417852 + 0.000494646
[5]	cv_agg's binary_logloss: 0.417349 + 0.000695109
[6]	cv_agg's binary_logloss: 0.417218 + 0.000721504
[7]	cv_agg's binary_logloss: 0.417028 + 0.000818811
[8]	cv_agg's binary_logloss: 0.416972 + 0.000757649
[9]	cv_agg's binary_logloss: 0.416948 + 0.000769272
[10]	cv_agg's binary_logloss: 0.416938 + 0.000782975
[11]	cv_agg's binary_logloss: 0.416943 + 0.000777428
[12]	cv_agg's binary_logloss: 0.416944 + 0.000779144
[13]	cv_agg's binary_logloss: 0.416941 + 0.000776965
[1]	cv_agg's binary_logloss: 0.430225 + 0.000698112
[2]	cv_agg's binary_logloss: 0.422454 + 0.000642502
[3]	cv_agg's binary_logloss: 0.419421 + 0.00100842
[4]	cv_agg's binary_logloss: 0.418167 + 0.000958629
[5]	cv_agg's binary_logloss: 0.417847 + 0.00098626
[6]	cv_agg's binary_logloss: 0.417816 + 0.000887448
[7]	cv_agg's binary_logloss: 0.417779 + 0.000887762
[8]	cv_agg's binary_logloss: 0.41774 + 0.000920302
[9]	cv_agg's binary_logloss: 0.417719 + 0.000920269
[10]	cv_agg's binary_logloss: 0.417715 + 0.000922235
[11]	cv_agg's binary_logloss: 0.417717 + 0.000921852
[12]	cv_agg's binary_logloss: 0.417715 + 0.000923877
[13]	cv_agg's binary_logloss: 0.417718 + 0.000920556
[14]	cv_agg's binary_logloss: 0.417718 + 0.000920556
[15]	cv_agg's binary_logloss: 0.417718 + 0.000920556
[1]	cv_agg's binary_logloss: 0.430278 + 0.000608359
[2]	cv_agg's binary_logloss: 0.422521 + 0.000649979
[3]	cv_agg's binary_logloss: 0.419527 + 0.000712452
[4]	cv_agg's binary_logloss: 0.418264 + 0.000699965
[5]	cv_agg's binary_logloss: 0.417873 + 0.000727846
[6]	cv_agg's binary_logloss: 0.417682 + 0.000805021
[7]	cv_agg's binary_logloss: 0.417503 + 0.000862246
[8]	cv_agg's binary_logloss: 0.417518 + 0.000884594
[9]	cv_agg's binary_logloss: 0.417525 + 0.000880058
[10]	cv_agg's binary_logloss: 0.417523 + 0.000895435
[1]	cv_agg's binary_logloss: 0.430249 + 0.000861336
[2]	cv_agg's binary_logloss: 0.422555 + 0.000842483
[3]	cv_agg's binary_logloss: 0.419493 + 0.00057649
[4]	cv_agg's binary_logloss: 0.417922 + 0.000420911
[5]	cv_agg's binary_logloss: 0.417609 + 0.000627881
[6]	cv_agg's binary_logloss: 0.417402 + 0.000398407
[7]	cv_agg's binary_logloss: 0.417417 + 0.000513275
[8]	cv_agg's binary_logloss: 0.417565 + 0.000506202
[9]	cv_agg's binary_logloss: 0.417607 + 0.000335891
[1]	cv_agg's binary_logloss: 0.430251 + 0.000885315
[2]	cv_agg's binary_logloss: 0.422691 + 0.000794704
[3]	cv_agg's binary_logloss: 0.41982 + 0.000753917
[4]	cv_agg's binary_logloss: 0.41842 + 0.000531056
[5]	cv_agg's binary_logloss: 0.417891 + 0.000660081
[6]	cv_agg's binary_logloss: 0.417806 + 0.000925928
[7]	cv_agg's binary_logloss: 0.41765 + 0.00089348
[8]	cv_agg's binary_logloss: 0.417726 + 0.00094184
[9]	cv_agg's binary_logloss: 0.41759 + 0.000772838
[10]	cv_agg's binary_logloss: 0.417553 + 0.000767358
[11]	cv_agg's binary_logloss: 0.417549 + 0.000759558
[12]	cv_agg's binary_logloss: 0.417544 + 0.000758404
[13]	cv_agg's binary_logloss: 0.417559 + 0.000765829
[14]	cv_agg's binary_logloss: 0.417553 + 0.000760696
[15]	cv_agg's binary_logloss: 0.417568 + 0.000774456
[1]	cv_agg's binary_logloss: 0.430138 + 0.000813746
[2]	cv_agg's binary_logloss: 0.422591 + 0.000881488
[3]	cv_agg's binary_logloss: 0.419561 + 0.000855686
[4]	cv_agg's binary_logloss: 0.417916 + 0.00086976
[5]	cv_agg's binary_logloss: 0.417464 + 0.000960193
[6]	cv_agg's binary_logloss: 0.417164 + 0.001053
[7]	cv_agg's binary_logloss: 0.417122 + 0.00120411
[8]	cv_agg's binary_logloss: 0.417141 + 0.00128
[9]	cv_agg's binary_logloss: 0.417194 + 0.00130666
[10]	cv_agg's binary_logloss: 0.417216 + 0.00132032
[1]	cv_agg's binary_logloss: 0.430212 + 0.000665021
[2]	cv_agg's binary_logloss: 0.422572 + 0.000658796
[3]	cv_agg's binary_logloss: 0.419791 + 0.000613808
[4]	cv_agg's binary_logloss: 0.418357 + 0.00079074
[5]	cv_agg's binary_logloss: 0.417722 + 0.000762214
[6]	cv_agg's binary_logloss: 0.417592 + 0.000876429
[7]	cv_agg's binary_logloss: 0.417595 + 0.000923752
[8]	cv_agg's binary_logloss: 0.417574 + 0.000937513
[9]	cv_agg's binary_logloss: 0.417538 + 0.000988588
[10]	cv_agg's binary_logloss: 0.417538 + 0.000990837
[11]	cv_agg's binary_logloss: 0.417543 + 0.000978877
[12]	cv_agg's binary_logloss: 0.417548 + 0.000986392
[1]	cv_agg's binary_logloss: 0.430218 + 0.000672419
[2]	cv_agg's binary_logloss: 0.422524 + 0.000668668
[3]	cv_agg's binary_logloss: 0.419437 + 0.000352959
[4]	cv_agg's binary_logloss: 0.418174 + 0.000652946
[5]	cv_agg's binary_logloss: 0.417803 + 0.000736464
[6]	cv_agg's binary_logloss: 0.417542 + 0.000796001
[7]	cv_agg's binary_logloss: 0.417385 + 0.000865172
[8]	cv_agg's binary_logloss: 0.417382 + 0.000893765
[9]	cv_agg's binary_logloss: 0.417357 + 0.000896534
[10]	cv_agg's binary_logloss: 0.417344 + 0.000891681
[11]	cv_agg's binary_logloss: 0.417354 + 0.000897185
[12]	cv_agg's binary_logloss: 0.417354 + 0.000897185
[13]	cv_agg's binary_logloss: 0.417354 + 0.000897185
[1]	cv_agg's binary_logloss: 0.430198 + 0.000883307
[2]	cv_agg's binary_logloss: 0.422745 + 0.000766909
[3]	cv_agg's binary_logloss: 0.419461 + 0.000660403
[4]	cv_agg's binary_logloss: 0.417782 + 0.000390239
[5]	cv_agg's binary_logloss: 0.417284 + 0.000374418
[6]	cv_agg's binary_logloss: 0.417361 + 0.000472381
[7]	cv_agg's binary_logloss: 0.417483 + 0.0006982
[8]	cv_agg's binary_logloss: 0.417656 + 0.000785271
[1]	cv_agg's binary_logloss: 0.430135 + 0.000886674
[2]	cv_agg's binary_logloss: 0.422591 + 0.000863818
[3]	cv_agg's binary_logloss: 0.419495 + 0.000699429
[4]	cv_agg's binary_logloss: 0.417913 + 0.000624022
[5]	cv_agg's binary_logloss: 0.417454 + 0.000609049
[6]	cv_agg's binary_logloss: 0.417309 + 0.000902542
[7]	cv_agg's binary_logloss: 0.417274 + 0.000853346
[8]	cv_agg's binary_logloss: 0.417325 + 0.000840862
[9]	cv_agg's binary_logloss: 0.417436 + 0.000786804
[10]	cv_agg's binary_logloss: 0.417435 + 0.000845906
[1]	cv_agg's binary_logloss: 0.430111 + 0.000827752
[2]	cv_agg's binary_logloss: 0.422594 + 0.000893017
[3]	cv_agg's binary_logloss: 0.419468 + 0.000931086
[4]	cv_agg's binary_logloss: 0.418153 + 0.000894322
[5]	cv_agg's binary_logloss: 0.417695 + 0.000881111
[6]	cv_agg's binary_logloss: 0.417493 + 0.00112337
[7]	cv_agg's binary_logloss: 0.417355 + 0.00107153
[8]	cv_agg's binary_logloss: 0.417342 + 0.00105707
[9]	cv_agg's binary_logloss: 0.417369 + 0.00113309
[10]	cv_agg's binary_logloss: 0.417354 + 0.00113826
[11]	cv_agg's binary_logloss: 0.417345 + 0.00113787
[1]	cv_agg's binary_logloss: 0.430148 + 0.000633436
[2]	cv_agg's binary_logloss: 0.422526 + 0.000632412
[3]	cv_agg's binary_logloss: 0.419681 + 0.00058173
[4]	cv_agg's binary_logloss: 0.418199 + 0.000764825
[5]	cv_agg's binary_logloss: 0.417714 + 0.000766204
[6]	cv_agg's binary_logloss: 0.417589 + 0.000843153
[7]	cv_agg's binary_logloss: 0.417532 + 0.000910132
[8]	cv_agg's binary_logloss: 0.417524 + 0.000915136
[9]	cv_agg's binary_logloss: 0.417587 + 0.00089621
[10]	cv_agg's binary_logloss: 0.417592 + 0.000901701
[11]	cv_agg's binary_logloss: 0.417592 + 0.00089952
[1]	cv_agg's binary_logloss: 0.430198 + 0.000688798
[2]	cv_agg's binary_logloss: 0.422441 + 0.000555322
[3]	cv_agg's binary_logloss: 0.419688 + 0.000808544
[4]	cv_agg's binary_logloss: 0.41857 + 0.000754137
[5]	cv_agg's binary_logloss: 0.418108 + 0.00091538
[6]	cv_agg's binary_logloss: 0.417989 + 0.000949871
[7]	cv_agg's binary_logloss: 0.417871 + 0.000896332
[8]	cv_agg's binary_logloss: 0.417873 + 0.00092331
[9]	cv_agg's binary_logloss: 0.417863 + 0.00091511
[10]	cv_agg's binary_logloss: 0.41787 + 0.000922679
[11]	cv_agg's binary_logloss: 0.417875 + 0.000913831
[12]	cv_agg's binary_logloss: 0.417875 + 0.000913831
[1]	cv_agg's binary_logloss: 0.43021 + 0.000848463
[2]	cv_agg's binary_logloss: 0.422714 + 0.000784875
[3]	cv_agg's binary_logloss: 0.419427 + 0.000630524
[4]	cv_agg's binary_logloss: 0.417856 + 0.000682848
[5]	cv_agg's binary_logloss: 0.417737 + 0.000956978
[6]	cv_agg's binary_logloss: 0.417755 + 0.000827964
[7]	cv_agg's binary_logloss: 0.417896 + 0.000877488
[8]	cv_agg's binary_logloss: 0.417864 + 0.000936602
[1]	cv_agg's binary_logloss: 0.430167 + 0.000853475
[2]	cv_agg's binary_logloss: 0.422553 + 0.000862377
[3]	cv_agg's binary_logloss: 0.419381 + 0.00071508
[4]	cv_agg's binary_logloss: 0.417926 + 0.000629229
[5]	cv_agg's binary_logloss: 0.417099 + 0.000729746
[6]	cv_agg's binary_logloss: 0.417114 + 0.000924218
[7]	cv_agg's binary_logloss: 0.417161 + 0.000891586
[8]	cv_agg's binary_logloss: 0.41726 + 0.000790028
[1]	cv_agg's binary_logloss: 0.430135 + 0.000803832
[2]	cv_agg's binary_logloss: 0.422428 + 0.000741549
[3]	cv_agg's binary_logloss: 0.419283 + 0.000672131
[4]	cv_agg's binary_logloss: 0.41787 + 0.000528477
[5]	cv_agg's binary_logloss: 0.417352 + 0.000605353
[6]	cv_agg's binary_logloss: 0.41726 + 0.000652978
[7]	cv_agg's binary_logloss: 0.417277 + 0.000817213
[8]	cv_agg's binary_logloss: 0.417264 + 0.000808508
[9]	cv_agg's binary_logloss: 0.417321 + 0.000798007
[1]	cv_agg's binary_logloss: 0.430173 + 0.000606432
[2]	cv_agg's binary_logloss: 0.422443 + 0.000686436
[3]	cv_agg's binary_logloss: 0.419418 + 0.000651442
[4]	cv_agg's binary_logloss: 0.418151 + 0.000883209
[5]	cv_agg's binary_logloss: 0.417587 + 0.000831046
[6]	cv_agg's binary_logloss: 0.417357 + 0.00095464
[7]	cv_agg's binary_logloss: 0.41732 + 0.000917344
[8]	cv_agg's binary_logloss: 0.417325 + 0.000944922
[9]	cv_agg's binary_logloss: 0.417307 + 0.000936038
[10]	cv_agg's binary_logloss: 0.4173 + 0.000942986
[11]	cv_agg's binary_logloss: 0.417309 + 0.00092935
[12]	cv_agg's binary_logloss: 0.417304 + 0.000935687
[13]	cv_agg's binary_logloss: 0.417289 + 0.00095249
[14]	cv_agg's binary_logloss: 0.417289 + 0.00095249
[15]	cv_agg's binary_logloss: 0.417289 + 0.00095249
[16]	cv_agg's binary_logloss: 0.417289 + 0.00095249
[1]	cv_agg's binary_logloss: 0.430245 + 0.000649334
[2]	cv_agg's binary_logloss: 0.42241 + 0.000553413
[3]	cv_agg's binary_logloss: 0.419563 + 0.000713732
[4]	cv_agg's binary_logloss: 0.41855 + 0.000774966
[5]	cv_agg's binary_logloss: 0.41804 + 0.000922835
[6]	cv_agg's binary_logloss: 0.417782 + 0.000976727
[7]	cv_agg's binary_logloss: 0.417799 + 0.00096057
[8]	cv_agg's binary_logloss: 0.417798 + 0.000961872
[9]	cv_agg's binary_logloss: 0.417789 + 0.00094449
[1]	cv_agg's binary_logloss: 0.43018 + 0.000876093
[2]	cv_agg's binary_logloss: 0.422625 + 0.000812338
[3]	cv_agg's binary_logloss: 0.419434 + 0.000840821
[4]	cv_agg's binary_logloss: 0.417893 + 0.000819727
[5]	cv_agg's binary_logloss: 0.417638 + 0.00100005
[6]	cv_agg's binary_logloss: 0.417585 + 0.00100888
[7]	cv_agg's binary_logloss: 0.417497 + 0.0010309
[8]	cv_agg's binary_logloss: 0.417741 + 0.00109689
[9]	cv_agg's binary_logloss: 0.417784 + 0.00111664
[10]	cv_agg's binary_logloss: 0.418129 + 0.00096013
[1]	cv_agg's binary_logloss: 0.430184 + 0.000881946
[2]	cv_agg's binary_logloss: 0.422473 + 0.00075835
[3]	cv_agg's binary_logloss: 0.41939 + 0.000552942
[4]	cv_agg's binary_logloss: 0.418018 + 0.000704851
[5]	cv_agg's binary_logloss: 0.41743 + 0.00102412
[6]	cv_agg's binary_logloss: 0.417289 + 0.00121899
[7]	cv_agg's binary_logloss: 0.417235 + 0.00121249
[8]	cv_agg's binary_logloss: 0.417281 + 0.0013186
[9]	cv_agg's binary_logloss: 0.417289 + 0.00126876
[10]	cv_agg's binary_logloss: 0.417281 + 0.00143724
[1]	cv_agg's binary_logloss: 0.430152 + 0.000808887
[2]	cv_agg's binary_logloss: 0.422452 + 0.000780051
[3]	cv_agg's binary_logloss: 0.419201 + 0.000660767
[4]	cv_agg's binary_logloss: 0.417729 + 0.000457521
[5]	cv_agg's binary_logloss: 0.417324 + 0.000419055
[6]	cv_agg's binary_logloss: 0.417196 + 0.00039047
[7]	cv_agg's binary_logloss: 0.417023 + 0.000481738
[8]	cv_agg's binary_logloss: 0.417093 + 0.000488142
[9]	cv_agg's binary_logloss: 0.417127 + 0.000476025
[10]	cv_agg's binary_logloss: 0.417133 + 0.000466043
[1]	cv_agg's binary_logloss: 0.430264 + 0.000619629
[2]	cv_agg's binary_logloss: 0.42252 + 0.000580878
[3]	cv_agg's binary_logloss: 0.419552 + 0.00051799
[4]	cv_agg's binary_logloss: 0.418305 + 0.000644982
[5]	cv_agg's binary_logloss: 0.417706 + 0.000595287
[6]	cv_agg's binary_logloss: 0.41753 + 0.000522731
[7]	cv_agg's binary_logloss: 0.417366 + 0.00050124
[8]	cv_agg's binary_logloss: 0.417328 + 0.00044009
[9]	cv_agg's binary_logloss: 0.417331 + 0.000418891
[10]	cv_agg's binary_logloss: 0.417304 + 0.000396783
[11]	cv_agg's binary_logloss: 0.417296 + 0.00040327
[12]	cv_agg's binary_logloss: 0.417286 + 0.000413466
[13]	cv_agg's binary_logloss: 0.417286 + 0.000413466
[14]	cv_agg's binary_logloss: 0.417286 + 0.000413466
[15]	cv_agg's binary_logloss: 0.417286 + 0.000413466
[1]	cv_agg's binary_logloss: 0.430299 + 0.000649426
[2]	cv_agg's binary_logloss: 0.422473 + 0.000602338
[3]	cv_agg's binary_logloss: 0.419711 + 0.000777763
[4]	cv_agg's binary_logloss: 0.418465 + 0.000713222
[5]	cv_agg's binary_logloss: 0.418009 + 0.00062194
[6]	cv_agg's binary_logloss: 0.417909 + 0.000584677
[7]	cv_agg's binary_logloss: 0.41784 + 0.000634882
[8]	cv_agg's binary_logloss: 0.417841 + 0.000675444
[9]	cv_agg's binary_logloss: 0.417825 + 0.000671961
[10]	cv_agg's binary_logloss: 0.417834 + 0.00067822
[11]	cv_agg's binary_logloss: 0.417846 + 0.000669241
[12]	cv_agg's binary_logloss: 0.417846 + 0.000669241
[1]	cv_agg's binary_logloss: 0.430068 + 0.000725465
[2]	cv_agg's binary_logloss: 0.422528 + 0.000710354
[3]	cv_agg's binary_logloss: 0.419315 + 0.000666092
[4]	cv_agg's binary_logloss: 0.41795 + 0.00062195
[5]	cv_agg's binary_logloss: 0.417537 + 0.000481951
[6]	cv_agg's binary_logloss: 0.417459 + 0.000540969
[7]	cv_agg's binary_logloss: 0.417326 + 0.000586036
[8]	cv_agg's binary_logloss: 0.417385 + 0.000565794
[9]	cv_agg's binary_logloss: 0.417507 + 0.000412318
[10]	cv_agg's binary_logloss: 0.417612 + 0.000464665
[1]	cv_agg's binary_logloss: 0.430062 + 0.000718296
[2]	cv_agg's binary_logloss: 0.422385 + 0.000707783
[3]	cv_agg's binary_logloss: 0.419218 + 0.000497791
[4]	cv_agg's binary_logloss: 0.417762 + 0.000311784
[5]	cv_agg's binary_logloss: 0.417387 + 0.000454827
[6]	cv_agg's binary_logloss: 0.417184 + 0.000538131
[7]	cv_agg's binary_logloss: 0.417319 + 0.000659892
[8]	cv_agg's binary_logloss: 0.417472 + 0.000639744
[9]	cv_agg's binary_logloss: 0.417496 + 0.000705908
[1]	cv_agg's binary_logloss: 0.430089 + 0.000625307
[2]	cv_agg's binary_logloss: 0.422515 + 0.00080543
[3]	cv_agg's binary_logloss: 0.419325 + 0.000688088
[4]	cv_agg's binary_logloss: 0.418085 + 0.000640679
[5]	cv_agg's binary_logloss: 0.41769 + 0.000647129
[6]	cv_agg's binary_logloss: 0.417781 + 0.000239227
[7]	cv_agg's binary_logloss: 0.41761 + 0.000396332
[8]	cv_agg's binary_logloss: 0.417555 + 0.00033778
[9]	cv_agg's binary_logloss: 0.41758 + 0.000292022
[10]	cv_agg's binary_logloss: 0.417589 + 0.000299042
[11]	cv_agg's binary_logloss: 0.417592 + 0.00029525
[1]	cv_agg's binary_logloss: 0.430135 + 0.00039218
[2]	cv_agg's binary_logloss: 0.422539 + 0.000629735
[3]	cv_agg's binary_logloss: 0.4195 + 0.00048664
[4]	cv_agg's binary_logloss: 0.418246 + 0.000577012
[5]	cv_agg's binary_logloss: 0.417627 + 0.000774118
[6]	cv_agg's binary_logloss: 0.417412 + 0.000676492
[7]	cv_agg's binary_logloss: 0.417383 + 0.000673655
[8]	cv_agg's binary_logloss: 0.417344 + 0.00069526
[9]	cv_agg's binary_logloss: 0.417382 + 0.000723066
[10]	cv_agg's binary_logloss: 0.417386 + 0.000739282
[11]	cv_agg's binary_logloss: 0.417386 + 0.000723818
[1]	cv_agg's binary_logloss: 0.430079 + 0.000433616
[2]	cv_agg's binary_logloss: 0.422502 + 0.000628502
[3]	cv_agg's binary_logloss: 0.419486 + 0.000429684
[4]	cv_agg's binary_logloss: 0.41824 + 0.000454678
[5]	cv_agg's binary_logloss: 0.417716 + 0.000635458
[6]	cv_agg's binary_logloss: 0.417536 + 0.000550032
[7]	cv_agg's binary_logloss: 0.417431 + 0.000523634
[8]	cv_agg's binary_logloss: 0.417417 + 0.000532212
[9]	cv_agg's binary_logloss: 0.417386 + 0.000504402
[10]	cv_agg's binary_logloss: 0.417385 + 0.000517013
[11]	cv_agg's binary_logloss: 0.417401 + 0.000495156
[12]	cv_agg's binary_logloss: 0.417401 + 0.000495156
[13]	cv_agg's binary_logloss: 0.417401 + 0.000495156
[1]	cv_agg's binary_logloss: 0.430125 + 0.000904412
[2]	cv_agg's binary_logloss: 0.422644 + 0.000803706
[3]	cv_agg's binary_logloss: 0.419456 + 0.000843396
[4]	cv_agg's binary_logloss: 0.417818 + 0.000833774
[5]	cv_agg's binary_logloss: 0.417494 + 0.000918773
[6]	cv_agg's binary_logloss: 0.417378 + 0.000734247
[7]	cv_agg's binary_logloss: 0.417289 + 0.000874303
[8]	cv_agg's binary_logloss: 0.41739 + 0.0010894
[9]	cv_agg's binary_logloss: 0.417709 + 0.00100889
[10]	cv_agg's binary_logloss: 0.417795 + 0.000874974
[1]	cv_agg's binary_logloss: 0.430119 + 0.000896735
[2]	cv_agg's binary_logloss: 0.422552 + 0.000853239
[3]	cv_agg's binary_logloss: 0.419563 + 0.000750108
[4]	cv_agg's binary_logloss: 0.418166 + 0.000466577
[5]	cv_agg's binary_logloss: 0.417633 + 0.000521475
[6]	cv_agg's binary_logloss: 0.417487 + 0.000537998
[7]	cv_agg's binary_logloss: 0.417302 + 0.000442285
[8]	cv_agg's binary_logloss: 0.417385 + 0.000485897
[9]	cv_agg's binary_logloss: 0.417535 + 0.000693045
[10]	cv_agg's binary_logloss: 0.417535 + 0.00073239
[1]	cv_agg's binary_logloss: 0.430146 + 0.000737723
[2]	cv_agg's binary_logloss: 0.42263 + 0.000882288
[3]	cv_agg's binary_logloss: 0.41947 + 0.000874223
[4]	cv_agg's binary_logloss: 0.417912 + 0.000625098
[5]	cv_agg's binary_logloss: 0.417623 + 0.000812694
[6]	cv_agg's binary_logloss: 0.417549 + 0.000754771
[7]	cv_agg's binary_logloss: 0.417636 + 0.000808756
[8]	cv_agg's binary_logloss: 0.417623 + 0.000890376
[9]	cv_agg's binary_logloss: 0.417646 + 0.000877251
[1]	cv_agg's binary_logloss: 0.430152 + 0.000634779
[2]	cv_agg's binary_logloss: 0.422554 + 0.000641645
[3]	cv_agg's binary_logloss: 0.419463 + 0.00058142
[4]	cv_agg's binary_logloss: 0.418151 + 0.000959174
[5]	cv_agg's binary_logloss: 0.417669 + 0.00099873
[6]	cv_agg's binary_logloss: 0.417637 + 0.000994547
[7]	cv_agg's binary_logloss: 0.417589 + 0.00109377
[8]	cv_agg's binary_logloss: 0.417559 + 0.00111658
[9]	cv_agg's binary_logloss: 0.417541 + 0.00118032
[10]	cv_agg's binary_logloss: 0.417535 + 0.00118792
[11]	cv_agg's binary_logloss: 0.417543 + 0.00117704
[12]	cv_agg's binary_logloss: 0.41755 + 0.0011868
[13]	cv_agg's binary_logloss: 0.417541 + 0.0011929
[1]	cv_agg's binary_logloss: 0.430236 + 0.00078415
[2]	cv_agg's binary_logloss: 0.422455 + 0.0008673
[3]	cv_agg's binary_logloss: 0.419372 + 0.000790342
[4]	cv_agg's binary_logloss: 0.418257 + 0.000718535
[5]	cv_agg's binary_logloss: 0.417897 + 0.00056232
[6]	cv_agg's binary_logloss: 0.417653 + 0.000559245
[7]	cv_agg's binary_logloss: 0.417612 + 0.000598681
[8]	cv_agg's binary_logloss: 0.417617 + 0.000636088
[9]	cv_agg's binary_logloss: 0.417621 + 0.000622428
[10]	cv_agg's binary_logloss: 0.417633 + 0.00063825
[1]	cv_agg's binary_logloss: 0.430175 + 0.000863003
[2]	cv_agg's binary_logloss: 0.422643 + 0.000871525
[3]	cv_agg's binary_logloss: 0.419182 + 0.000916937
[4]	cv_agg's binary_logloss: 0.417645 + 0.000699587
[5]	cv_agg's binary_logloss: 0.417442 + 0.000787383
[6]	cv_agg's binary_logloss: 0.417401 + 0.000949576
[7]	cv_agg's binary_logloss: 0.417255 + 0.00104972
[8]	cv_agg's binary_logloss: 0.417188 + 0.00119566
[9]	cv_agg's binary_logloss: 0.417328 + 0.00112572
[10]	cv_agg's binary_logloss: 0.417718 + 0.00110434
[11]	cv_agg's binary_logloss: 0.41799 + 0.00102446
[1]	cv_agg's binary_logloss: 0.43017 + 0.000855465
[2]	cv_agg's binary_logloss: 0.422582 + 0.000842944
[3]	cv_agg's binary_logloss: 0.419564 + 0.00078564
[4]	cv_agg's binary_logloss: 0.418081 + 0.000791849
[5]	cv_agg's binary_logloss: 0.417373 + 0.000907935
[6]	cv_agg's binary_logloss: 0.417349 + 0.0009453
[7]	cv_agg's binary_logloss: 0.417136 + 0.000919656
[8]	cv_agg's binary_logloss: 0.417217 + 0.0010264
[9]	cv_agg's binary_logloss: 0.417246 + 0.00112731
[10]	cv_agg's binary_logloss: 0.417217 + 0.00113269
[1]	cv_agg's binary_logloss: 0.430201 + 0.000689256
[2]	cv_agg's binary_logloss: 0.422561 + 0.000801681
[3]	cv_agg's binary_logloss: 0.419404 + 0.000919772
[4]	cv_agg's binary_logloss: 0.417916 + 0.0006125
[5]	cv_agg's binary_logloss: 0.417412 + 0.000668886
[6]	cv_agg's binary_logloss: 0.417338 + 0.000422229
[7]	cv_agg's binary_logloss: 0.417428 + 0.000456688
[8]	cv_agg's binary_logloss: 0.417398 + 0.000470369
[9]	cv_agg's binary_logloss: 0.417381 + 0.000401242
[1]	cv_agg's binary_logloss: 0.430206 + 0.000590586
[2]	cv_agg's binary_logloss: 0.422574 + 0.000627353
[3]	cv_agg's binary_logloss: 0.419609 + 0.000449337
[4]	cv_agg's binary_logloss: 0.418331 + 0.00070444
[5]	cv_agg's binary_logloss: 0.417722 + 0.00078391
[6]	cv_agg's binary_logloss: 0.417577 + 0.000769089
[7]	cv_agg's binary_logloss: 0.417433 + 0.000700159
[8]	cv_agg's binary_logloss: 0.417432 + 0.000729422
[9]	cv_agg's binary_logloss: 0.417452 + 0.000682464
[10]	cv_agg's binary_logloss: 0.417414 + 0.000700277
[11]	cv_agg's binary_logloss: 0.417403 + 0.000703504
[12]	cv_agg's binary_logloss: 0.417403 + 0.000703504
[13]	cv_agg's binary_logloss: 0.417403 + 0.000703504
[14]	cv_agg's binary_logloss: 0.417403 + 0.000703504
[15]	cv_agg's binary_logloss: 0.417403 + 0.000703504
[1]	cv_agg's binary_logloss: 0.430323 + 0.000779508
[2]	cv_agg's binary_logloss: 0.422553 + 0.000830668
[3]	cv_agg's binary_logloss: 0.419549 + 0.000707896
[4]	cv_agg's binary_logloss: 0.418319 + 0.000688019
[5]	cv_agg's binary_logloss: 0.417866 + 0.000576615
[6]	cv_agg's binary_logloss: 0.417749 + 0.000603031
[7]	cv_agg's binary_logloss: 0.417728 + 0.000597367
[8]	cv_agg's binary_logloss: 0.417735 + 0.000621812
[9]	cv_agg's binary_logloss: 0.417714 + 0.000612478
[10]	cv_agg's binary_logloss: 0.417711 + 0.000615551
[11]	cv_agg's binary_logloss: 0.417711 + 0.000615551
[12]	cv_agg's binary_logloss: 0.417711 + 0.000615551
[13]	cv_agg's binary_logloss: 0.417711 + 0.000615551
[1]	cv_agg's binary_logloss: 0.430175 + 0.000884482
[2]	cv_agg's binary_logloss: 0.422513 + 0.000748146
[3]	cv_agg's binary_logloss: 0.419306 + 0.000656923
[4]	cv_agg's binary_logloss: 0.418008 + 0.000723921
[5]	cv_agg's binary_logloss: 0.417661 + 0.000919958
[6]	cv_agg's binary_logloss: 0.417689 + 0.000716728
[7]	cv_agg's binary_logloss: 0.417517 + 0.000587519
[8]	cv_agg's binary_logloss: 0.417516 + 0.000832052
[9]	cv_agg's binary_logloss: 0.417822 + 0.000936797
[10]	cv_agg's binary_logloss: 0.41805 + 0.00088726
[11]	cv_agg's binary_logloss: 0.417986 + 0.000770885
[1]	cv_agg's binary_logloss: 0.430178 + 0.000883775
[2]	cv_agg's binary_logloss: 0.422485 + 0.000849537
[3]	cv_agg's binary_logloss: 0.41936 + 0.000723362
[4]	cv_agg's binary_logloss: 0.417912 + 0.000661671
[5]	cv_agg's binary_logloss: 0.41732 + 0.000912353
[6]	cv_agg's binary_logloss: 0.417103 + 0.000974596
[7]	cv_agg's binary_logloss: 0.417157 + 0.00116958
[8]	cv_agg's binary_logloss: 0.417177 + 0.00124457
[9]	cv_agg's binary_logloss: 0.417231 + 0.00126235
[1]	cv_agg's binary_logloss: 0.43024 + 0.00070082
[2]	cv_agg's binary_logloss: 0.422589 + 0.00069956
[3]	cv_agg's binary_logloss: 0.419624 + 0.000986291
[4]	cv_agg's binary_logloss: 0.418422 + 0.000869088
[5]	cv_agg's binary_logloss: 0.4179 + 0.00105052
[6]	cv_agg's binary_logloss: 0.41794 + 0.00095721
[7]	cv_agg's binary_logloss: 0.417717 + 0.000765569
[8]	cv_agg's binary_logloss: 0.417732 + 0.000843119
[9]	cv_agg's binary_logloss: 0.417683 + 0.000860401
[10]	cv_agg's binary_logloss: 0.417696 + 0.00086884
[11]	cv_agg's binary_logloss: 0.417683 + 0.00087998
[12]	cv_agg's binary_logloss: 0.41768 + 0.000884638
[13]	cv_agg's binary_logloss: 0.41768 + 0.000884638
[14]	cv_agg's binary_logloss: 0.41768 + 0.000884638
[15]	cv_agg's binary_logloss: 0.41768 + 0.000884638
[1]	cv_agg's binary_logloss: 0.43026 + 0.000669738
[2]	cv_agg's binary_logloss: 0.422475 + 0.000679613
[3]	cv_agg's binary_logloss: 0.41969 + 0.000845188
[4]	cv_agg's binary_logloss: 0.41822 + 0.000659922
[5]	cv_agg's binary_logloss: 0.417672 + 0.000773061
[6]	cv_agg's binary_logloss: 0.417449 + 0.000978953
[7]	cv_agg's binary_logloss: 0.417301 + 0.000924812
[8]	cv_agg's binary_logloss: 0.41734 + 0.000920878
[9]	cv_agg's binary_logloss: 0.41735 + 0.000903838
[10]	cv_agg's binary_logloss: 0.417323 + 0.000931925
[1]	cv_agg's binary_logloss: 0.430347 + 0.000748649
[2]	cv_agg's binary_logloss: 0.422508 + 0.000815814
[3]	cv_agg's binary_logloss: 0.419622 + 0.000656438
[4]	cv_agg's binary_logloss: 0.418414 + 0.000497118
[5]	cv_agg's binary_logloss: 0.417822 + 0.00064419
[6]	cv_agg's binary_logloss: 0.417587 + 0.000725314
[7]	cv_agg's binary_logloss: 0.417493 + 0.000737391
[8]	cv_agg's binary_logloss: 0.417502 + 0.000778807
[9]	cv_agg's binary_logloss: 0.417514 + 0.000776268
[10]	cv_agg's binary_logloss: 0.417514 + 0.000776394
[1]	cv_agg's binary_logloss: 0.430049 + 0.00071064
[2]	cv_agg's binary_logloss: 0.422527 + 0.000801567
[3]	cv_agg's binary_logloss: 0.419295 + 0.00055487
[4]	cv_agg's binary_logloss: 0.41783 + 0.000424983
[5]	cv_agg's binary_logloss: 0.4175 + 0.000447497
[6]	cv_agg's binary_logloss: 0.417351 + 0.000534926
[7]	cv_agg's binary_logloss: 0.417364 + 0.000353219
[8]	cv_agg's binary_logloss: 0.417368 + 0.000287685
[9]	cv_agg's binary_logloss: 0.417205 + 0.000213169
[10]	cv_agg's binary_logloss: 0.417474 + 0.000212296
[11]	cv_agg's binary_logloss: 0.417541 + 0.000235363
[12]	cv_agg's binary_logloss: 0.41768 + 0.000236146
[1]	cv_agg's binary_logloss: 0.430124 + 0.000690104
[2]	cv_agg's binary_logloss: 0.422539 + 0.00080259
[3]	cv_agg's binary_logloss: 0.419094 + 0.00067119
[4]	cv_agg's binary_logloss: 0.417618 + 0.000778241
[5]	cv_agg's binary_logloss: 0.417319 + 0.000917872
[6]	cv_agg's binary_logloss: 0.417124 + 0.0009
[7]	cv_agg's binary_logloss: 0.417098 + 0.00102188
[8]	cv_agg's binary_logloss: 0.417051 + 0.00105391
[9]	cv_agg's binary_logloss: 0.416988 + 0.000903693
[10]	cv_agg's binary_logloss: 0.417011 + 0.000913989
[11]	cv_agg's binary_logloss: 0.417042 + 0.000872342
[12]	cv_agg's binary_logloss: 0.417047 + 0.0008647
[1]	cv_agg's binary_logloss: 0.430156 + 0.000503707
[2]	cv_agg's binary_logloss: 0.422576 + 0.000745048
[3]	cv_agg's binary_logloss: 0.419269 + 0.000813753
[4]	cv_agg's binary_logloss: 0.417957 + 0.000743341
[5]	cv_agg's binary_logloss: 0.41739 + 0.00082326
[6]	cv_agg's binary_logloss: 0.417289 + 0.000735983
[7]	cv_agg's binary_logloss: 0.417224 + 0.000830177
[8]	cv_agg's binary_logloss: 0.417155 + 0.000941803
[9]	cv_agg's binary_logloss: 0.417132 + 0.000898948
[10]	cv_agg's binary_logloss: 0.417171 + 0.000888884
[11]	cv_agg's binary_logloss: 0.417167 + 0.00088822
[12]	cv_agg's binary_logloss: 0.41717 + 0.00088655
[1]	cv_agg's binary_logloss: 0.430125 + 0.000425433
[2]	cv_agg's binary_logloss: 0.422436 + 0.000689343
[3]	cv_agg's binary_logloss: 0.419166 + 0.000624227
[4]	cv_agg's binary_logloss: 0.41798 + 0.000707141
[5]	cv_agg's binary_logloss: 0.417345 + 0.000815515
[6]	cv_agg's binary_logloss: 0.417147 + 0.000950921
[7]	cv_agg's binary_logloss: 0.417021 + 0.000990604
[8]	cv_agg's binary_logloss: 0.416973 + 0.00105472
[9]	cv_agg's binary_logloss: 0.416935 + 0.00105966
[10]	cv_agg's binary_logloss: 0.41693 + 0.00106645
[11]	cv_agg's binary_logloss: 0.416937 + 0.00105685
[12]	cv_agg's binary_logloss: 0.416937 + 0.00105685
[13]	cv_agg's binary_logloss: 0.416935 + 0.0010597
[1]	cv_agg's binary_logloss: 0.43015 + 0.000471508
[2]	cv_agg's binary_logloss: 0.422441 + 0.000817838
[3]	cv_agg's binary_logloss: 0.419586 + 0.000544865
[4]	cv_agg's binary_logloss: 0.418424 + 0.00059163
[5]	cv_agg's binary_logloss: 0.417868 + 0.00048711
[6]	cv_agg's binary_logloss: 0.417713 + 0.000502795
[7]	cv_agg's binary_logloss: 0.417687 + 0.000495686
[8]	cv_agg's binary_logloss: 0.417683 + 0.000494055
[9]	cv_agg's binary_logloss: 0.417622 + 0.000482702
[10]	cv_agg's binary_logloss: 0.417601 + 0.00046826
[11]	cv_agg's binary_logloss: 0.417601 + 0.00046826
[12]	cv_agg's binary_logloss: 0.417601 + 0.00046826
[13]	cv_agg's binary_logloss: 0.417601 + 0.00046826
[14]	cv_agg's binary_logloss: 0.417601 + 0.00046826
[1]	cv_agg's binary_logloss: 0.430054 + 0.000685386
[2]	cv_agg's binary_logloss: 0.422379 + 0.000743338
[3]	cv_agg's binary_logloss: 0.419138 + 0.000596004
[4]	cv_agg's binary_logloss: 0.417677 + 0.000452768
[5]	cv_agg's binary_logloss: 0.417327 + 0.000606296
[6]	cv_agg's binary_logloss: 0.417132 + 0.000768292
[7]	cv_agg's binary_logloss: 0.417182 + 0.00107087
[8]	cv_agg's binary_logloss: 0.417376 + 0.0010222
[9]	cv_agg's binary_logloss: 0.41732 + 0.000925365
[1]	cv_agg's binary_logloss: 0.4301 + 0.000670436
[2]	cv_agg's binary_logloss: 0.4224 + 0.000740293
[3]	cv_agg's binary_logloss: 0.419098 + 0.000554582
[4]	cv_agg's binary_logloss: 0.417714 + 0.000607791
[5]	cv_agg's binary_logloss: 0.417351 + 0.000694052
[6]	cv_agg's binary_logloss: 0.417021 + 0.000562502
[7]	cv_agg's binary_logloss: 0.416797 + 0.00058675
[8]	cv_agg's binary_logloss: 0.416997 + 0.000671913
[9]	cv_agg's binary_logloss: 0.416937 + 0.000868319
[10]	cv_agg's binary_logloss: 0.417101 + 0.000973179
[1]	cv_agg's binary_logloss: 0.430138 + 0.000502875
[2]	cv_agg's binary_logloss: 0.422414 + 0.000670328
[3]	cv_agg's binary_logloss: 0.419275 + 0.000684365
[4]	cv_agg's binary_logloss: 0.417923 + 0.000674042
[5]	cv_agg's binary_logloss: 0.41741 + 0.000759826
[6]	cv_agg's binary_logloss: 0.41734 + 0.000694277
[7]	cv_agg's binary_logloss: 0.41714 + 0.00080458
[8]	cv_agg's binary_logloss: 0.417192 + 0.000805135
[9]	cv_agg's binary_logloss: 0.417144 + 0.000748912
[10]	cv_agg's binary_logloss: 0.417161 + 0.000761445
[1]	cv_agg's binary_logloss: 0.430111 + 0.000392258
[2]	cv_agg's binary_logloss: 0.422513 + 0.000775384
[3]	cv_agg's binary_logloss: 0.419293 + 0.000841241
[4]	cv_agg's binary_logloss: 0.418046 + 0.000848409
[5]	cv_agg's binary_logloss: 0.417418 + 0.000996332
[6]	cv_agg's binary_logloss: 0.417303 + 0.00105874
[7]	cv_agg's binary_logloss: 0.417296 + 0.00102831
[8]	cv_agg's binary_logloss: 0.417339 + 0.00107905
[9]	cv_agg's binary_logloss: 0.417335 + 0.00110176
[10]	cv_agg's binary_logloss: 0.417332 + 0.00111445
[1]	cv_agg's binary_logloss: 0.430135 + 0.000502391
[2]	cv_agg's binary_logloss: 0.422538 + 0.000754154
[3]	cv_agg's binary_logloss: 0.419334 + 0.000717125
[4]	cv_agg's binary_logloss: 0.41816 + 0.000802454
[5]	cv_agg's binary_logloss: 0.417444 + 0.000795241
[6]	cv_agg's binary_logloss: 0.417263 + 0.000899401
[7]	cv_agg's binary_logloss: 0.417216 + 0.000903948
[8]	cv_agg's binary_logloss: 0.417211 + 0.000893115
[9]	cv_agg's binary_logloss: 0.417182 + 0.0008449
[10]	cv_agg's binary_logloss: 0.417182 + 0.000841427
[11]	cv_agg's binary_logloss: 0.417182 + 0.000841427
[12]	cv_agg's binary_logloss: 0.417182 + 0.000841427
[13]	cv_agg's binary_logloss: 0.417182 + 0.000841427
[14]	cv_agg's binary_logloss: 0.417182 + 0.000841427
Time used: 108.83595824241638
