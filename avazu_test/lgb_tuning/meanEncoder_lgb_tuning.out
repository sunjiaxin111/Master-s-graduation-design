WARNING:root:设置参数
WARNING:root:交叉验证
WARNING:root:调参2：降低过拟合
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:63: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
WARNING:root:调参3：降低过拟合
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:94: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
WARNING:root:调参4：降低过拟合
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the "boost_from_average" parameter in "binary" objective is true.
This may cause significantly different results comparing to the previous versions of LightGBM.
Try to set boost_from_average=false, if your old models produce bad results
[LightGBM] [Info] Number of positive: 6980, number of negative: 33020
[LightGBM] [Info] Total Bins 209
[LightGBM] [Info] Number of data: 40000, number of used features: 42
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174500 -> initscore=-1.554065
[LightGBM] [Info] Start training from score -1.554065
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
meanEncoder_lgb_tuning.py:128: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'
will be corrected to return the positional minimum in the future.
Use 'series.values.argmin' to get the position of the minimum now.
  boost_rounds = pd.Series(cv_results['binary_logloss-mean']).argmin()
WARNING:root:{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'binary_logloss', 'learning_rate': 0.5, 'max_depth': -1, 'num_leaves': 80, 'max_bin': 5, 'min_data_in_leaf': 15, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 45, 'lambda_l1': 0.4, 'lambda_l2': 0.4, 'min_split_gain': 0.4}
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421223 + 0.00148599
[2]	cv_agg's binary_logloss: 0.411679 + 0.00211696
[3]	cv_agg's binary_logloss: 0.408611 + 0.00231173
[4]	cv_agg's binary_logloss: 0.407525 + 0.00218756
[5]	cv_agg's binary_logloss: 0.407207 + 0.00248286
[6]	cv_agg's binary_logloss: 0.407663 + 0.00237839
[7]	cv_agg's binary_logloss: 0.408675 + 0.0024095
[8]	cv_agg's binary_logloss: 0.409884 + 0.00170907
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420965 + 0.0013425
[2]	cv_agg's binary_logloss: 0.411085 + 0.00174147
[3]	cv_agg's binary_logloss: 0.407779 + 0.00187378
[4]	cv_agg's binary_logloss: 0.407012 + 0.002243
[5]	cv_agg's binary_logloss: 0.40653 + 0.00253999
[6]	cv_agg's binary_logloss: 0.406658 + 0.0024683
[7]	cv_agg's binary_logloss: 0.407137 + 0.00247008
[8]	cv_agg's binary_logloss: 0.407482 + 0.0024063
[1]	cv_agg's binary_logloss: 0.421027 + 0.00092386
[2]	cv_agg's binary_logloss: 0.411329 + 0.0012663
[3]	cv_agg's binary_logloss: 0.407899 + 0.00170925
[4]	cv_agg's binary_logloss: 0.406552 + 0.0017775
[5]	cv_agg's binary_logloss: 0.406424 + 0.00202482
[6]	cv_agg's binary_logloss: 0.406602 + 0.00180279
[7]	cv_agg's binary_logloss: 0.407033 + 0.0018969
[8]	cv_agg's binary_logloss: 0.407737 + 0.00203646
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410138 + 0.00255082
[7]	cv_agg's binary_logloss: 0.411546 + 0.00270039
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410395 + 0.00234061
[7]	cv_agg's binary_logloss: 0.411293 + 0.00204446
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410395 + 0.00234061
[7]	cv_agg's binary_logloss: 0.411293 + 0.00204446
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410395 + 0.00234061
[7]	cv_agg's binary_logloss: 0.411293 + 0.00204446
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410395 + 0.00234061
[7]	cv_agg's binary_logloss: 0.411293 + 0.00204446
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410395 + 0.00234061
[7]	cv_agg's binary_logloss: 0.411293 + 0.00204446
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410395 + 0.00234061
[7]	cv_agg's binary_logloss: 0.411293 + 0.00204446
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410395 + 0.00234061
[7]	cv_agg's binary_logloss: 0.411293 + 0.00204446
[1]	cv_agg's binary_logloss: 0.423062 + 0.00028534
[2]	cv_agg's binary_logloss: 0.413436 + 0.00111078
[3]	cv_agg's binary_logloss: 0.410305 + 0.000987793
[4]	cv_agg's binary_logloss: 0.409528 + 0.00175382
[5]	cv_agg's binary_logloss: 0.410063 + 0.00223549
[6]	cv_agg's binary_logloss: 0.410395 + 0.00234061
[7]	cv_agg's binary_logloss: 0.411293 + 0.00204446
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.408656 + 0.00220209
[7]	cv_agg's binary_logloss: 0.40934 + 0.00207309
[8]	cv_agg's binary_logloss: 0.410062 + 0.00212922
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.409064 + 0.00236752
[7]	cv_agg's binary_logloss: 0.409971 + 0.00241873
[8]	cv_agg's binary_logloss: 0.410602 + 0.00246219
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.409064 + 0.00236752
[7]	cv_agg's binary_logloss: 0.409971 + 0.00241873
[8]	cv_agg's binary_logloss: 0.410602 + 0.00246219
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.409064 + 0.00236752
[7]	cv_agg's binary_logloss: 0.409971 + 0.00241873
[8]	cv_agg's binary_logloss: 0.410602 + 0.00246219
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.409064 + 0.00236752
[7]	cv_agg's binary_logloss: 0.409971 + 0.00241873
[8]	cv_agg's binary_logloss: 0.410602 + 0.00246219
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.409064 + 0.00236752
[7]	cv_agg's binary_logloss: 0.409971 + 0.00241873
[8]	cv_agg's binary_logloss: 0.410602 + 0.00246219
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.409064 + 0.00236752
[7]	cv_agg's binary_logloss: 0.409971 + 0.00241873
[8]	cv_agg's binary_logloss: 0.410602 + 0.00246219
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.409064 + 0.00236752
[7]	cv_agg's binary_logloss: 0.409971 + 0.00241873
[8]	cv_agg's binary_logloss: 0.410602 + 0.00246219
[1]	cv_agg's binary_logloss: 0.423045 + 0.000381911
[2]	cv_agg's binary_logloss: 0.41341 + 0.00103242
[3]	cv_agg's binary_logloss: 0.410094 + 0.00170072
[4]	cv_agg's binary_logloss: 0.408999 + 0.00205546
[5]	cv_agg's binary_logloss: 0.408604 + 0.0022074
[6]	cv_agg's binary_logloss: 0.409064 + 0.00236752
[7]	cv_agg's binary_logloss: 0.409971 + 0.00241873
[8]	cv_agg's binary_logloss: 0.410602 + 0.00246219
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.408548 + 0.0020607
[7]	cv_agg's binary_logloss: 0.40899 + 0.00226234
[8]	cv_agg's binary_logloss: 0.409459 + 0.00224053
[9]	cv_agg's binary_logloss: 0.410663 + 0.00204713
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.409047 + 0.00195652
[7]	cv_agg's binary_logloss: 0.409474 + 0.0018704
[8]	cv_agg's binary_logloss: 0.410249 + 0.0019082
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.409047 + 0.00195652
[7]	cv_agg's binary_logloss: 0.409474 + 0.0018704
[8]	cv_agg's binary_logloss: 0.410249 + 0.0019082
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.409047 + 0.00195652
[7]	cv_agg's binary_logloss: 0.409474 + 0.0018704
[8]	cv_agg's binary_logloss: 0.410249 + 0.0019082
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.409047 + 0.00195652
[7]	cv_agg's binary_logloss: 0.409474 + 0.0018704
[8]	cv_agg's binary_logloss: 0.410249 + 0.0019082
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.409047 + 0.00195652
[7]	cv_agg's binary_logloss: 0.409474 + 0.0018704
[8]	cv_agg's binary_logloss: 0.410249 + 0.0019082
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.409047 + 0.00195652
[7]	cv_agg's binary_logloss: 0.409474 + 0.0018704
[8]	cv_agg's binary_logloss: 0.410249 + 0.0019082
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.409047 + 0.00195652
[7]	cv_agg's binary_logloss: 0.409474 + 0.0018704
[8]	cv_agg's binary_logloss: 0.410249 + 0.0019082
[1]	cv_agg's binary_logloss: 0.423092 + 0.000659585
[2]	cv_agg's binary_logloss: 0.413586 + 0.00102462
[3]	cv_agg's binary_logloss: 0.409967 + 0.00121009
[4]	cv_agg's binary_logloss: 0.408822 + 0.00178288
[5]	cv_agg's binary_logloss: 0.408673 + 0.00191233
[6]	cv_agg's binary_logloss: 0.409047 + 0.00195652
[7]	cv_agg's binary_logloss: 0.409474 + 0.0018704
[8]	cv_agg's binary_logloss: 0.410249 + 0.0019082
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407824 + 0.002248
[7]	cv_agg's binary_logloss: 0.408559 + 0.00256615
[8]	cv_agg's binary_logloss: 0.408951 + 0.0026593
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407945 + 0.00225443
[7]	cv_agg's binary_logloss: 0.408451 + 0.00195887
[8]	cv_agg's binary_logloss: 0.40883 + 0.00177181
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407945 + 0.00225443
[7]	cv_agg's binary_logloss: 0.408451 + 0.00195887
[8]	cv_agg's binary_logloss: 0.40883 + 0.00177181
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407945 + 0.00225443
[7]	cv_agg's binary_logloss: 0.408451 + 0.00195887
[8]	cv_agg's binary_logloss: 0.40883 + 0.00177181
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407945 + 0.00225443
[7]	cv_agg's binary_logloss: 0.408451 + 0.00195887
[8]	cv_agg's binary_logloss: 0.40883 + 0.00177181
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407945 + 0.00225443
[7]	cv_agg's binary_logloss: 0.408451 + 0.00195887
[8]	cv_agg's binary_logloss: 0.40883 + 0.00177181
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407945 + 0.00225443
[7]	cv_agg's binary_logloss: 0.408451 + 0.00195887
[8]	cv_agg's binary_logloss: 0.40883 + 0.00177181
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407945 + 0.00225443
[7]	cv_agg's binary_logloss: 0.408451 + 0.00195887
[8]	cv_agg's binary_logloss: 0.40883 + 0.00177181
[1]	cv_agg's binary_logloss: 0.422316 + 0.000461254
[2]	cv_agg's binary_logloss: 0.412253 + 0.000631426
[3]	cv_agg's binary_logloss: 0.408762 + 0.00109235
[4]	cv_agg's binary_logloss: 0.407859 + 0.00154518
[5]	cv_agg's binary_logloss: 0.40767 + 0.00186329
[6]	cv_agg's binary_logloss: 0.407945 + 0.00225443
[7]	cv_agg's binary_logloss: 0.408451 + 0.00195887
[8]	cv_agg's binary_logloss: 0.40883 + 0.00177181
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.421925 + 0.000932229
[2]	cv_agg's binary_logloss: 0.412168 + 0.00123296
[3]	cv_agg's binary_logloss: 0.408275 + 0.00160934
[4]	cv_agg's binary_logloss: 0.407059 + 0.00179207
[5]	cv_agg's binary_logloss: 0.406447 + 0.00193454
[6]	cv_agg's binary_logloss: 0.406637 + 0.00175469
[7]	cv_agg's binary_logloss: 0.407076 + 0.00179455
[8]	cv_agg's binary_logloss: 0.407832 + 0.00191728
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411542 + 0.00210945
[7]	cv_agg's binary_logloss: 0.412152 + 0.00237205
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411916 + 0.002173
[7]	cv_agg's binary_logloss: 0.412605 + 0.00254597
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411916 + 0.002173
[7]	cv_agg's binary_logloss: 0.412605 + 0.00254597
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411916 + 0.002173
[7]	cv_agg's binary_logloss: 0.412605 + 0.00254597
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411916 + 0.002173
[7]	cv_agg's binary_logloss: 0.412605 + 0.00254597
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411916 + 0.002173
[7]	cv_agg's binary_logloss: 0.412605 + 0.00254597
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411916 + 0.002173
[7]	cv_agg's binary_logloss: 0.412605 + 0.00254597
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411916 + 0.002173
[7]	cv_agg's binary_logloss: 0.412605 + 0.00254597
[1]	cv_agg's binary_logloss: 0.423494 + 0.000543744
[2]	cv_agg's binary_logloss: 0.414445 + 0.00107587
[3]	cv_agg's binary_logloss: 0.41138 + 0.0013851
[4]	cv_agg's binary_logloss: 0.411078 + 0.00166492
[5]	cv_agg's binary_logloss: 0.411411 + 0.00188279
[6]	cv_agg's binary_logloss: 0.411916 + 0.002173
[7]	cv_agg's binary_logloss: 0.412605 + 0.00254597
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410653 + 0.0025914
[7]	cv_agg's binary_logloss: 0.411111 + 0.00255658
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410562 + 0.00237929
[7]	cv_agg's binary_logloss: 0.411453 + 0.00278945
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410562 + 0.00237929
[7]	cv_agg's binary_logloss: 0.411453 + 0.00278945
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410562 + 0.00237929
[7]	cv_agg's binary_logloss: 0.411453 + 0.00278945
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410562 + 0.00237929
[7]	cv_agg's binary_logloss: 0.411453 + 0.00278945
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410562 + 0.00237929
[7]	cv_agg's binary_logloss: 0.411453 + 0.00278945
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410562 + 0.00237929
[7]	cv_agg's binary_logloss: 0.411453 + 0.00278945
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410562 + 0.00237929
[7]	cv_agg's binary_logloss: 0.411453 + 0.00278945
[1]	cv_agg's binary_logloss: 0.423274 + 0.000780971
[2]	cv_agg's binary_logloss: 0.41413 + 0.00109142
[3]	cv_agg's binary_logloss: 0.410568 + 0.00182085
[4]	cv_agg's binary_logloss: 0.410011 + 0.00229868
[5]	cv_agg's binary_logloss: 0.410227 + 0.00234357
[6]	cv_agg's binary_logloss: 0.410562 + 0.00237929
[7]	cv_agg's binary_logloss: 0.411453 + 0.00278945
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.409457 + 0.00191613
[7]	cv_agg's binary_logloss: 0.409893 + 0.00181556
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.40944 + 0.00150079
[7]	cv_agg's binary_logloss: 0.410266 + 0.00155983
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.40944 + 0.00150079
[7]	cv_agg's binary_logloss: 0.410266 + 0.00155983
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.40944 + 0.00150079
[7]	cv_agg's binary_logloss: 0.410266 + 0.00155983
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.40944 + 0.00150079
[7]	cv_agg's binary_logloss: 0.410266 + 0.00155983
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.40944 + 0.00150079
[7]	cv_agg's binary_logloss: 0.410266 + 0.00155983
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.40944 + 0.00150079
[7]	cv_agg's binary_logloss: 0.410266 + 0.00155983
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.40944 + 0.00150079
[7]	cv_agg's binary_logloss: 0.410266 + 0.00155983
[1]	cv_agg's binary_logloss: 0.422967 + 0.000719743
[2]	cv_agg's binary_logloss: 0.413183 + 0.00132984
[3]	cv_agg's binary_logloss: 0.409848 + 0.00140271
[4]	cv_agg's binary_logloss: 0.40897 + 0.0012914
[5]	cv_agg's binary_logloss: 0.409114 + 0.0014526
[6]	cv_agg's binary_logloss: 0.40944 + 0.00150079
[7]	cv_agg's binary_logloss: 0.410266 + 0.00155983
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408164 + 0.0012807
[7]	cv_agg's binary_logloss: 0.408686 + 0.00129737
[8]	cv_agg's binary_logloss: 0.409281 + 0.00122544
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408513 + 0.00139859
[7]	cv_agg's binary_logloss: 0.408983 + 0.00149747
[8]	cv_agg's binary_logloss: 0.409736 + 0.00157483
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408513 + 0.00139859
[7]	cv_agg's binary_logloss: 0.408983 + 0.00149747
[8]	cv_agg's binary_logloss: 0.409736 + 0.00157483
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408513 + 0.00139859
[7]	cv_agg's binary_logloss: 0.408983 + 0.00149747
[8]	cv_agg's binary_logloss: 0.409736 + 0.00157483
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408513 + 0.00139859
[7]	cv_agg's binary_logloss: 0.408983 + 0.00149747
[8]	cv_agg's binary_logloss: 0.409736 + 0.00157483
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408513 + 0.00139859
[7]	cv_agg's binary_logloss: 0.408983 + 0.00149747
[8]	cv_agg's binary_logloss: 0.409736 + 0.00157483
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408513 + 0.00139859
[7]	cv_agg's binary_logloss: 0.408983 + 0.00149747
[8]	cv_agg's binary_logloss: 0.409736 + 0.00157483
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408513 + 0.00139859
[7]	cv_agg's binary_logloss: 0.408983 + 0.00149747
[8]	cv_agg's binary_logloss: 0.409736 + 0.00157483
[1]	cv_agg's binary_logloss: 0.422678 + 0.000278001
[2]	cv_agg's binary_logloss: 0.412715 + 0.000526513
[3]	cv_agg's binary_logloss: 0.408786 + 0.000663303
[4]	cv_agg's binary_logloss: 0.408056 + 0.00109668
[5]	cv_agg's binary_logloss: 0.408016 + 0.00129949
[6]	cv_agg's binary_logloss: 0.408513 + 0.00139859
[7]	cv_agg's binary_logloss: 0.408983 + 0.00149747
[8]	cv_agg's binary_logloss: 0.409736 + 0.00157483
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.422125 + 0.000679096
[2]	cv_agg's binary_logloss: 0.411945 + 0.00126226
[3]	cv_agg's binary_logloss: 0.408329 + 0.00153372
[4]	cv_agg's binary_logloss: 0.406918 + 0.00199058
[5]	cv_agg's binary_logloss: 0.406589 + 0.00210013
[6]	cv_agg's binary_logloss: 0.407042 + 0.00202476
[7]	cv_agg's binary_logloss: 0.407642 + 0.00215723
[8]	cv_agg's binary_logloss: 0.407813 + 0.00245766
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411253 + 0.00220316
[7]	cv_agg's binary_logloss: 0.412471 + 0.00195096
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411777 + 0.00262785
[7]	cv_agg's binary_logloss: 0.412605 + 0.00239608
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411777 + 0.00262785
[7]	cv_agg's binary_logloss: 0.412605 + 0.00239608
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411777 + 0.00262785
[7]	cv_agg's binary_logloss: 0.412605 + 0.00239608
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411777 + 0.00262785
[7]	cv_agg's binary_logloss: 0.412605 + 0.00239608
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411777 + 0.00262785
[7]	cv_agg's binary_logloss: 0.412605 + 0.00239608
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411777 + 0.00262785
[7]	cv_agg's binary_logloss: 0.412605 + 0.00239608
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411777 + 0.00262785
[7]	cv_agg's binary_logloss: 0.412605 + 0.00239608
[1]	cv_agg's binary_logloss: 0.42338 + 0.00031659
[2]	cv_agg's binary_logloss: 0.414059 + 0.00110475
[3]	cv_agg's binary_logloss: 0.411214 + 0.00168682
[4]	cv_agg's binary_logloss: 0.410713 + 0.00204029
[5]	cv_agg's binary_logloss: 0.411081 + 0.00214226
[6]	cv_agg's binary_logloss: 0.411777 + 0.00262785
[7]	cv_agg's binary_logloss: 0.412605 + 0.00239608
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.40977 + 0.0023977
[7]	cv_agg's binary_logloss: 0.410366 + 0.00230481
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.409937 + 0.00210829
[7]	cv_agg's binary_logloss: 0.410597 + 0.00212302
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.409937 + 0.00210829
[7]	cv_agg's binary_logloss: 0.410597 + 0.00212302
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.409937 + 0.00210829
[7]	cv_agg's binary_logloss: 0.410597 + 0.00212302
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.409937 + 0.00210829
[7]	cv_agg's binary_logloss: 0.410597 + 0.00212302
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.409937 + 0.00210829
[7]	cv_agg's binary_logloss: 0.410597 + 0.00212302
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.409937 + 0.00210829
[7]	cv_agg's binary_logloss: 0.410597 + 0.00212302
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.409937 + 0.00210829
[7]	cv_agg's binary_logloss: 0.410597 + 0.00212302
[1]	cv_agg's binary_logloss: 0.422983 + 0.000506507
[2]	cv_agg's binary_logloss: 0.413248 + 0.00091721
[3]	cv_agg's binary_logloss: 0.41003 + 0.00135754
[4]	cv_agg's binary_logloss: 0.409372 + 0.00149308
[5]	cv_agg's binary_logloss: 0.409542 + 0.00194731
[6]	cv_agg's binary_logloss: 0.409937 + 0.00210829
[7]	cv_agg's binary_logloss: 0.410597 + 0.00212302
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.410056 + 0.00130748
[7]	cv_agg's binary_logloss: 0.410357 + 0.00132338
[8]	cv_agg's binary_logloss: 0.411022 + 0.00115839
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.409751 + 0.00121976
[7]	cv_agg's binary_logloss: 0.410452 + 0.00119489
[8]	cv_agg's binary_logloss: 0.410804 + 0.00132106
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.409751 + 0.00121976
[7]	cv_agg's binary_logloss: 0.410452 + 0.00119489
[8]	cv_agg's binary_logloss: 0.410804 + 0.00132106
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.409751 + 0.00121976
[7]	cv_agg's binary_logloss: 0.410452 + 0.00119489
[8]	cv_agg's binary_logloss: 0.410804 + 0.00132106
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.409751 + 0.00121976
[7]	cv_agg's binary_logloss: 0.410452 + 0.00119489
[8]	cv_agg's binary_logloss: 0.410804 + 0.00132106
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.409751 + 0.00121976
[7]	cv_agg's binary_logloss: 0.410452 + 0.00119489
[8]	cv_agg's binary_logloss: 0.410804 + 0.00132106
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.409751 + 0.00121976
[7]	cv_agg's binary_logloss: 0.410452 + 0.00119489
[8]	cv_agg's binary_logloss: 0.410804 + 0.00132106
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.409751 + 0.00121976
[7]	cv_agg's binary_logloss: 0.410452 + 0.00119489
[8]	cv_agg's binary_logloss: 0.410804 + 0.00132106
[1]	cv_agg's binary_logloss: 0.422955 + 0.000717458
[2]	cv_agg's binary_logloss: 0.413458 + 0.000974002
[3]	cv_agg's binary_logloss: 0.409871 + 0.00116455
[4]	cv_agg's binary_logloss: 0.409533 + 0.00109063
[5]	cv_agg's binary_logloss: 0.409409 + 0.00133595
[6]	cv_agg's binary_logloss: 0.409751 + 0.00121976
[7]	cv_agg's binary_logloss: 0.410452 + 0.00119489
[8]	cv_agg's binary_logloss: 0.410804 + 0.00132106
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407491 + 0.00145779
[7]	cv_agg's binary_logloss: 0.408035 + 0.00169619
[8]	cv_agg's binary_logloss: 0.408566 + 0.001424
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407581 + 0.00175055
[7]	cv_agg's binary_logloss: 0.407959 + 0.00203982
[8]	cv_agg's binary_logloss: 0.408638 + 0.00244955
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407581 + 0.00175055
[7]	cv_agg's binary_logloss: 0.407959 + 0.00203982
[8]	cv_agg's binary_logloss: 0.408638 + 0.00244955
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407581 + 0.00175055
[7]	cv_agg's binary_logloss: 0.407959 + 0.00203982
[8]	cv_agg's binary_logloss: 0.408638 + 0.00244955
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407581 + 0.00175055
[7]	cv_agg's binary_logloss: 0.407959 + 0.00203982
[8]	cv_agg's binary_logloss: 0.408638 + 0.00244955
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407581 + 0.00175055
[7]	cv_agg's binary_logloss: 0.407959 + 0.00203982
[8]	cv_agg's binary_logloss: 0.408638 + 0.00244955
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407581 + 0.00175055
[7]	cv_agg's binary_logloss: 0.407959 + 0.00203982
[8]	cv_agg's binary_logloss: 0.408638 + 0.00244955
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407581 + 0.00175055
[7]	cv_agg's binary_logloss: 0.407959 + 0.00203982
[8]	cv_agg's binary_logloss: 0.408638 + 0.00244955
[1]	cv_agg's binary_logloss: 0.422326 + 0.00100557
[2]	cv_agg's binary_logloss: 0.412081 + 0.000871699
[3]	cv_agg's binary_logloss: 0.408754 + 0.0012059
[4]	cv_agg's binary_logloss: 0.407395 + 0.00173078
[5]	cv_agg's binary_logloss: 0.407195 + 0.00166796
[6]	cv_agg's binary_logloss: 0.407581 + 0.00175055
[7]	cv_agg's binary_logloss: 0.407959 + 0.00203982
[8]	cv_agg's binary_logloss: 0.408638 + 0.00244955
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421815 + 0.00106658
[2]	cv_agg's binary_logloss: 0.411682 + 0.00132047
[3]	cv_agg's binary_logloss: 0.408256 + 0.00152284
[4]	cv_agg's binary_logloss: 0.407001 + 0.00172481
[5]	cv_agg's binary_logloss: 0.406813 + 0.00134793
[6]	cv_agg's binary_logloss: 0.407324 + 0.00181962
[7]	cv_agg's binary_logloss: 0.408079 + 0.00184149
[8]	cv_agg's binary_logloss: 0.408552 + 0.00166891
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411833 + 0.00206785
[7]	cv_agg's binary_logloss: 0.413756 + 0.00197846
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411887 + 0.00202276
[7]	cv_agg's binary_logloss: 0.412831 + 0.00223278
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411887 + 0.00202276
[7]	cv_agg's binary_logloss: 0.412831 + 0.00223278
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411887 + 0.00202276
[7]	cv_agg's binary_logloss: 0.412831 + 0.00223278
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411887 + 0.00202276
[7]	cv_agg's binary_logloss: 0.412831 + 0.00223278
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411887 + 0.00202276
[7]	cv_agg's binary_logloss: 0.412831 + 0.00223278
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411887 + 0.00202276
[7]	cv_agg's binary_logloss: 0.412831 + 0.00223278
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411887 + 0.00202276
[7]	cv_agg's binary_logloss: 0.412831 + 0.00223278
[1]	cv_agg's binary_logloss: 0.42316 + 0.000553111
[2]	cv_agg's binary_logloss: 0.414254 + 0.00110545
[3]	cv_agg's binary_logloss: 0.411355 + 0.00153974
[4]	cv_agg's binary_logloss: 0.410429 + 0.00212634
[5]	cv_agg's binary_logloss: 0.411378 + 0.0020192
[6]	cv_agg's binary_logloss: 0.411887 + 0.00202276
[7]	cv_agg's binary_logloss: 0.412831 + 0.00223278
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410704 + 0.00146553
[7]	cv_agg's binary_logloss: 0.411339 + 0.00167868
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410487 + 0.00149508
[7]	cv_agg's binary_logloss: 0.411103 + 0.00153244
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410487 + 0.00149508
[7]	cv_agg's binary_logloss: 0.411103 + 0.00153244
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410487 + 0.00149508
[7]	cv_agg's binary_logloss: 0.411103 + 0.00153244
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410487 + 0.00149508
[7]	cv_agg's binary_logloss: 0.411103 + 0.00153244
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410487 + 0.00149508
[7]	cv_agg's binary_logloss: 0.411103 + 0.00153244
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410487 + 0.00149508
[7]	cv_agg's binary_logloss: 0.411103 + 0.00153244
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410487 + 0.00149508
[7]	cv_agg's binary_logloss: 0.411103 + 0.00153244
[1]	cv_agg's binary_logloss: 0.422303 + 0.000428348
[2]	cv_agg's binary_logloss: 0.413268 + 0.00067931
[3]	cv_agg's binary_logloss: 0.410333 + 0.000924171
[4]	cv_agg's binary_logloss: 0.409772 + 0.00128294
[5]	cv_agg's binary_logloss: 0.410218 + 0.0014745
[6]	cv_agg's binary_logloss: 0.410487 + 0.00149508
[7]	cv_agg's binary_logloss: 0.411103 + 0.00153244
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.408894 + 0.00178229
[7]	cv_agg's binary_logloss: 0.409674 + 0.0020329
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.409111 + 0.00167304
[7]	cv_agg's binary_logloss: 0.409871 + 0.00132443
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.409111 + 0.00167304
[7]	cv_agg's binary_logloss: 0.409871 + 0.00132443
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.409111 + 0.00167304
[7]	cv_agg's binary_logloss: 0.409871 + 0.00132443
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.409111 + 0.00167304
[7]	cv_agg's binary_logloss: 0.409871 + 0.00132443
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.409111 + 0.00167304
[7]	cv_agg's binary_logloss: 0.409871 + 0.00132443
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.409111 + 0.00167304
[7]	cv_agg's binary_logloss: 0.409871 + 0.00132443
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.409111 + 0.00167304
[7]	cv_agg's binary_logloss: 0.409871 + 0.00132443
[1]	cv_agg's binary_logloss: 0.421834 + 0.00119573
[2]	cv_agg's binary_logloss: 0.412557 + 0.00141684
[3]	cv_agg's binary_logloss: 0.409546 + 0.00142447
[4]	cv_agg's binary_logloss: 0.408312 + 0.00141118
[5]	cv_agg's binary_logloss: 0.408462 + 0.00152053
[6]	cv_agg's binary_logloss: 0.409111 + 0.00167304
[7]	cv_agg's binary_logloss: 0.409871 + 0.00132443
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.40871 + 0.00138335
[7]	cv_agg's binary_logloss: 0.409222 + 0.00107961
[8]	cv_agg's binary_logloss: 0.410103 + 0.00174277
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.408646 + 0.00153176
[7]	cv_agg's binary_logloss: 0.408842 + 0.00159296
[8]	cv_agg's binary_logloss: 0.409406 + 0.00164818
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.408646 + 0.00153176
[7]	cv_agg's binary_logloss: 0.408842 + 0.00159296
[8]	cv_agg's binary_logloss: 0.409406 + 0.00164818
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.408646 + 0.00153176
[7]	cv_agg's binary_logloss: 0.408842 + 0.00159296
[8]	cv_agg's binary_logloss: 0.409406 + 0.00164818
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.408646 + 0.00153176
[7]	cv_agg's binary_logloss: 0.408842 + 0.00159296
[8]	cv_agg's binary_logloss: 0.409406 + 0.00164818
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.408646 + 0.00153176
[7]	cv_agg's binary_logloss: 0.408842 + 0.00159296
[8]	cv_agg's binary_logloss: 0.409406 + 0.00164818
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.408646 + 0.00153176
[7]	cv_agg's binary_logloss: 0.408842 + 0.00159296
[8]	cv_agg's binary_logloss: 0.409406 + 0.00164818
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.408646 + 0.00153176
[7]	cv_agg's binary_logloss: 0.408842 + 0.00159296
[8]	cv_agg's binary_logloss: 0.409406 + 0.00164818
[1]	cv_agg's binary_logloss: 0.421945 + 0.00107063
[2]	cv_agg's binary_logloss: 0.412475 + 0.00116078
[3]	cv_agg's binary_logloss: 0.409241 + 0.00123153
[4]	cv_agg's binary_logloss: 0.40827 + 0.00155774
[5]	cv_agg's binary_logloss: 0.408153 + 0.0016618
[6]	cv_agg's binary_logloss: 0.408646 + 0.00153176
[7]	cv_agg's binary_logloss: 0.408842 + 0.00159296
[8]	cv_agg's binary_logloss: 0.409406 + 0.00164818
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.421345 + 0.00137795
[2]	cv_agg's binary_logloss: 0.411734 + 0.00157183
[3]	cv_agg's binary_logloss: 0.408657 + 0.00174889
[4]	cv_agg's binary_logloss: 0.407413 + 0.00216309
[5]	cv_agg's binary_logloss: 0.407179 + 0.00234314
[6]	cv_agg's binary_logloss: 0.407506 + 0.0023144
[7]	cv_agg's binary_logloss: 0.407878 + 0.00262268
[8]	cv_agg's binary_logloss: 0.408334 + 0.00252331
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412084 + 0.00197661
[7]	cv_agg's binary_logloss: 0.41306 + 0.00193173
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412556 + 0.00141333
[7]	cv_agg's binary_logloss: 0.413649 + 0.00161785
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412556 + 0.00141333
[7]	cv_agg's binary_logloss: 0.413649 + 0.00161785
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412556 + 0.00141333
[7]	cv_agg's binary_logloss: 0.413649 + 0.00161785
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412556 + 0.00141333
[7]	cv_agg's binary_logloss: 0.413649 + 0.00161785
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412556 + 0.00141333
[7]	cv_agg's binary_logloss: 0.413649 + 0.00161785
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412556 + 0.00141333
[7]	cv_agg's binary_logloss: 0.413649 + 0.00161785
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412556 + 0.00141333
[7]	cv_agg's binary_logloss: 0.413649 + 0.00161785
[1]	cv_agg's binary_logloss: 0.423166 + 0.000698041
[2]	cv_agg's binary_logloss: 0.414431 + 0.00106865
[3]	cv_agg's binary_logloss: 0.411624 + 0.00146637
[4]	cv_agg's binary_logloss: 0.411353 + 0.00151039
[5]	cv_agg's binary_logloss: 0.411647 + 0.0016823
[6]	cv_agg's binary_logloss: 0.412556 + 0.00141333
[7]	cv_agg's binary_logloss: 0.413649 + 0.00161785
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410059 + 0.00229864
[7]	cv_agg's binary_logloss: 0.411029 + 0.00252461
[8]	cv_agg's binary_logloss: 0.412122 + 0.00226461
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410064 + 0.00212035
[7]	cv_agg's binary_logloss: 0.410774 + 0.00224358
[8]	cv_agg's binary_logloss: 0.411678 + 0.00248268
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410064 + 0.00212035
[7]	cv_agg's binary_logloss: 0.410774 + 0.00224358
[8]	cv_agg's binary_logloss: 0.411678 + 0.00248268
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410064 + 0.00212035
[7]	cv_agg's binary_logloss: 0.410774 + 0.00224358
[8]	cv_agg's binary_logloss: 0.411678 + 0.00248268
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410064 + 0.00212035
[7]	cv_agg's binary_logloss: 0.410774 + 0.00224358
[8]	cv_agg's binary_logloss: 0.411678 + 0.00248268
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410064 + 0.00212035
[7]	cv_agg's binary_logloss: 0.410774 + 0.00224358
[8]	cv_agg's binary_logloss: 0.411678 + 0.00248268
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410064 + 0.00212035
[7]	cv_agg's binary_logloss: 0.410774 + 0.00224358
[8]	cv_agg's binary_logloss: 0.411678 + 0.00248268
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410064 + 0.00212035
[7]	cv_agg's binary_logloss: 0.410774 + 0.00224358
[8]	cv_agg's binary_logloss: 0.411678 + 0.00248268
[1]	cv_agg's binary_logloss: 0.42255 + 0.000407186
[2]	cv_agg's binary_logloss: 0.412882 + 0.000739094
[3]	cv_agg's binary_logloss: 0.410015 + 0.00133888
[4]	cv_agg's binary_logloss: 0.409876 + 0.00158424
[5]	cv_agg's binary_logloss: 0.409723 + 0.00221582
[6]	cv_agg's binary_logloss: 0.410064 + 0.00212035
[7]	cv_agg's binary_logloss: 0.410774 + 0.00224358
[8]	cv_agg's binary_logloss: 0.411678 + 0.00248268
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408717 + 0.00178672
[7]	cv_agg's binary_logloss: 0.40937 + 0.00175816
[8]	cv_agg's binary_logloss: 0.410156 + 0.00159439
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408801 + 0.00180137
[7]	cv_agg's binary_logloss: 0.409628 + 0.00168065
[8]	cv_agg's binary_logloss: 0.410485 + 0.00143176
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408801 + 0.00180137
[7]	cv_agg's binary_logloss: 0.409628 + 0.00168065
[8]	cv_agg's binary_logloss: 0.410485 + 0.00143176
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408801 + 0.00180137
[7]	cv_agg's binary_logloss: 0.409628 + 0.00168065
[8]	cv_agg's binary_logloss: 0.410485 + 0.00143176
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408801 + 0.00180137
[7]	cv_agg's binary_logloss: 0.409628 + 0.00168065
[8]	cv_agg's binary_logloss: 0.410485 + 0.00143176
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408801 + 0.00180137
[7]	cv_agg's binary_logloss: 0.409628 + 0.00168065
[8]	cv_agg's binary_logloss: 0.410485 + 0.00143176
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408801 + 0.00180137
[7]	cv_agg's binary_logloss: 0.409628 + 0.00168065
[8]	cv_agg's binary_logloss: 0.410485 + 0.00143176
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408801 + 0.00180137
[7]	cv_agg's binary_logloss: 0.409628 + 0.00168065
[8]	cv_agg's binary_logloss: 0.410485 + 0.00143176
[1]	cv_agg's binary_logloss: 0.421493 + 0.00142731
[2]	cv_agg's binary_logloss: 0.412369 + 0.00154392
[3]	cv_agg's binary_logloss: 0.409425 + 0.00186915
[4]	cv_agg's binary_logloss: 0.408487 + 0.00181073
[5]	cv_agg's binary_logloss: 0.408472 + 0.0017537
[6]	cv_agg's binary_logloss: 0.408801 + 0.00180137
[7]	cv_agg's binary_logloss: 0.409628 + 0.00168065
[8]	cv_agg's binary_logloss: 0.410485 + 0.00143176
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.40848 + 0.00197147
[7]	cv_agg's binary_logloss: 0.409028 + 0.00202724
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.408627 + 0.00193237
[7]	cv_agg's binary_logloss: 0.409201 + 0.0020023
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.408627 + 0.00193237
[7]	cv_agg's binary_logloss: 0.409201 + 0.0020023
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.408627 + 0.00193237
[7]	cv_agg's binary_logloss: 0.409201 + 0.0020023
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.408627 + 0.00193237
[7]	cv_agg's binary_logloss: 0.409201 + 0.0020023
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.408627 + 0.00193237
[7]	cv_agg's binary_logloss: 0.409201 + 0.0020023
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.408627 + 0.00193237
[7]	cv_agg's binary_logloss: 0.409201 + 0.0020023
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.408627 + 0.00193237
[7]	cv_agg's binary_logloss: 0.409201 + 0.0020023
[1]	cv_agg's binary_logloss: 0.421619 + 0.000989622
[2]	cv_agg's binary_logloss: 0.412476 + 0.00158698
[3]	cv_agg's binary_logloss: 0.409061 + 0.00178045
[4]	cv_agg's binary_logloss: 0.408081 + 0.00194817
[5]	cv_agg's binary_logloss: 0.408148 + 0.00225857
[6]	cv_agg's binary_logloss: 0.408627 + 0.00193237
[7]	cv_agg's binary_logloss: 0.409201 + 0.0020023
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.420955 + 0.00141667
[2]	cv_agg's binary_logloss: 0.41111 + 0.00177046
[3]	cv_agg's binary_logloss: 0.407759 + 0.00175093
[4]	cv_agg's binary_logloss: 0.406809 + 0.00206859
[5]	cv_agg's binary_logloss: 0.406285 + 0.00213819
[6]	cv_agg's binary_logloss: 0.406425 + 0.00212057
[7]	cv_agg's binary_logloss: 0.406756 + 0.00216339
[8]	cv_agg's binary_logloss: 0.40733 + 0.00244974
[1]	cv_agg's binary_logloss: 0.421064 + 0.00118546
[2]	cv_agg's binary_logloss: 0.411169 + 0.00144174
[3]	cv_agg's binary_logloss: 0.407931 + 0.00154995
[4]	cv_agg's binary_logloss: 0.40668 + 0.0014771
[5]	cv_agg's binary_logloss: 0.406541 + 0.00137461
[6]	cv_agg's binary_logloss: 0.406425 + 0.00139012
[7]	cv_agg's binary_logloss: 0.406588 + 0.0014225
[8]	cv_agg's binary_logloss: 0.407044 + 0.00175577
[9]	cv_agg's binary_logloss: 0.407406 + 0.00191654
[1]	cv_agg's binary_logloss: 0.421041 + 0.00116943
[2]	cv_agg's binary_logloss: 0.41129 + 0.00151375
[3]	cv_agg's binary_logloss: 0.407871 + 0.00150018
[4]	cv_agg's binary_logloss: 0.406231 + 0.00179652
[5]	cv_agg's binary_logloss: 0.406002 + 0.00171173
[6]	cv_agg's binary_logloss: 0.406038 + 0.00174582
[7]	cv_agg's binary_logloss: 0.406388 + 0.00159972
[8]	cv_agg's binary_logloss: 0.406867 + 0.00179817
[1]	cv_agg's binary_logloss: 0.4212 + 0.0012721
[2]	cv_agg's binary_logloss: 0.411595 + 0.00194604
[3]	cv_agg's binary_logloss: 0.408443 + 0.00224938
[4]	cv_agg's binary_logloss: 0.407106 + 0.00220514
[5]	cv_agg's binary_logloss: 0.407155 + 0.00249737
[6]	cv_agg's binary_logloss: 0.406933 + 0.00260296
[7]	cv_agg's binary_logloss: 0.407178 + 0.0023821
[8]	cv_agg's binary_logloss: 0.407419 + 0.00248568
[9]	cv_agg's binary_logloss: 0.407468 + 0.00271722
[1]	cv_agg's binary_logloss: 0.42126 + 0.00111579
[2]	cv_agg's binary_logloss: 0.411744 + 0.00137857
[3]	cv_agg's binary_logloss: 0.408521 + 0.00134189
[4]	cv_agg's binary_logloss: 0.407172 + 0.00138227
[5]	cv_agg's binary_logloss: 0.407 + 0.00138862
[6]	cv_agg's binary_logloss: 0.407096 + 0.00146513
[7]	cv_agg's binary_logloss: 0.407316 + 0.00139042
[8]	cv_agg's binary_logloss: 0.407511 + 0.0015504
[1]	cv_agg's binary_logloss: 0.420841 + 0.00137005
[2]	cv_agg's binary_logloss: 0.410937 + 0.00165564
[3]	cv_agg's binary_logloss: 0.407739 + 0.00197659
[4]	cv_agg's binary_logloss: 0.406706 + 0.00210534
[5]	cv_agg's binary_logloss: 0.406425 + 0.00219468
[6]	cv_agg's binary_logloss: 0.407169 + 0.00223725
[7]	cv_agg's binary_logloss: 0.407554 + 0.00255648
[8]	cv_agg's binary_logloss: 0.408303 + 0.00252315
[1]	cv_agg's binary_logloss: 0.420907 + 0.00116417
[2]	cv_agg's binary_logloss: 0.410932 + 0.00146966
[3]	cv_agg's binary_logloss: 0.407545 + 0.00192611
[4]	cv_agg's binary_logloss: 0.406326 + 0.00191443
[5]	cv_agg's binary_logloss: 0.406085 + 0.0019798
[6]	cv_agg's binary_logloss: 0.406234 + 0.00192846
[7]	cv_agg's binary_logloss: 0.406804 + 0.00217822
[8]	cv_agg's binary_logloss: 0.407156 + 0.0024811
[1]	cv_agg's binary_logloss: 0.420978 + 0.00123051
[2]	cv_agg's binary_logloss: 0.411194 + 0.00158885
[3]	cv_agg's binary_logloss: 0.408104 + 0.00217502
[4]	cv_agg's binary_logloss: 0.406621 + 0.00216751
[5]	cv_agg's binary_logloss: 0.406466 + 0.00208272
[6]	cv_agg's binary_logloss: 0.406754 + 0.00180871
[7]	cv_agg's binary_logloss: 0.406583 + 0.00198584
[8]	cv_agg's binary_logloss: 0.407041 + 0.00207167
[1]	cv_agg's binary_logloss: 0.421052 + 0.00125347
[2]	cv_agg's binary_logloss: 0.411441 + 0.00173085
[3]	cv_agg's binary_logloss: 0.408006 + 0.00215669
[4]	cv_agg's binary_logloss: 0.406594 + 0.00222847
[5]	cv_agg's binary_logloss: 0.406493 + 0.00260089
[6]	cv_agg's binary_logloss: 0.406982 + 0.00260291
[7]	cv_agg's binary_logloss: 0.407171 + 0.00278979
[8]	cv_agg's binary_logloss: 0.407513 + 0.00294392
[1]	cv_agg's binary_logloss: 0.421085 + 0.00114212
[2]	cv_agg's binary_logloss: 0.411362 + 0.00154167
[3]	cv_agg's binary_logloss: 0.407929 + 0.00172
[4]	cv_agg's binary_logloss: 0.406658 + 0.00211497
[5]	cv_agg's binary_logloss: 0.406206 + 0.0019434
[6]	cv_agg's binary_logloss: 0.406257 + 0.00187429
[7]	cv_agg's binary_logloss: 0.406354 + 0.00197178
[8]	cv_agg's binary_logloss: 0.406472 + 0.00192223
[1]	cv_agg's binary_logloss: 0.420835 + 0.00137611
[2]	cv_agg's binary_logloss: 0.411235 + 0.0019377
[3]	cv_agg's binary_logloss: 0.408091 + 0.00231804
[4]	cv_agg's binary_logloss: 0.407046 + 0.00231848
[5]	cv_agg's binary_logloss: 0.406663 + 0.00276148
[6]	cv_agg's binary_logloss: 0.407135 + 0.00288188
[7]	cv_agg's binary_logloss: 0.407492 + 0.00290094
[8]	cv_agg's binary_logloss: 0.407844 + 0.0029496
[1]	cv_agg's binary_logloss: 0.420913 + 0.00121522
[2]	cv_agg's binary_logloss: 0.411209 + 0.00195064
[3]	cv_agg's binary_logloss: 0.407867 + 0.00250843
[4]	cv_agg's binary_logloss: 0.406893 + 0.00253487
[5]	cv_agg's binary_logloss: 0.406727 + 0.00219009
[6]	cv_agg's binary_logloss: 0.406918 + 0.00215261
[7]	cv_agg's binary_logloss: 0.407402 + 0.00210083
[8]	cv_agg's binary_logloss: 0.407767 + 0.00195218
[1]	cv_agg's binary_logloss: 0.42098 + 0.00127896
[2]	cv_agg's binary_logloss: 0.411564 + 0.00204579
[3]	cv_agg's binary_logloss: 0.408093 + 0.00219352
[4]	cv_agg's binary_logloss: 0.406758 + 0.00215914
[5]	cv_agg's binary_logloss: 0.406214 + 0.00244967
[6]	cv_agg's binary_logloss: 0.406491 + 0.00214678
[7]	cv_agg's binary_logloss: 0.406455 + 0.00240723
[8]	cv_agg's binary_logloss: 0.40676 + 0.00239346
[1]	cv_agg's binary_logloss: 0.420939 + 0.00103481
[2]	cv_agg's binary_logloss: 0.41144 + 0.00168259
[3]	cv_agg's binary_logloss: 0.407995 + 0.00181051
[4]	cv_agg's binary_logloss: 0.40682 + 0.00220851
[5]	cv_agg's binary_logloss: 0.406297 + 0.00197976
[6]	cv_agg's binary_logloss: 0.406606 + 0.00191126
[7]	cv_agg's binary_logloss: 0.40673 + 0.00195529
[8]	cv_agg's binary_logloss: 0.406899 + 0.00209685
[1]	cv_agg's binary_logloss: 0.421013 + 0.00105186
[2]	cv_agg's binary_logloss: 0.411413 + 0.00158364
[3]	cv_agg's binary_logloss: 0.407813 + 0.0017729
[4]	cv_agg's binary_logloss: 0.406448 + 0.00167607
[5]	cv_agg's binary_logloss: 0.406144 + 0.00196125
[6]	cv_agg's binary_logloss: 0.4062 + 0.00198001
[7]	cv_agg's binary_logloss: 0.406215 + 0.00210361
[8]	cv_agg's binary_logloss: 0.406073 + 0.00228386
[9]	cv_agg's binary_logloss: 0.406116 + 0.00234563
[10]	cv_agg's binary_logloss: 0.406114 + 0.00234997
[11]	cv_agg's binary_logloss: 0.406118 + 0.00235796
[1]	cv_agg's binary_logloss: 0.421039 + 0.00113335
[2]	cv_agg's binary_logloss: 0.411411 + 0.00186213
[3]	cv_agg's binary_logloss: 0.408024 + 0.00193197
[4]	cv_agg's binary_logloss: 0.406979 + 0.00194242
[5]	cv_agg's binary_logloss: 0.406384 + 0.00171252
[6]	cv_agg's binary_logloss: 0.406475 + 0.0017497
[7]	cv_agg's binary_logloss: 0.406659 + 0.00188587
[8]	cv_agg's binary_logloss: 0.40678 + 0.00212999
[1]	cv_agg's binary_logloss: 0.421032 + 0.00111438
[2]	cv_agg's binary_logloss: 0.411308 + 0.00181599
[3]	cv_agg's binary_logloss: 0.407659 + 0.00195603
[4]	cv_agg's binary_logloss: 0.406393 + 0.00210087
[5]	cv_agg's binary_logloss: 0.406284 + 0.00245652
[6]	cv_agg's binary_logloss: 0.40656 + 0.00230544
[7]	cv_agg's binary_logloss: 0.407107 + 0.00222871
[8]	cv_agg's binary_logloss: 0.4072 + 0.00212835
[1]	cv_agg's binary_logloss: 0.420985 + 0.00105893
[2]	cv_agg's binary_logloss: 0.41126 + 0.00173455
[3]	cv_agg's binary_logloss: 0.407927 + 0.00196401
[4]	cv_agg's binary_logloss: 0.406841 + 0.00187474
[5]	cv_agg's binary_logloss: 0.406621 + 0.00216719
[6]	cv_agg's binary_logloss: 0.406608 + 0.00217676
[7]	cv_agg's binary_logloss: 0.406695 + 0.00204074
[8]	cv_agg's binary_logloss: 0.406836 + 0.0018778
[9]	cv_agg's binary_logloss: 0.407095 + 0.00217692
[1]	cv_agg's binary_logloss: 0.421051 + 0.000910157
[2]	cv_agg's binary_logloss: 0.411432 + 0.00131577
[3]	cv_agg's binary_logloss: 0.407923 + 0.00127814
[4]	cv_agg's binary_logloss: 0.406568 + 0.0013426
[5]	cv_agg's binary_logloss: 0.40613 + 0.00148884
[6]	cv_agg's binary_logloss: 0.405981 + 0.00156732
[7]	cv_agg's binary_logloss: 0.405937 + 0.00194249
[8]	cv_agg's binary_logloss: 0.406265 + 0.00228503
[9]	cv_agg's binary_logloss: 0.40644 + 0.00232251
[10]	cv_agg's binary_logloss: 0.406604 + 0.00247737
[1]	cv_agg's binary_logloss: 0.42108 + 0.000936803
[2]	cv_agg's binary_logloss: 0.411353 + 0.00140481
[3]	cv_agg's binary_logloss: 0.407632 + 0.00154931
[4]	cv_agg's binary_logloss: 0.40637 + 0.00162595
[5]	cv_agg's binary_logloss: 0.40586 + 0.00156433
[6]	cv_agg's binary_logloss: 0.405987 + 0.00159063
[7]	cv_agg's binary_logloss: 0.406027 + 0.00190673
[8]	cv_agg's binary_logloss: 0.406072 + 0.00208094
[1]	cv_agg's binary_logloss: 0.421089 + 0.00110919
[2]	cv_agg's binary_logloss: 0.411318 + 0.00163073
[3]	cv_agg's binary_logloss: 0.407848 + 0.00180942
[4]	cv_agg's binary_logloss: 0.406752 + 0.00200269
[5]	cv_agg's binary_logloss: 0.406351 + 0.00158279
[6]	cv_agg's binary_logloss: 0.406498 + 0.00177597
[7]	cv_agg's binary_logloss: 0.406896 + 0.002002
[8]	cv_agg's binary_logloss: 0.407066 + 0.00193785
[1]	cv_agg's binary_logloss: 0.421062 + 0.00107819
[2]	cv_agg's binary_logloss: 0.411339 + 0.00167395
[3]	cv_agg's binary_logloss: 0.407861 + 0.00173341
[4]	cv_agg's binary_logloss: 0.406741 + 0.00178552
[5]	cv_agg's binary_logloss: 0.406173 + 0.00196808
[6]	cv_agg's binary_logloss: 0.406192 + 0.00222315
[7]	cv_agg's binary_logloss: 0.406657 + 0.00215011
[8]	cv_agg's binary_logloss: 0.406892 + 0.00231745
[1]	cv_agg's binary_logloss: 0.421062 + 0.00107819
[2]	cv_agg's binary_logloss: 0.411342 + 0.00161934
[3]	cv_agg's binary_logloss: 0.407826 + 0.00182317
[4]	cv_agg's binary_logloss: 0.406603 + 0.00205319
[5]	cv_agg's binary_logloss: 0.406182 + 0.00233041
[6]	cv_agg's binary_logloss: 0.406069 + 0.00246412
[7]	cv_agg's binary_logloss: 0.406301 + 0.00272987
[8]	cv_agg's binary_logloss: 0.40673 + 0.00274334
[9]	cv_agg's binary_logloss: 0.406702 + 0.00270079
[1]	cv_agg's binary_logloss: 0.42111 + 0.000941609
[2]	cv_agg's binary_logloss: 0.411345 + 0.0015517
[3]	cv_agg's binary_logloss: 0.407819 + 0.00178552
[4]	cv_agg's binary_logloss: 0.406545 + 0.00171981
[5]	cv_agg's binary_logloss: 0.406447 + 0.00183844
[6]	cv_agg's binary_logloss: 0.406391 + 0.00218248
[7]	cv_agg's binary_logloss: 0.406539 + 0.00244188
[8]	cv_agg's binary_logloss: 0.406693 + 0.00232973
[9]	cv_agg's binary_logloss: 0.406901 + 0.00244087
[1]	cv_agg's binary_logloss: 0.421095 + 0.000972589
[2]	cv_agg's binary_logloss: 0.411131 + 0.00138962
[3]	cv_agg's binary_logloss: 0.4076 + 0.00169777
[4]	cv_agg's binary_logloss: 0.406354 + 0.00168019
[5]	cv_agg's binary_logloss: 0.406225 + 0.00185235
[6]	cv_agg's binary_logloss: 0.406166 + 0.00203531
[7]	cv_agg's binary_logloss: 0.406176 + 0.00216194
[8]	cv_agg's binary_logloss: 0.406127 + 0.00217316
[9]	cv_agg's binary_logloss: 0.40611 + 0.00221577
[10]	cv_agg's binary_logloss: 0.406099 + 0.00223325
[11]	cv_agg's binary_logloss: 0.4061 + 0.00223214
[12]	cv_agg's binary_logloss: 0.406113 + 0.00223247
[13]	cv_agg's binary_logloss: 0.406107 + 0.00226041
[1]	cv_agg's binary_logloss: 0.421067 + 0.00124741
[2]	cv_agg's binary_logloss: 0.411138 + 0.00156797
[3]	cv_agg's binary_logloss: 0.407763 + 0.00162992
[4]	cv_agg's binary_logloss: 0.40668 + 0.0014835
[5]	cv_agg's binary_logloss: 0.406789 + 0.00143214
[6]	cv_agg's binary_logloss: 0.406775 + 0.00158792
[7]	cv_agg's binary_logloss: 0.407446 + 0.00160648
[1]	cv_agg's binary_logloss: 0.421089 + 0.00126314
[2]	cv_agg's binary_logloss: 0.411173 + 0.00165562
[3]	cv_agg's binary_logloss: 0.407725 + 0.00200278
[4]	cv_agg's binary_logloss: 0.406497 + 0.00212765
[5]	cv_agg's binary_logloss: 0.40675 + 0.00209714
[6]	cv_agg's binary_logloss: 0.407008 + 0.00208906
[7]	cv_agg's binary_logloss: 0.407353 + 0.00231374
[1]	cv_agg's binary_logloss: 0.42106 + 0.00126491
[2]	cv_agg's binary_logloss: 0.411494 + 0.00185336
[3]	cv_agg's binary_logloss: 0.408312 + 0.0021059
[4]	cv_agg's binary_logloss: 0.407156 + 0.00194476
[5]	cv_agg's binary_logloss: 0.406975 + 0.00214723
[6]	cv_agg's binary_logloss: 0.407441 + 0.00225852
[7]	cv_agg's binary_logloss: 0.407559 + 0.00220682
[8]	cv_agg's binary_logloss: 0.40783 + 0.00213576
[1]	cv_agg's binary_logloss: 0.421141 + 0.00109024
[2]	cv_agg's binary_logloss: 0.411631 + 0.00148528
[3]	cv_agg's binary_logloss: 0.408066 + 0.00164278
[4]	cv_agg's binary_logloss: 0.407182 + 0.00181958
[5]	cv_agg's binary_logloss: 0.406833 + 0.00189065
[6]	cv_agg's binary_logloss: 0.40705 + 0.00182739
[7]	cv_agg's binary_logloss: 0.407155 + 0.00211284
[8]	cv_agg's binary_logloss: 0.407436 + 0.00217901
[1]	cv_agg's binary_logloss: 0.421135 + 0.00115108
[2]	cv_agg's binary_logloss: 0.41137 + 0.00156964
[3]	cv_agg's binary_logloss: 0.408067 + 0.00169314
[4]	cv_agg's binary_logloss: 0.406772 + 0.00166631
[5]	cv_agg's binary_logloss: 0.4065 + 0.00165118
[6]	cv_agg's binary_logloss: 0.406529 + 0.00175896
[7]	cv_agg's binary_logloss: 0.406679 + 0.00159412
[8]	cv_agg's binary_logloss: 0.406673 + 0.00169696
[1]	cv_agg's binary_logloss: 0.42099 + 0.00117859
[2]	cv_agg's binary_logloss: 0.411238 + 0.00170364
[3]	cv_agg's binary_logloss: 0.407769 + 0.00212058
[4]	cv_agg's binary_logloss: 0.40687 + 0.0024207
[5]	cv_agg's binary_logloss: 0.40679 + 0.00268329
[6]	cv_agg's binary_logloss: 0.407073 + 0.00273911
[7]	cv_agg's binary_logloss: 0.407405 + 0.00251637
[8]	cv_agg's binary_logloss: 0.407803 + 0.00252044
[1]	cv_agg's binary_logloss: 0.420993 + 0.00117793
[2]	cv_agg's binary_logloss: 0.411451 + 0.001885
[3]	cv_agg's binary_logloss: 0.407999 + 0.00230709
[4]	cv_agg's binary_logloss: 0.406797 + 0.00233957
[5]	cv_agg's binary_logloss: 0.406702 + 0.00230573
[6]	cv_agg's binary_logloss: 0.406482 + 0.00199994
[7]	cv_agg's binary_logloss: 0.406636 + 0.00196642
[8]	cv_agg's binary_logloss: 0.406942 + 0.0018256
[9]	cv_agg's binary_logloss: 0.407424 + 0.00190412
[1]	cv_agg's binary_logloss: 0.421088 + 0.00113829
[2]	cv_agg's binary_logloss: 0.411435 + 0.00187644
[3]	cv_agg's binary_logloss: 0.408085 + 0.00205587
[4]	cv_agg's binary_logloss: 0.406801 + 0.00209561
[5]	cv_agg's binary_logloss: 0.406422 + 0.0022752
[6]	cv_agg's binary_logloss: 0.406652 + 0.00224444
[7]	cv_agg's binary_logloss: 0.406999 + 0.0019039
[8]	cv_agg's binary_logloss: 0.407299 + 0.0018484
[1]	cv_agg's binary_logloss: 0.421002 + 0.00103885
[2]	cv_agg's binary_logloss: 0.411284 + 0.00164913
[3]	cv_agg's binary_logloss: 0.407695 + 0.00162641
[4]	cv_agg's binary_logloss: 0.406828 + 0.00187617
[5]	cv_agg's binary_logloss: 0.406529 + 0.00196327
[6]	cv_agg's binary_logloss: 0.406552 + 0.001904
[7]	cv_agg's binary_logloss: 0.406966 + 0.00191588
[8]	cv_agg's binary_logloss: 0.407195 + 0.00190119
[1]	cv_agg's binary_logloss: 0.421032 + 0.0010766
[2]	cv_agg's binary_logloss: 0.41126 + 0.00157523
[3]	cv_agg's binary_logloss: 0.407855 + 0.00146706
[4]	cv_agg's binary_logloss: 0.406723 + 0.00155034
[5]	cv_agg's binary_logloss: 0.406456 + 0.00151387
[6]	cv_agg's binary_logloss: 0.406436 + 0.00145768
[7]	cv_agg's binary_logloss: 0.406442 + 0.00182874
[8]	cv_agg's binary_logloss: 0.406576 + 0.00186062
[9]	cv_agg's binary_logloss: 0.406609 + 0.00192987
[1]	cv_agg's binary_logloss: 0.420929 + 0.00101991
[2]	cv_agg's binary_logloss: 0.411331 + 0.00171216
[3]	cv_agg's binary_logloss: 0.407813 + 0.00192742
[4]	cv_agg's binary_logloss: 0.406774 + 0.00186989
[5]	cv_agg's binary_logloss: 0.406462 + 0.00188002
[6]	cv_agg's binary_logloss: 0.406542 + 0.00196547
[7]	cv_agg's binary_logloss: 0.406991 + 0.00224817
[8]	cv_agg's binary_logloss: 0.40755 + 0.00231917
[1]	cv_agg's binary_logloss: 0.42098 + 0.00107768
[2]	cv_agg's binary_logloss: 0.411562 + 0.00184633
[3]	cv_agg's binary_logloss: 0.40816 + 0.00213395
[4]	cv_agg's binary_logloss: 0.407005 + 0.00221795
[5]	cv_agg's binary_logloss: 0.406493 + 0.00230224
[6]	cv_agg's binary_logloss: 0.406546 + 0.00227019
[7]	cv_agg's binary_logloss: 0.407294 + 0.00247069
[8]	cv_agg's binary_logloss: 0.407637 + 0.00242676
[1]	cv_agg's binary_logloss: 0.420968 + 0.000989678
[2]	cv_agg's binary_logloss: 0.411492 + 0.00173861
[3]	cv_agg's binary_logloss: 0.407883 + 0.00162737
[4]	cv_agg's binary_logloss: 0.406964 + 0.00174386
[5]	cv_agg's binary_logloss: 0.406178 + 0.00179965
[6]	cv_agg's binary_logloss: 0.406311 + 0.00178805
[7]	cv_agg's binary_logloss: 0.406284 + 0.00191639
[8]	cv_agg's binary_logloss: 0.406649 + 0.00183754
[1]	cv_agg's binary_logloss: 0.421005 + 0.000970989
[2]	cv_agg's binary_logloss: 0.411421 + 0.00161696
[3]	cv_agg's binary_logloss: 0.407822 + 0.00166362
[4]	cv_agg's binary_logloss: 0.406834 + 0.00192707
[5]	cv_agg's binary_logloss: 0.406683 + 0.0021715
[6]	cv_agg's binary_logloss: 0.406759 + 0.00240937
[7]	cv_agg's binary_logloss: 0.406435 + 0.00303258
[8]	cv_agg's binary_logloss: 0.406764 + 0.003112
[9]	cv_agg's binary_logloss: 0.406749 + 0.00315362
[10]	cv_agg's binary_logloss: 0.40675 + 0.0032273
[1]	cv_agg's binary_logloss: 0.421049 + 0.000995956
[2]	cv_agg's binary_logloss: 0.411424 + 0.00159344
[3]	cv_agg's binary_logloss: 0.407926 + 0.0017856
[4]	cv_agg's binary_logloss: 0.406533 + 0.00199667
[5]	cv_agg's binary_logloss: 0.406173 + 0.00222473
[6]	cv_agg's binary_logloss: 0.405861 + 0.00238645
[7]	cv_agg's binary_logloss: 0.40593 + 0.00229017
[8]	cv_agg's binary_logloss: 0.405838 + 0.00235491
[9]	cv_agg's binary_logloss: 0.405846 + 0.00235354
[10]	cv_agg's binary_logloss: 0.40584 + 0.00237992
[11]	cv_agg's binary_logloss: 0.405837 + 0.00238632
[12]	cv_agg's binary_logloss: 0.405864 + 0.00240781
[13]	cv_agg's binary_logloss: 0.405864 + 0.00240781
[14]	cv_agg's binary_logloss: 0.405864 + 0.00240781
[1]	cv_agg's binary_logloss: 0.421043 + 0.00111069
[2]	cv_agg's binary_logloss: 0.411385 + 0.00171507
[3]	cv_agg's binary_logloss: 0.407727 + 0.00188548
[4]	cv_agg's binary_logloss: 0.406461 + 0.0021775
[5]	cv_agg's binary_logloss: 0.40643 + 0.0021926
[6]	cv_agg's binary_logloss: 0.406233 + 0.00235437
[7]	cv_agg's binary_logloss: 0.406534 + 0.00245812
[8]	cv_agg's binary_logloss: 0.406912 + 0.00263922
[9]	cv_agg's binary_logloss: 0.407297 + 0.00271758
[1]	cv_agg's binary_logloss: 0.421043 + 0.00111069
[2]	cv_agg's binary_logloss: 0.411285 + 0.00184258
[3]	cv_agg's binary_logloss: 0.4077 + 0.00213943
[4]	cv_agg's binary_logloss: 0.406702 + 0.00196847
[5]	cv_agg's binary_logloss: 0.406177 + 0.00197207
[6]	cv_agg's binary_logloss: 0.40633 + 0.00194201
[7]	cv_agg's binary_logloss: 0.406638 + 0.00157785
[8]	cv_agg's binary_logloss: 0.40703 + 0.00192921
[1]	cv_agg's binary_logloss: 0.421092 + 0.000954079
[2]	cv_agg's binary_logloss: 0.411499 + 0.00145306
[3]	cv_agg's binary_logloss: 0.407801 + 0.00175863
[4]	cv_agg's binary_logloss: 0.406808 + 0.00180054
[5]	cv_agg's binary_logloss: 0.406311 + 0.00226079
[6]	cv_agg's binary_logloss: 0.406098 + 0.00247401
[7]	cv_agg's binary_logloss: 0.406531 + 0.00255027
[8]	cv_agg's binary_logloss: 0.406708 + 0.0028216
[9]	cv_agg's binary_logloss: 0.407295 + 0.0029502
[1]	cv_agg's binary_logloss: 0.421074 + 0.000949542
[2]	cv_agg's binary_logloss: 0.411179 + 0.00124969
[3]	cv_agg's binary_logloss: 0.407518 + 0.00175445
[4]	cv_agg's binary_logloss: 0.406081 + 0.00168721
[5]	cv_agg's binary_logloss: 0.405909 + 0.00187093
[6]	cv_agg's binary_logloss: 0.406026 + 0.00190191
[7]	cv_agg's binary_logloss: 0.406154 + 0.00229229
[8]	cv_agg's binary_logloss: 0.406236 + 0.002337
[1]	cv_agg's binary_logloss: 0.42104 + 0.00103179
[2]	cv_agg's binary_logloss: 0.41109 + 0.00136656
[3]	cv_agg's binary_logloss: 0.407571 + 0.00159682
[4]	cv_agg's binary_logloss: 0.406279 + 0.00201862
[5]	cv_agg's binary_logloss: 0.405778 + 0.00206126
[6]	cv_agg's binary_logloss: 0.405954 + 0.00230204
[7]	cv_agg's binary_logloss: 0.405849 + 0.00235547
[8]	cv_agg's binary_logloss: 0.405803 + 0.00246859
[1]	cv_agg's binary_logloss: 0.421001 + 0.00105509
[2]	cv_agg's binary_logloss: 0.411347 + 0.00172356
[3]	cv_agg's binary_logloss: 0.408079 + 0.00182205
[4]	cv_agg's binary_logloss: 0.407005 + 0.00206033
[5]	cv_agg's binary_logloss: 0.406851 + 0.00220216
[6]	cv_agg's binary_logloss: 0.407134 + 0.00248731
[7]	cv_agg's binary_logloss: 0.40755 + 0.00253569
[8]	cv_agg's binary_logloss: 0.407976 + 0.00254672
[1]	cv_agg's binary_logloss: 0.42107 + 0.000930498
[2]	cv_agg's binary_logloss: 0.411488 + 0.00168181
[3]	cv_agg's binary_logloss: 0.408179 + 0.00175944
[4]	cv_agg's binary_logloss: 0.407161 + 0.00168795
[5]	cv_agg's binary_logloss: 0.406603 + 0.00207185
[6]	cv_agg's binary_logloss: 0.406524 + 0.00189058
[7]	cv_agg's binary_logloss: 0.406978 + 0.00195751
[8]	cv_agg's binary_logloss: 0.407095 + 0.0019911
[9]	cv_agg's binary_logloss: 0.407183 + 0.0021875
[1]	cv_agg's binary_logloss: 0.421072 + 0.000926935
[2]	cv_agg's binary_logloss: 0.4116 + 0.0014615
[3]	cv_agg's binary_logloss: 0.407861 + 0.00162295
[4]	cv_agg's binary_logloss: 0.406598 + 0.0017207
[5]	cv_agg's binary_logloss: 0.40637 + 0.00193997
[6]	cv_agg's binary_logloss: 0.406268 + 0.00210178
[7]	cv_agg's binary_logloss: 0.406632 + 0.00235164
[8]	cv_agg's binary_logloss: 0.406873 + 0.00239909
[9]	cv_agg's binary_logloss: 0.407163 + 0.00234706
[1]	cv_agg's binary_logloss: 0.421062 + 0.000939354
[2]	cv_agg's binary_logloss: 0.411323 + 0.00153917
[3]	cv_agg's binary_logloss: 0.407646 + 0.00206671
[4]	cv_agg's binary_logloss: 0.40636 + 0.00183643
[5]	cv_agg's binary_logloss: 0.40602 + 0.00198606
[6]	cv_agg's binary_logloss: 0.406171 + 0.0019912
[7]	cv_agg's binary_logloss: 0.406358 + 0.00195011
[8]	cv_agg's binary_logloss: 0.406585 + 0.00217085
[1]	cv_agg's binary_logloss: 0.421082 + 0.000923162
[2]	cv_agg's binary_logloss: 0.411047 + 0.00123197
[3]	cv_agg's binary_logloss: 0.407361 + 0.00163744
[4]	cv_agg's binary_logloss: 0.406212 + 0.00172394
[5]	cv_agg's binary_logloss: 0.405801 + 0.00200303
[6]	cv_agg's binary_logloss: 0.405508 + 0.00198032
[7]	cv_agg's binary_logloss: 0.405522 + 0.00210993
[8]	cv_agg's binary_logloss: 0.405597 + 0.00221295
[9]	cv_agg's binary_logloss: 0.405674 + 0.00234228
[1]	cv_agg's binary_logloss: 0.420985 + 0.00120945
[2]	cv_agg's binary_logloss: 0.41134 + 0.00188393
[3]	cv_agg's binary_logloss: 0.408127 + 0.00216347
[4]	cv_agg's binary_logloss: 0.407003 + 0.00215438
[5]	cv_agg's binary_logloss: 0.406709 + 0.00209781
[6]	cv_agg's binary_logloss: 0.40703 + 0.00215165
[7]	cv_agg's binary_logloss: 0.407236 + 0.00248519
[8]	cv_agg's binary_logloss: 0.407536 + 0.00249196
[1]	cv_agg's binary_logloss: 0.421037 + 0.00122241
[2]	cv_agg's binary_logloss: 0.411412 + 0.00185217
[3]	cv_agg's binary_logloss: 0.408049 + 0.00218012
[4]	cv_agg's binary_logloss: 0.407017 + 0.00220448
[5]	cv_agg's binary_logloss: 0.406756 + 0.0023445
[6]	cv_agg's binary_logloss: 0.406476 + 0.00263073
[7]	cv_agg's binary_logloss: 0.406721 + 0.00247582
[8]	cv_agg's binary_logloss: 0.407159 + 0.00252108
[9]	cv_agg's binary_logloss: 0.407599 + 0.00258225
[1]	cv_agg's binary_logloss: 0.42118 + 0.00113393
[2]	cv_agg's binary_logloss: 0.41177 + 0.00175012
[3]	cv_agg's binary_logloss: 0.408206 + 0.00207822
[4]	cv_agg's binary_logloss: 0.407276 + 0.00215349
[5]	cv_agg's binary_logloss: 0.406808 + 0.0023567
[6]	cv_agg's binary_logloss: 0.407063 + 0.00226902
[7]	cv_agg's binary_logloss: 0.407411 + 0.00231646
[8]	cv_agg's binary_logloss: 0.407602 + 0.0021542
[1]	cv_agg's binary_logloss: 0.421155 + 0.00111348
[2]	cv_agg's binary_logloss: 0.411418 + 0.0016827
[3]	cv_agg's binary_logloss: 0.40804 + 0.0018311
[4]	cv_agg's binary_logloss: 0.406918 + 0.0017008
[5]	cv_agg's binary_logloss: 0.406662 + 0.00175748
[6]	cv_agg's binary_logloss: 0.406692 + 0.00177186
[7]	cv_agg's binary_logloss: 0.406731 + 0.00174319
[8]	cv_agg's binary_logloss: 0.40684 + 0.00162741
[1]	cv_agg's binary_logloss: 0.421061 + 0.00117663
[2]	cv_agg's binary_logloss: 0.411331 + 0.00159587
[3]	cv_agg's binary_logloss: 0.407703 + 0.00168883
[4]	cv_agg's binary_logloss: 0.406454 + 0.00196116
[5]	cv_agg's binary_logloss: 0.406229 + 0.00220459
[6]	cv_agg's binary_logloss: 0.406265 + 0.00222997
[7]	cv_agg's binary_logloss: 0.406235 + 0.00236915
[8]	cv_agg's binary_logloss: 0.406401 + 0.00250538
[1]	cv_agg's binary_logloss: 0.420995 + 0.00101821
[2]	cv_agg's binary_logloss: 0.411545 + 0.00183941
[3]	cv_agg's binary_logloss: 0.407989 + 0.00233408
[4]	cv_agg's binary_logloss: 0.40682 + 0.00266684
[5]	cv_agg's binary_logloss: 0.40627 + 0.00273509
[6]	cv_agg's binary_logloss: 0.40648 + 0.00261678
[7]	cv_agg's binary_logloss: 0.406834 + 0.00242345
[8]	cv_agg's binary_logloss: 0.407474 + 0.00252282
[1]	cv_agg's binary_logloss: 0.421101 + 0.00100118
[2]	cv_agg's binary_logloss: 0.411721 + 0.00156938
[3]	cv_agg's binary_logloss: 0.408186 + 0.00197069
[4]	cv_agg's binary_logloss: 0.406824 + 0.00208361
[5]	cv_agg's binary_logloss: 0.406388 + 0.0018634
[6]	cv_agg's binary_logloss: 0.406624 + 0.0019133
[7]	cv_agg's binary_logloss: 0.406904 + 0.00213998
[8]	cv_agg's binary_logloss: 0.407106 + 0.00228591
[1]	cv_agg's binary_logloss: 0.421027 + 0.000988334
[2]	cv_agg's binary_logloss: 0.411378 + 0.00165276
[3]	cv_agg's binary_logloss: 0.407777 + 0.00174519
[4]	cv_agg's binary_logloss: 0.406815 + 0.00194092
[5]	cv_agg's binary_logloss: 0.406679 + 0.00180657
[6]	cv_agg's binary_logloss: 0.406707 + 0.00198819
[7]	cv_agg's binary_logloss: 0.406876 + 0.00196893
[8]	cv_agg's binary_logloss: 0.407098 + 0.00212577
[1]	cv_agg's binary_logloss: 0.421042 + 0.00107053
[2]	cv_agg's binary_logloss: 0.411247 + 0.00169305
[3]	cv_agg's binary_logloss: 0.407494 + 0.0019061
[4]	cv_agg's binary_logloss: 0.406413 + 0.00204285
[5]	cv_agg's binary_logloss: 0.406386 + 0.00219698
[6]	cv_agg's binary_logloss: 0.406476 + 0.00228292
[7]	cv_agg's binary_logloss: 0.406579 + 0.00225287
[8]	cv_agg's binary_logloss: 0.406582 + 0.00227131
[1]	cv_agg's binary_logloss: 0.420965 + 0.00109432
[2]	cv_agg's binary_logloss: 0.411186 + 0.00159273
[3]	cv_agg's binary_logloss: 0.407436 + 0.00165838
[4]	cv_agg's binary_logloss: 0.406562 + 0.00185118
[5]	cv_agg's binary_logloss: 0.405894 + 0.00160806
[6]	cv_agg's binary_logloss: 0.406102 + 0.00166574
[7]	cv_agg's binary_logloss: 0.406106 + 0.00174587
[8]	cv_agg's binary_logloss: 0.40626 + 0.00175306
[1]	cv_agg's binary_logloss: 0.421004 + 0.00106996
[2]	cv_agg's binary_logloss: 0.411188 + 0.00173923
[3]	cv_agg's binary_logloss: 0.408035 + 0.00217704
[4]	cv_agg's binary_logloss: 0.406845 + 0.00211861
[5]	cv_agg's binary_logloss: 0.406466 + 0.00246456
[6]	cv_agg's binary_logloss: 0.406449 + 0.00232265
[7]	cv_agg's binary_logloss: 0.406501 + 0.00241204
[8]	cv_agg's binary_logloss: 0.407088 + 0.00215656
[9]	cv_agg's binary_logloss: 0.407391 + 0.00246488
[1]	cv_agg's binary_logloss: 0.421084 + 0.00095516
[2]	cv_agg's binary_logloss: 0.411436 + 0.00140438
[3]	cv_agg's binary_logloss: 0.407714 + 0.00152877
[4]	cv_agg's binary_logloss: 0.406751 + 0.00177177
[5]	cv_agg's binary_logloss: 0.406414 + 0.00184657
[6]	cv_agg's binary_logloss: 0.406343 + 0.00193323
[7]	cv_agg's binary_logloss: 0.406773 + 0.00209761
[8]	cv_agg's binary_logloss: 0.407107 + 0.00196519
[9]	cv_agg's binary_logloss: 0.40734 + 0.00210724
[1]	cv_agg's binary_logloss: 0.421069 + 0.000950571
[2]	cv_agg's binary_logloss: 0.411345 + 0.00126654
[3]	cv_agg's binary_logloss: 0.407662 + 0.00168602
[4]	cv_agg's binary_logloss: 0.406413 + 0.00177451
[5]	cv_agg's binary_logloss: 0.406147 + 0.00205641
[6]	cv_agg's binary_logloss: 0.406221 + 0.00217966
[7]	cv_agg's binary_logloss: 0.406502 + 0.0023514
[8]	cv_agg's binary_logloss: 0.406934 + 0.00234384
[1]	cv_agg's binary_logloss: 0.421048 + 0.000924034
[2]	cv_agg's binary_logloss: 0.411256 + 0.00130977
[3]	cv_agg's binary_logloss: 0.407404 + 0.00167522
[4]	cv_agg's binary_logloss: 0.406243 + 0.00152502
[5]	cv_agg's binary_logloss: 0.406242 + 0.00186949
[6]	cv_agg's binary_logloss: 0.406495 + 0.00195423
[7]	cv_agg's binary_logloss: 0.406556 + 0.00222118
[8]	cv_agg's binary_logloss: 0.406659 + 0.00228132
[1]	cv_agg's binary_logloss: 0.421012 + 0.00100325
[2]	cv_agg's binary_logloss: 0.411064 + 0.00136149
[3]	cv_agg's binary_logloss: 0.407518 + 0.00138498
[4]	cv_agg's binary_logloss: 0.406476 + 0.00172578
[5]	cv_agg's binary_logloss: 0.406081 + 0.00180649
[6]	cv_agg's binary_logloss: 0.406123 + 0.00169343
[7]	cv_agg's binary_logloss: 0.40617 + 0.00171054
[8]	cv_agg's binary_logloss: 0.406237 + 0.00191603
[1]	cv_agg's binary_logloss: 0.421059 + 0.00100101
[2]	cv_agg's binary_logloss: 0.411476 + 0.00149275
[3]	cv_agg's binary_logloss: 0.408039 + 0.00159081
[4]	cv_agg's binary_logloss: 0.406895 + 0.00185442
[5]	cv_agg's binary_logloss: 0.406394 + 0.00167451
[6]	cv_agg's binary_logloss: 0.406198 + 0.00176544
[7]	cv_agg's binary_logloss: 0.406443 + 0.00190215
[8]	cv_agg's binary_logloss: 0.406714 + 0.00202193
[9]	cv_agg's binary_logloss: 0.407244 + 0.00203798
[1]	cv_agg's binary_logloss: 0.421103 + 0.000895635
[2]	cv_agg's binary_logloss: 0.411474 + 0.00175117
[3]	cv_agg's binary_logloss: 0.407814 + 0.0017599
[4]	cv_agg's binary_logloss: 0.406658 + 0.00160086
[5]	cv_agg's binary_logloss: 0.406304 + 0.00179295
[6]	cv_agg's binary_logloss: 0.406361 + 0.00200417
[7]	cv_agg's binary_logloss: 0.406431 + 0.00217389
[8]	cv_agg's binary_logloss: 0.406703 + 0.00218206
[1]	cv_agg's binary_logloss: 0.421103 + 0.0009178
[2]	cv_agg's binary_logloss: 0.411417 + 0.00136889
[3]	cv_agg's binary_logloss: 0.407962 + 0.00175973
[4]	cv_agg's binary_logloss: 0.406727 + 0.00200047
[5]	cv_agg's binary_logloss: 0.406431 + 0.00189239
[6]	cv_agg's binary_logloss: 0.406542 + 0.00247256
[7]	cv_agg's binary_logloss: 0.406824 + 0.00239858
[8]	cv_agg's binary_logloss: 0.406935 + 0.00226189
[1]	cv_agg's binary_logloss: 0.421062 + 0.000860942
[2]	cv_agg's binary_logloss: 0.411203 + 0.00140692
[3]	cv_agg's binary_logloss: 0.407771 + 0.00166648
[4]	cv_agg's binary_logloss: 0.4063 + 0.0016422
[5]	cv_agg's binary_logloss: 0.406079 + 0.00180975
[6]	cv_agg's binary_logloss: 0.406245 + 0.001925
[7]	cv_agg's binary_logloss: 0.406638 + 0.00166502
[8]	cv_agg's binary_logloss: 0.40662 + 0.00191447
[1]	cv_agg's binary_logloss: 0.421091 + 0.000889555
[2]	cv_agg's binary_logloss: 0.411234 + 0.00144077
[3]	cv_agg's binary_logloss: 0.407557 + 0.00161528
[4]	cv_agg's binary_logloss: 0.406598 + 0.00157554
[5]	cv_agg's binary_logloss: 0.406098 + 0.0016687
[6]	cv_agg's binary_logloss: 0.406029 + 0.00180035
[7]	cv_agg's binary_logloss: 0.405789 + 0.001865
[8]	cv_agg's binary_logloss: 0.40582 + 0.00190193
[9]	cv_agg's binary_logloss: 0.405767 + 0.00185605
[10]	cv_agg's binary_logloss: 0.405782 + 0.00187655
[11]	cv_agg's binary_logloss: 0.405789 + 0.00188221
[12]	cv_agg's binary_logloss: 0.405791 + 0.00188444
[1]	cv_agg's binary_logloss: 0.420966 + 0.000652125
[2]	cv_agg's binary_logloss: 0.41119 + 0.00162939
[3]	cv_agg's binary_logloss: 0.407623 + 0.00182697
[4]	cv_agg's binary_logloss: 0.406488 + 0.00186393
[5]	cv_agg's binary_logloss: 0.405908 + 0.00178717
[6]	cv_agg's binary_logloss: 0.406202 + 0.00172624
[7]	cv_agg's binary_logloss: 0.406556 + 0.00167935
[8]	cv_agg's binary_logloss: 0.406795 + 0.0018861
[1]	cv_agg's binary_logloss: 0.420918 + 0.000658254
[2]	cv_agg's binary_logloss: 0.411203 + 0.00143844
[3]	cv_agg's binary_logloss: 0.407695 + 0.00185705
[4]	cv_agg's binary_logloss: 0.406618 + 0.00197675
[5]	cv_agg's binary_logloss: 0.406206 + 0.00161268
[6]	cv_agg's binary_logloss: 0.406366 + 0.00163623
[7]	cv_agg's binary_logloss: 0.406463 + 0.00173474
[8]	cv_agg's binary_logloss: 0.406701 + 0.00170091
[1]	cv_agg's binary_logloss: 0.420925 + 0.000597871
[2]	cv_agg's binary_logloss: 0.41118 + 0.00112009
[3]	cv_agg's binary_logloss: 0.407571 + 0.0014228
[4]	cv_agg's binary_logloss: 0.406341 + 0.00154849
[5]	cv_agg's binary_logloss: 0.406065 + 0.00139679
[6]	cv_agg's binary_logloss: 0.406181 + 0.0014409
[7]	cv_agg's binary_logloss: 0.406318 + 0.00126196
[8]	cv_agg's binary_logloss: 0.40634 + 0.00139615
[1]	cv_agg's binary_logloss: 0.420936 + 0.000681499
[2]	cv_agg's binary_logloss: 0.411187 + 0.00135758
[3]	cv_agg's binary_logloss: 0.407614 + 0.00206763
[4]	cv_agg's binary_logloss: 0.406335 + 0.00217298
[5]	cv_agg's binary_logloss: 0.406118 + 0.00245597
[6]	cv_agg's binary_logloss: 0.406092 + 0.00254469
[7]	cv_agg's binary_logloss: 0.4062 + 0.00282329
[8]	cv_agg's binary_logloss: 0.406397 + 0.00292439
[9]	cv_agg's binary_logloss: 0.406359 + 0.00300938
[1]	cv_agg's binary_logloss: 0.420889 + 0.000683227
[2]	cv_agg's binary_logloss: 0.410994 + 0.00121426
[3]	cv_agg's binary_logloss: 0.40737 + 0.00121537
[4]	cv_agg's binary_logloss: 0.406038 + 0.00120375
[5]	cv_agg's binary_logloss: 0.405837 + 0.00122064
[6]	cv_agg's binary_logloss: 0.405648 + 0.00146563
[7]	cv_agg's binary_logloss: 0.405791 + 0.00176801
[8]	cv_agg's binary_logloss: 0.405805 + 0.00172425
[9]	cv_agg's binary_logloss: 0.40579 + 0.00176242
[1]	cv_agg's binary_logloss: 0.421014 + 0.000949229
[2]	cv_agg's binary_logloss: 0.411618 + 0.00149873
[3]	cv_agg's binary_logloss: 0.408248 + 0.00181962
[4]	cv_agg's binary_logloss: 0.40707 + 0.00219698
[5]	cv_agg's binary_logloss: 0.40686 + 0.00212417
[6]	cv_agg's binary_logloss: 0.407287 + 0.00175851
[7]	cv_agg's binary_logloss: 0.407552 + 0.00181647
[8]	cv_agg's binary_logloss: 0.407875 + 0.00211749
[1]	cv_agg's binary_logloss: 0.421102 + 0.00100986
[2]	cv_agg's binary_logloss: 0.411532 + 0.00171764
[3]	cv_agg's binary_logloss: 0.407831 + 0.00206135
[4]	cv_agg's binary_logloss: 0.40689 + 0.00216113
[5]	cv_agg's binary_logloss: 0.406481 + 0.00225061
[6]	cv_agg's binary_logloss: 0.406705 + 0.00203415
[7]	cv_agg's binary_logloss: 0.406854 + 0.00221974
[8]	cv_agg's binary_logloss: 0.407149 + 0.00226602
[1]	cv_agg's binary_logloss: 0.421029 + 0.00105396
[2]	cv_agg's binary_logloss: 0.411331 + 0.00162378
[3]	cv_agg's binary_logloss: 0.407825 + 0.00154262
[4]	cv_agg's binary_logloss: 0.406437 + 0.00180294
[5]	cv_agg's binary_logloss: 0.405952 + 0.00171079
[6]	cv_agg's binary_logloss: 0.406139 + 0.00169813
[7]	cv_agg's binary_logloss: 0.406621 + 0.00147896
[8]	cv_agg's binary_logloss: 0.406845 + 0.00131231
[1]	cv_agg's binary_logloss: 0.421073 + 0.00110742
[2]	cv_agg's binary_logloss: 0.411438 + 0.00149506
[3]	cv_agg's binary_logloss: 0.407624 + 0.0017683
[4]	cv_agg's binary_logloss: 0.406346 + 0.00172013
[5]	cv_agg's binary_logloss: 0.40618 + 0.00186132
[6]	cv_agg's binary_logloss: 0.406318 + 0.00221222
[7]	cv_agg's binary_logloss: 0.406494 + 0.00236693
[8]	cv_agg's binary_logloss: 0.40649 + 0.00260374
[1]	cv_agg's binary_logloss: 0.421069 + 0.00111196
[2]	cv_agg's binary_logloss: 0.411309 + 0.00160158
[3]	cv_agg's binary_logloss: 0.407605 + 0.00163206
[4]	cv_agg's binary_logloss: 0.406542 + 0.00174487
[5]	cv_agg's binary_logloss: 0.406019 + 0.00180034
[6]	cv_agg's binary_logloss: 0.40602 + 0.00185609
[7]	cv_agg's binary_logloss: 0.405956 + 0.00193518
[8]	cv_agg's binary_logloss: 0.406111 + 0.00208713
[9]	cv_agg's binary_logloss: 0.406174 + 0.00213143
[10]	cv_agg's binary_logloss: 0.406149 + 0.00215588
[1]	cv_agg's binary_logloss: 0.421016 + 0.000967143
[2]	cv_agg's binary_logloss: 0.411683 + 0.0016267
[3]	cv_agg's binary_logloss: 0.408427 + 0.00184576
[4]	cv_agg's binary_logloss: 0.407447 + 0.0019071
[5]	cv_agg's binary_logloss: 0.40698 + 0.00180531
[6]	cv_agg's binary_logloss: 0.407088 + 0.00184774
[7]	cv_agg's binary_logloss: 0.40742 + 0.00165974
[8]	cv_agg's binary_logloss: 0.40778 + 0.00175893
[1]	cv_agg's binary_logloss: 0.42099 + 0.00100573
[2]	cv_agg's binary_logloss: 0.411616 + 0.00178334
[3]	cv_agg's binary_logloss: 0.407946 + 0.00205377
[4]	cv_agg's binary_logloss: 0.407046 + 0.00197393
[5]	cv_agg's binary_logloss: 0.406683 + 0.00195377
[6]	cv_agg's binary_logloss: 0.406929 + 0.00207557
[7]	cv_agg's binary_logloss: 0.407047 + 0.00221307
[8]	cv_agg's binary_logloss: 0.407078 + 0.00229185
[1]	cv_agg's binary_logloss: 0.42099 + 0.000979991
[2]	cv_agg's binary_logloss: 0.411475 + 0.00163677
[3]	cv_agg's binary_logloss: 0.407462 + 0.00211736
[4]	cv_agg's binary_logloss: 0.406248 + 0.00211288
[5]	cv_agg's binary_logloss: 0.4055 + 0.00216835
[6]	cv_agg's binary_logloss: 0.405625 + 0.00213125
[7]	cv_agg's binary_logloss: 0.405821 + 0.00208166
[8]	cv_agg's binary_logloss: 0.406083 + 0.00223578
[1]	cv_agg's binary_logloss: 0.420971 + 0.00106358
[2]	cv_agg's binary_logloss: 0.41115 + 0.00164844
[3]	cv_agg's binary_logloss: 0.407587 + 0.00166988
[4]	cv_agg's binary_logloss: 0.406574 + 0.00170437
[5]	cv_agg's binary_logloss: 0.406322 + 0.00157953
[6]	cv_agg's binary_logloss: 0.4061 + 0.00183397
[7]	cv_agg's binary_logloss: 0.406305 + 0.0018159
[8]	cv_agg's binary_logloss: 0.40639 + 0.00191797
[9]	cv_agg's binary_logloss: 0.406236 + 0.00213832
[1]	cv_agg's binary_logloss: 0.421082 + 0.000993488
[2]	cv_agg's binary_logloss: 0.411474 + 0.00148721
[3]	cv_agg's binary_logloss: 0.407832 + 0.00139554
[4]	cv_agg's binary_logloss: 0.406484 + 0.00136431
[5]	cv_agg's binary_logloss: 0.406064 + 0.00125181
[6]	cv_agg's binary_logloss: 0.406079 + 0.00114048
[7]	cv_agg's binary_logloss: 0.405981 + 0.00130366
[8]	cv_agg's binary_logloss: 0.405967 + 0.00135441
[9]	cv_agg's binary_logloss: 0.406019 + 0.00134923
[10]	cv_agg's binary_logloss: 0.406011 + 0.00137538
[11]	cv_agg's binary_logloss: 0.406021 + 0.00139286
[1]	cv_agg's binary_logloss: 0.420851 + 0.000677815
[2]	cv_agg's binary_logloss: 0.411252 + 0.00131596
[3]	cv_agg's binary_logloss: 0.40777 + 0.00145148
[4]	cv_agg's binary_logloss: 0.406743 + 0.00168553
[5]	cv_agg's binary_logloss: 0.406693 + 0.00201275
[6]	cv_agg's binary_logloss: 0.406722 + 0.00196373
[7]	cv_agg's binary_logloss: 0.407025 + 0.00200427
[8]	cv_agg's binary_logloss: 0.407301 + 0.0023519
[1]	cv_agg's binary_logloss: 0.420889 + 0.000663828
[2]	cv_agg's binary_logloss: 0.411093 + 0.0014208
[3]	cv_agg's binary_logloss: 0.407537 + 0.00168937
[4]	cv_agg's binary_logloss: 0.406238 + 0.00178058
[5]	cv_agg's binary_logloss: 0.405869 + 0.00198803
[6]	cv_agg's binary_logloss: 0.405722 + 0.00172797
[7]	cv_agg's binary_logloss: 0.405883 + 0.00206846
[8]	cv_agg's binary_logloss: 0.406317 + 0.0022414
[9]	cv_agg's binary_logloss: 0.40669 + 0.00215977
[1]	cv_agg's binary_logloss: 0.420882 + 0.000649876
[2]	cv_agg's binary_logloss: 0.411021 + 0.00123182
[3]	cv_agg's binary_logloss: 0.407452 + 0.00137112
[4]	cv_agg's binary_logloss: 0.406478 + 0.00151325
[5]	cv_agg's binary_logloss: 0.405984 + 0.00148944
[6]	cv_agg's binary_logloss: 0.405886 + 0.00161427
[7]	cv_agg's binary_logloss: 0.40613 + 0.00187289
[8]	cv_agg's binary_logloss: 0.406439 + 0.00173779
[9]	cv_agg's binary_logloss: 0.406538 + 0.00168368
[1]	cv_agg's binary_logloss: 0.420884 + 0.000662195
[2]	cv_agg's binary_logloss: 0.411041 + 0.00114434
[3]	cv_agg's binary_logloss: 0.407541 + 0.00157093
[4]	cv_agg's binary_logloss: 0.406283 + 0.00135447
[5]	cv_agg's binary_logloss: 0.405776 + 0.00146362
[6]	cv_agg's binary_logloss: 0.406005 + 0.00166118
[7]	cv_agg's binary_logloss: 0.406363 + 0.00181882
[8]	cv_agg's binary_logloss: 0.406456 + 0.00183254
[1]	cv_agg's binary_logloss: 0.420828 + 0.000714159
[2]	cv_agg's binary_logloss: 0.410848 + 0.00137118
[3]	cv_agg's binary_logloss: 0.407338 + 0.00167875
[4]	cv_agg's binary_logloss: 0.406156 + 0.00196976
[5]	cv_agg's binary_logloss: 0.406017 + 0.00195077
[6]	cv_agg's binary_logloss: 0.405885 + 0.00210179
[7]	cv_agg's binary_logloss: 0.405656 + 0.00231045
[8]	cv_agg's binary_logloss: 0.405926 + 0.00249015
[9]	cv_agg's binary_logloss: 0.406027 + 0.00261795
[10]	cv_agg's binary_logloss: 0.406004 + 0.00263918
[1]	cv_agg's binary_logloss: 0.420885 + 0.000628238
[2]	cv_agg's binary_logloss: 0.41117 + 0.00145541
[3]	cv_agg's binary_logloss: 0.407773 + 0.001699
[4]	cv_agg's binary_logloss: 0.406845 + 0.00205601
[5]	cv_agg's binary_logloss: 0.406595 + 0.00201342
[6]	cv_agg's binary_logloss: 0.406606 + 0.00255561
[7]	cv_agg's binary_logloss: 0.40676 + 0.00251752
[8]	cv_agg's binary_logloss: 0.407221 + 0.00262008
[1]	cv_agg's binary_logloss: 0.420906 + 0.000569293
[2]	cv_agg's binary_logloss: 0.411169 + 0.00110862
[3]	cv_agg's binary_logloss: 0.407543 + 0.00153311
[4]	cv_agg's binary_logloss: 0.406558 + 0.0017356
[5]	cv_agg's binary_logloss: 0.405824 + 0.00172024
[6]	cv_agg's binary_logloss: 0.405784 + 0.0018943
[7]	cv_agg's binary_logloss: 0.405974 + 0.00182988
[8]	cv_agg's binary_logloss: 0.406352 + 0.0018488
[9]	cv_agg's binary_logloss: 0.406525 + 0.00194966
[1]	cv_agg's binary_logloss: 0.420881 + 0.000577199
[2]	cv_agg's binary_logloss: 0.410994 + 0.0011795
[3]	cv_agg's binary_logloss: 0.407533 + 0.00149167
[4]	cv_agg's binary_logloss: 0.406348 + 0.00167249
[5]	cv_agg's binary_logloss: 0.405718 + 0.0016541
[6]	cv_agg's binary_logloss: 0.405957 + 0.00186215
[7]	cv_agg's binary_logloss: 0.406211 + 0.00234045
[8]	cv_agg's binary_logloss: 0.406339 + 0.00240314
[1]	cv_agg's binary_logloss: 0.420867 + 0.000699722
[2]	cv_agg's binary_logloss: 0.410883 + 0.00122221
[3]	cv_agg's binary_logloss: 0.407242 + 0.00167833
[4]	cv_agg's binary_logloss: 0.40601 + 0.00171494
[5]	cv_agg's binary_logloss: 0.405583 + 0.00184842
[6]	cv_agg's binary_logloss: 0.405321 + 0.00207316
[7]	cv_agg's binary_logloss: 0.405464 + 0.0024094
[8]	cv_agg's binary_logloss: 0.40571 + 0.00249051
[9]	cv_agg's binary_logloss: 0.405679 + 0.00252668
[1]	cv_agg's binary_logloss: 0.421052 + 0.000845812
[2]	cv_agg's binary_logloss: 0.411336 + 0.00151923
[3]	cv_agg's binary_logloss: 0.408061 + 0.0015599
[4]	cv_agg's binary_logloss: 0.4071 + 0.00173859
[5]	cv_agg's binary_logloss: 0.40648 + 0.00166432
[6]	cv_agg's binary_logloss: 0.406198 + 0.00155306
[7]	cv_agg's binary_logloss: 0.406042 + 0.00171606
[8]	cv_agg's binary_logloss: 0.405969 + 0.00170865
[9]	cv_agg's binary_logloss: 0.405917 + 0.00174927
[10]	cv_agg's binary_logloss: 0.405922 + 0.00177441
[11]	cv_agg's binary_logloss: 0.405924 + 0.00178681
[12]	cv_agg's binary_logloss: 0.405911 + 0.00180269
[13]	cv_agg's binary_logloss: 0.405909 + 0.00180109
[14]	cv_agg's binary_logloss: 0.405909 + 0.00180109
[15]	cv_agg's binary_logloss: 0.405909 + 0.00180109
[16]	cv_agg's binary_logloss: 0.405909 + 0.00180109
[1]	cv_agg's binary_logloss: 0.421003 + 0.000552274
[2]	cv_agg's binary_logloss: 0.411159 + 0.00138952
[3]	cv_agg's binary_logloss: 0.407638 + 0.00184822
[4]	cv_agg's binary_logloss: 0.40653 + 0.00213512
[5]	cv_agg's binary_logloss: 0.406135 + 0.00212313
[6]	cv_agg's binary_logloss: 0.406236 + 0.00192153
[7]	cv_agg's binary_logloss: 0.406243 + 0.00220495
[8]	cv_agg's binary_logloss: 0.406778 + 0.002511
[1]	cv_agg's binary_logloss: 0.421002 + 0.00055647
[2]	cv_agg's binary_logloss: 0.411074 + 0.00145181
[3]	cv_agg's binary_logloss: 0.40761 + 0.00166307
[4]	cv_agg's binary_logloss: 0.406199 + 0.00177115
[5]	cv_agg's binary_logloss: 0.405286 + 0.00191763
[6]	cv_agg's binary_logloss: 0.405446 + 0.00223464
[7]	cv_agg's binary_logloss: 0.4058 + 0.00231153
[8]	cv_agg's binary_logloss: 0.405711 + 0.00237417
[1]	cv_agg's binary_logloss: 0.420957 + 0.000679887
[2]	cv_agg's binary_logloss: 0.410916 + 0.00143325
[3]	cv_agg's binary_logloss: 0.407284 + 0.00151401
[4]	cv_agg's binary_logloss: 0.406158 + 0.00165699
[5]	cv_agg's binary_logloss: 0.405833 + 0.00165158
[6]	cv_agg's binary_logloss: 0.405851 + 0.00188247
[7]	cv_agg's binary_logloss: 0.406228 + 0.00206525
[8]	cv_agg's binary_logloss: 0.406338 + 0.00222234
[1]	cv_agg's binary_logloss: 0.420933 + 0.000697
[2]	cv_agg's binary_logloss: 0.410948 + 0.00123294
[3]	cv_agg's binary_logloss: 0.407411 + 0.00114491
[4]	cv_agg's binary_logloss: 0.406167 + 0.00109451
[5]	cv_agg's binary_logloss: 0.405614 + 0.000907445
[6]	cv_agg's binary_logloss: 0.405478 + 0.00130134
[7]	cv_agg's binary_logloss: 0.40549 + 0.00132456
[8]	cv_agg's binary_logloss: 0.405404 + 0.00133605
[9]	cv_agg's binary_logloss: 0.405449 + 0.00132434
[10]	cv_agg's binary_logloss: 0.405406 + 0.00132896
[11]	cv_agg's binary_logloss: 0.405402 + 0.00133617
[12]	cv_agg's binary_logloss: 0.405403 + 0.00133434
[13]	cv_agg's binary_logloss: 0.405392 + 0.00134894
[14]	cv_agg's binary_logloss: 0.405389 + 0.00135249
[15]	cv_agg's binary_logloss: 0.405389 + 0.00135249
[16]	cv_agg's binary_logloss: 0.405389 + 0.00135249
[17]	cv_agg's binary_logloss: 0.405389 + 0.00135249
[18]	cv_agg's binary_logloss: 0.405389 + 0.00135249
[19]	cv_agg's binary_logloss: 0.405389 + 0.00135249
[20]	cv_agg's binary_logloss: 0.405389 + 0.00135249
[1]	cv_agg's binary_logloss: 0.421077 + 0.000808329
[2]	cv_agg's binary_logloss: 0.4111 + 0.00134652
[3]	cv_agg's binary_logloss: 0.407458 + 0.00134082
[4]	cv_agg's binary_logloss: 0.406196 + 0.00160346
[5]	cv_agg's binary_logloss: 0.405729 + 0.00165832
[6]	cv_agg's binary_logloss: 0.405704 + 0.00144487
[7]	cv_agg's binary_logloss: 0.405755 + 0.00144556
[8]	cv_agg's binary_logloss: 0.40566 + 0.00141407
[9]	cv_agg's binary_logloss: 0.405622 + 0.00139504
[10]	cv_agg's binary_logloss: 0.405608 + 0.00142569
[11]	cv_agg's binary_logloss: 0.405614 + 0.00142419
[12]	cv_agg's binary_logloss: 0.405621 + 0.00141565
[13]	cv_agg's binary_logloss: 0.40562 + 0.00141582
[1]	cv_agg's binary_logloss: 0.421052 + 0.000997671
[2]	cv_agg's binary_logloss: 0.411581 + 0.00180404
[3]	cv_agg's binary_logloss: 0.40799 + 0.00176983
[4]	cv_agg's binary_logloss: 0.406684 + 0.00222468
[5]	cv_agg's binary_logloss: 0.40638 + 0.00241386
[6]	cv_agg's binary_logloss: 0.406555 + 0.00217713
[7]	cv_agg's binary_logloss: 0.406793 + 0.00251036
[8]	cv_agg's binary_logloss: 0.407187 + 0.002402
[1]	cv_agg's binary_logloss: 0.42099 + 0.00103984
[2]	cv_agg's binary_logloss: 0.411403 + 0.00159031
[3]	cv_agg's binary_logloss: 0.407771 + 0.00177276
[4]	cv_agg's binary_logloss: 0.406256 + 0.00227446
[5]	cv_agg's binary_logloss: 0.406063 + 0.00220538
[6]	cv_agg's binary_logloss: 0.406163 + 0.00188456
[7]	cv_agg's binary_logloss: 0.406267 + 0.00162221
[8]	cv_agg's binary_logloss: 0.406549 + 0.00177221
[1]	cv_agg's binary_logloss: 0.420965 + 0.00106999
[2]	cv_agg's binary_logloss: 0.411195 + 0.00168151
[3]	cv_agg's binary_logloss: 0.407589 + 0.00162077
[4]	cv_agg's binary_logloss: 0.406688 + 0.0015811
[5]	cv_agg's binary_logloss: 0.406437 + 0.00171499
[6]	cv_agg's binary_logloss: 0.406314 + 0.00208165
[7]	cv_agg's binary_logloss: 0.406597 + 0.00190547
[8]	cv_agg's binary_logloss: 0.406859 + 0.0019616
[9]	cv_agg's binary_logloss: 0.407119 + 0.00201321
[1]	cv_agg's binary_logloss: 0.421086 + 0.00099763
[2]	cv_agg's binary_logloss: 0.411342 + 0.00136407
[3]	cv_agg's binary_logloss: 0.407555 + 0.00141614
[4]	cv_agg's binary_logloss: 0.406404 + 0.00140265
[5]	cv_agg's binary_logloss: 0.406148 + 0.00138469
[6]	cv_agg's binary_logloss: 0.406163 + 0.00146901
[7]	cv_agg's binary_logloss: 0.405997 + 0.00171483
[8]	cv_agg's binary_logloss: 0.406005 + 0.00187154
[9]	cv_agg's binary_logloss: 0.406087 + 0.00194841
[10]	cv_agg's binary_logloss: 0.406137 + 0.00198334
[1]	cv_agg's binary_logloss: 0.421038 + 0.00108606
[2]	cv_agg's binary_logloss: 0.411223 + 0.00148789
[3]	cv_agg's binary_logloss: 0.407619 + 0.00136606
[4]	cv_agg's binary_logloss: 0.406396 + 0.00143582
[5]	cv_agg's binary_logloss: 0.405879 + 0.00172313
[6]	cv_agg's binary_logloss: 0.405778 + 0.00169624
[7]	cv_agg's binary_logloss: 0.405638 + 0.00172733
[8]	cv_agg's binary_logloss: 0.405578 + 0.00187976
[9]	cv_agg's binary_logloss: 0.405569 + 0.00190918
[10]	cv_agg's binary_logloss: 0.405552 + 0.00190794
[11]	cv_agg's binary_logloss: 0.405561 + 0.00191673
[12]	cv_agg's binary_logloss: 0.405569 + 0.00192461
[13]	cv_agg's binary_logloss: 0.405579 + 0.00193415
[1]	cv_agg's binary_logloss: 0.42082 + 0.000718273
[2]	cv_agg's binary_logloss: 0.411116 + 0.00150294
[3]	cv_agg's binary_logloss: 0.407735 + 0.00181492
[4]	cv_agg's binary_logloss: 0.406722 + 0.00185533
[5]	cv_agg's binary_logloss: 0.406365 + 0.00208144
[6]	cv_agg's binary_logloss: 0.406577 + 0.00215249
[7]	cv_agg's binary_logloss: 0.406609 + 0.00190211
[8]	cv_agg's binary_logloss: 0.406843 + 0.00207172
[1]	cv_agg's binary_logloss: 0.420926 + 0.000679012
[2]	cv_agg's binary_logloss: 0.411046 + 0.00135296
[3]	cv_agg's binary_logloss: 0.407588 + 0.00173951
[4]	cv_agg's binary_logloss: 0.406583 + 0.00175286
[5]	cv_agg's binary_logloss: 0.40628 + 0.00173443
[6]	cv_agg's binary_logloss: 0.406131 + 0.00203787
[7]	cv_agg's binary_logloss: 0.406363 + 0.00196254
[8]	cv_agg's binary_logloss: 0.406688 + 0.00193342
[9]	cv_agg's binary_logloss: 0.407204 + 0.00204291
[1]	cv_agg's binary_logloss: 0.420926 + 0.000674324
[2]	cv_agg's binary_logloss: 0.411043 + 0.00123909
[3]	cv_agg's binary_logloss: 0.407707 + 0.00132579
[4]	cv_agg's binary_logloss: 0.406616 + 0.0015831
[5]	cv_agg's binary_logloss: 0.405932 + 0.00152872
[6]	cv_agg's binary_logloss: 0.405835 + 0.00144607
[7]	cv_agg's binary_logloss: 0.406041 + 0.00149629
[8]	cv_agg's binary_logloss: 0.406516 + 0.00179573
[9]	cv_agg's binary_logloss: 0.406672 + 0.00197041
[1]	cv_agg's binary_logloss: 0.420871 + 0.000725814
[2]	cv_agg's binary_logloss: 0.410944 + 0.0012264
[3]	cv_agg's binary_logloss: 0.407467 + 0.00148906
[4]	cv_agg's binary_logloss: 0.406283 + 0.00159599
[5]	cv_agg's binary_logloss: 0.406057 + 0.0019189
[6]	cv_agg's binary_logloss: 0.406151 + 0.00209087
[7]	cv_agg's binary_logloss: 0.406296 + 0.00210632
[8]	cv_agg's binary_logloss: 0.406168 + 0.00198443
[1]	cv_agg's binary_logloss: 0.420889 + 0.000865003
[2]	cv_agg's binary_logloss: 0.410888 + 0.00135205
[3]	cv_agg's binary_logloss: 0.407232 + 0.00177295
[4]	cv_agg's binary_logloss: 0.406099 + 0.00178745
[5]	cv_agg's binary_logloss: 0.405808 + 0.0018287
[6]	cv_agg's binary_logloss: 0.405678 + 0.00188172
[7]	cv_agg's binary_logloss: 0.405628 + 0.00175372
[8]	cv_agg's binary_logloss: 0.405613 + 0.00177803
[9]	cv_agg's binary_logloss: 0.405564 + 0.00181906
[10]	cv_agg's binary_logloss: 0.405567 + 0.0018301
[11]	cv_agg's binary_logloss: 0.405561 + 0.00183492
[12]	cv_agg's binary_logloss: 0.405568 + 0.00182621
[13]	cv_agg's binary_logloss: 0.405554 + 0.00184497
[14]	cv_agg's binary_logloss: 0.405554 + 0.00184497
[15]	cv_agg's binary_logloss: 0.405554 + 0.00184497
[16]	cv_agg's binary_logloss: 0.405554 + 0.00184497
[17]	cv_agg's binary_logloss: 0.405554 + 0.00184497
[18]	cv_agg's binary_logloss: 0.405554 + 0.00184497
[19]	cv_agg's binary_logloss: 0.405554 + 0.00184497
[1]	cv_agg's binary_logloss: 0.4209 + 0.000614401
[2]	cv_agg's binary_logloss: 0.411034 + 0.00143954
[3]	cv_agg's binary_logloss: 0.407296 + 0.00143206
[4]	cv_agg's binary_logloss: 0.406084 + 0.00147141
[5]	cv_agg's binary_logloss: 0.405743 + 0.00121564
[6]	cv_agg's binary_logloss: 0.405904 + 0.00121119
[7]	cv_agg's binary_logloss: 0.406129 + 0.00135158
[8]	cv_agg's binary_logloss: 0.40663 + 0.00146553
[1]	cv_agg's binary_logloss: 0.420976 + 0.00064108
[2]	cv_agg's binary_logloss: 0.411085 + 0.00110743
[3]	cv_agg's binary_logloss: 0.407512 + 0.00136697
[4]	cv_agg's binary_logloss: 0.406162 + 0.00194303
[5]	cv_agg's binary_logloss: 0.40599 + 0.00213215
[6]	cv_agg's binary_logloss: 0.406232 + 0.00219297
[7]	cv_agg's binary_logloss: 0.40652 + 0.00210679
[8]	cv_agg's binary_logloss: 0.406672 + 0.00224461
[1]	cv_agg's binary_logloss: 0.420896 + 0.000728804
[2]	cv_agg's binary_logloss: 0.410844 + 0.00133598
[3]	cv_agg's binary_logloss: 0.407194 + 0.00170936
[4]	cv_agg's binary_logloss: 0.405975 + 0.001757
[5]	cv_agg's binary_logloss: 0.40578 + 0.00179671
[6]	cv_agg's binary_logloss: 0.405768 + 0.00185152
[7]	cv_agg's binary_logloss: 0.405941 + 0.00198506
[8]	cv_agg's binary_logloss: 0.406318 + 0.00212082
[9]	cv_agg's binary_logloss: 0.406605 + 0.00228767
[1]	cv_agg's binary_logloss: 0.421034 + 0.000886361
[2]	cv_agg's binary_logloss: 0.411227 + 0.00152327
[3]	cv_agg's binary_logloss: 0.407382 + 0.0020041
[4]	cv_agg's binary_logloss: 0.406451 + 0.00208603
[5]	cv_agg's binary_logloss: 0.406064 + 0.00222579
[6]	cv_agg's binary_logloss: 0.405963 + 0.00228854
[7]	cv_agg's binary_logloss: 0.406061 + 0.00214214
[8]	cv_agg's binary_logloss: 0.406022 + 0.00206411
[9]	cv_agg's binary_logloss: 0.406053 + 0.0021518
[1]	cv_agg's binary_logloss: 0.420899 + 0.000840639
[2]	cv_agg's binary_logloss: 0.410887 + 0.00133956
[3]	cv_agg's binary_logloss: 0.407296 + 0.00160059
[4]	cv_agg's binary_logloss: 0.406287 + 0.00178414
[5]	cv_agg's binary_logloss: 0.405676 + 0.00197007
[6]	cv_agg's binary_logloss: 0.40538 + 0.00213212
[7]	cv_agg's binary_logloss: 0.405353 + 0.00233639
[8]	cv_agg's binary_logloss: 0.405357 + 0.00242466
[9]	cv_agg's binary_logloss: 0.405362 + 0.00251949
[10]	cv_agg's binary_logloss: 0.405335 + 0.00253294
[11]	cv_agg's binary_logloss: 0.405322 + 0.00253881
[12]	cv_agg's binary_logloss: 0.405331 + 0.00254881
[13]	cv_agg's binary_logloss: 0.40534 + 0.00255848
[14]	cv_agg's binary_logloss: 0.40534 + 0.00255848
[1]	cv_agg's binary_logloss: 0.421037 + 0.00051001
[2]	cv_agg's binary_logloss: 0.411338 + 0.00114348
[3]	cv_agg's binary_logloss: 0.407871 + 0.00156754
[4]	cv_agg's binary_logloss: 0.406578 + 0.00170657
[5]	cv_agg's binary_logloss: 0.406098 + 0.00181194
[6]	cv_agg's binary_logloss: 0.406177 + 0.0019996
[7]	cv_agg's binary_logloss: 0.406524 + 0.00190428
[8]	cv_agg's binary_logloss: 0.406866 + 0.00200637
[1]	cv_agg's binary_logloss: 0.420985 + 0.000571418
[2]	cv_agg's binary_logloss: 0.41101 + 0.00136614
[3]	cv_agg's binary_logloss: 0.407324 + 0.0015724
[4]	cv_agg's binary_logloss: 0.4062 + 0.0016208
[5]	cv_agg's binary_logloss: 0.405728 + 0.00173463
[6]	cv_agg's binary_logloss: 0.405774 + 0.00180605
[7]	cv_agg's binary_logloss: 0.405758 + 0.00195108
[8]	cv_agg's binary_logloss: 0.406069 + 0.00184147
[1]	cv_agg's binary_logloss: 0.420938 + 0.000669035
[2]	cv_agg's binary_logloss: 0.411068 + 0.0014495
[3]	cv_agg's binary_logloss: 0.407525 + 0.00151283
[4]	cv_agg's binary_logloss: 0.406514 + 0.00149285
[5]	cv_agg's binary_logloss: 0.406008 + 0.00147076
[6]	cv_agg's binary_logloss: 0.405787 + 0.0013937
[7]	cv_agg's binary_logloss: 0.406055 + 0.00166471
[8]	cv_agg's binary_logloss: 0.406328 + 0.00200221
[9]	cv_agg's binary_logloss: 0.406528 + 0.00209672
[1]	cv_agg's binary_logloss: 0.421102 + 0.00077901
[2]	cv_agg's binary_logloss: 0.411192 + 0.00140318
[3]	cv_agg's binary_logloss: 0.407418 + 0.00159535
[4]	cv_agg's binary_logloss: 0.40633 + 0.00196396
[5]	cv_agg's binary_logloss: 0.405981 + 0.00201396
[6]	cv_agg's binary_logloss: 0.405866 + 0.00230329
[7]	cv_agg's binary_logloss: 0.405851 + 0.00246404
[8]	cv_agg's binary_logloss: 0.405869 + 0.00255848
[9]	cv_agg's binary_logloss: 0.405871 + 0.00262907
[10]	cv_agg's binary_logloss: 0.405855 + 0.00262664
[1]	cv_agg's binary_logloss: 0.420978 + 0.000765911
[2]	cv_agg's binary_logloss: 0.410947 + 0.00132498
[3]	cv_agg's binary_logloss: 0.407432 + 0.00161747
[4]	cv_agg's binary_logloss: 0.406035 + 0.00172701
[5]	cv_agg's binary_logloss: 0.405456 + 0.0016781
[6]	cv_agg's binary_logloss: 0.40523 + 0.00166819
[7]	cv_agg's binary_logloss: 0.405131 + 0.00168
[8]	cv_agg's binary_logloss: 0.405133 + 0.00168123
[9]	cv_agg's binary_logloss: 0.405117 + 0.00171272
[10]	cv_agg's binary_logloss: 0.405129 + 0.00175487
[11]	cv_agg's binary_logloss: 0.405116 + 0.00175254
[12]	cv_agg's binary_logloss: 0.405116 + 0.00175254
[13]	cv_agg's binary_logloss: 0.405116 + 0.00175254
[14]	cv_agg's binary_logloss: 0.405116 + 0.00175254
[1]	cv_agg's binary_logloss: 0.421179 + 0.000604748
[2]	cv_agg's binary_logloss: 0.411129 + 0.00163871
[3]	cv_agg's binary_logloss: 0.407424 + 0.00186772
[4]	cv_agg's binary_logloss: 0.406399 + 0.00206872
[5]	cv_agg's binary_logloss: 0.406339 + 0.0020249
[6]	cv_agg's binary_logloss: 0.406226 + 0.00219041
[7]	cv_agg's binary_logloss: 0.406406 + 0.00200033
[8]	cv_agg's binary_logloss: 0.406858 + 0.0020929
[9]	cv_agg's binary_logloss: 0.407083 + 0.00210665
[1]	cv_agg's binary_logloss: 0.421102 + 0.000718257
[2]	cv_agg's binary_logloss: 0.41091 + 0.00163312
[3]	cv_agg's binary_logloss: 0.407431 + 0.00178289
[4]	cv_agg's binary_logloss: 0.406167 + 0.00185788
[5]	cv_agg's binary_logloss: 0.405566 + 0.00163748
[6]	cv_agg's binary_logloss: 0.405553 + 0.00169855
[7]	cv_agg's binary_logloss: 0.405664 + 0.00144205
[8]	cv_agg's binary_logloss: 0.405846 + 0.00148884
[9]	cv_agg's binary_logloss: 0.40604 + 0.00132245
[1]	cv_agg's binary_logloss: 0.421208 + 0.000947495
[2]	cv_agg's binary_logloss: 0.411032 + 0.00144556
[3]	cv_agg's binary_logloss: 0.407331 + 0.00143179
[4]	cv_agg's binary_logloss: 0.406076 + 0.00150314
[5]	cv_agg's binary_logloss: 0.405594 + 0.00159541
[6]	cv_agg's binary_logloss: 0.405266 + 0.0016331
[7]	cv_agg's binary_logloss: 0.405487 + 0.00186218
[8]	cv_agg's binary_logloss: 0.405597 + 0.00209566
[9]	cv_agg's binary_logloss: 0.405538 + 0.00221839
[1]	cv_agg's binary_logloss: 0.421162 + 0.000876478
[2]	cv_agg's binary_logloss: 0.41095 + 0.001295
[3]	cv_agg's binary_logloss: 0.407344 + 0.00125295
[4]	cv_agg's binary_logloss: 0.406032 + 0.00155111
[5]	cv_agg's binary_logloss: 0.405576 + 0.00158028
[6]	cv_agg's binary_logloss: 0.405512 + 0.00171632
[7]	cv_agg's binary_logloss: 0.405609 + 0.00177074
[8]	cv_agg's binary_logloss: 0.405586 + 0.00171619
[9]	cv_agg's binary_logloss: 0.405607 + 0.00176233
[1]	cv_agg's binary_logloss: 0.421091 + 0.0008429
[2]	cv_agg's binary_logloss: 0.41091 + 0.00129173
[3]	cv_agg's binary_logloss: 0.407263 + 0.00165922
[4]	cv_agg's binary_logloss: 0.405844 + 0.00167017
[5]	cv_agg's binary_logloss: 0.405189 + 0.00173246
[6]	cv_agg's binary_logloss: 0.405083 + 0.00208649
[7]	cv_agg's binary_logloss: 0.40498 + 0.00213306
[8]	cv_agg's binary_logloss: 0.405 + 0.0020826
[9]	cv_agg's binary_logloss: 0.404968 + 0.00211565
[10]	cv_agg's binary_logloss: 0.405019 + 0.00213767
[11]	cv_agg's binary_logloss: 0.404991 + 0.002145
[12]	cv_agg's binary_logloss: 0.404986 + 0.00214167
Time used: 88.33412837982178
